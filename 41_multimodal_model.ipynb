{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ee3a016-81f8-443d-b200-9616059a652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/raster\")\n",
    "sys.path.append(\"models/vector\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from initialize_gnn import initialize_gnn\n",
    "from cnn import CNN\n",
    "from vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268a3989-b0f0-4496-8567-e4435c5aa980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a seed for reproducible results\n",
    "np.random.seed(69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f8630a-e832-4fea-b0cf-fef86e34b62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, then MPS, otherwise use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "    # cluster path\n",
    "    multimodal_path = \"../scratch/multimodal\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    # local path\n",
    "    multimodal_path = \"../data.nosync/multimodal\"\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9bc9a6-4bff-4444-af15-53e494907a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "737ec790-06d8-49e5-a93f-3fad641d9b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots if working locally\n",
    "if not torch.cuda.is_available():\n",
    "    plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d6d062-de0e-4c88-8518-27cf100f0866",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d80f0071-6616-45bc-ada7-d7f954be8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BuildingMultimodalDataset(Dataset):\n",
    "    def __init__(self, raster_path, vector_path, operators, transform=None):\n",
    "        '''Stores the directory and filenames of the individual raster (.npz) and vector (.pt) files.'''\n",
    "        # store the path to the raster and vector files\n",
    "        self.raster_path = raster_path\n",
    "        self.vector_path = vector_path\n",
    "\n",
    "        # get filenames of the individual files, sort the filenames to make them line up\n",
    "        self.raster_filenames = sorted(os.listdir(self.raster_path))\n",
    "        self.vector_filenames = sorted(os.listdir(self.vector_path))\n",
    "\n",
    "        # make sure that the samples line up\n",
    "        assert len(self.raster_filenames) == len(self.vector_filenames)\n",
    "\n",
    "        # store indices of the operators within operator_order for slicing in the __getitem__ method\n",
    "        self.operators = sorted([operator_order.index(operator) for operator in operators if operator in operator_order])\n",
    "\n",
    "        # store transformation\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Enables dataset length calculation.'''\n",
    "        return len(self.raster_filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Enables indexing, returns graph and raster representation and generalization operator as label.'''\n",
    "        # load the raster sample associated with the given index\n",
    "        raster_filename = self.raster_filenames[index]\n",
    "        raster_sample_raw = np.load(os.path.join(self.raster_path, raster_filename))\n",
    "\n",
    "        # extract the rasters\n",
    "        focal_building_raster = raster_sample_raw[\"focal_building\"]\n",
    "        context_buildings_raster = raster_sample_raw[\"context_buildings\"]\n",
    "        roads_raster = raster_sample_raw[\"roads\"]\n",
    "\n",
    "        # stack the rasters to shape (3, n_pixels, n_pixels) and convert to tensor\n",
    "        raster_sample = np.stack([focal_building_raster, context_buildings_raster, roads_raster], axis=0)\n",
    "        raster_sample = torch.from_numpy(raster_sample).float()\n",
    "\n",
    "        # load the vector sample associated with the given index\n",
    "        vector_filename = self.vector_filenames[index]\n",
    "        vector_sample = torch.load(os.path.join(self.vector_path, vector_filename))\n",
    "\n",
    "        # extract the operators from the graph object\n",
    "        operators = vector_sample.y[self.operators]\n",
    "\n",
    "        # reshape the operators associated with the graph\n",
    "        vector_sample.y = vector_sample.y[self.operators].reshape(1, -1)\n",
    "\n",
    "        return raster_sample, vector_sample, operators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5c759b-a29e-4970-9962-54684478b60c",
   "metadata": {},
   "source": [
    "### Model design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0530f55-8b68-4bc2-baac-26b6b98b1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, raster_model, vector_model, dummy_raster_sample, dummy_vector_sample, n_classes):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        self.raster_model = raster_model\n",
    "        self.vector_model = vector_model\n",
    "        \n",
    "        # both models are already trained and only require gradient for fusion layers\n",
    "        for param in self.raster_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.vector_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # remove classification heads\n",
    "        self.raster_model.classification_heads = nn.Identity()\n",
    "        self.vector_model.classification_heads = nn.Identity()\n",
    "\n",
    "        # pass dummy raster and dummy vector samples through the networks to determine the number of output features\n",
    "        # when the classification heads are missing\n",
    "        out_raster = self.raster_model(dummy_raster_sample.unsqueeze(0))\n",
    "        out_vector = self.vector_model(dummy_vector_sample.x_dict, dummy_vector_sample.edge_index_dict)\n",
    "        n_raster_features = out_raster.shape[1]\n",
    "        n_vector_features = out_vector.shape[1]\n",
    "        \n",
    "        # fusion layer\n",
    "        self.fusion_layer = nn.Linear(n_raster_features + n_vector_features, n_classes)\n",
    "\n",
    "    def forward(self, raster, graph):\n",
    "        raster_output = self.raster_model(raster)\n",
    "        vector_output = self.vector_model(graph.x_dict, graph.edge_index_dict)\n",
    "\n",
    "        # concatenate along feature dimension\n",
    "        combined_features = torch.cat((raster_output, vector_output), dim=1)\n",
    "        result = self.fusion_layer(combined_features)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4f96a-b9c1-486e-b07d-a83c885ac113",
   "metadata": {},
   "source": [
    "### Elimination model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ffbd5e-7ad4-4e11-969e-00cf2b35ee1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000 samples in the training set.\n",
      "250 samples in the validation set.\n",
      "250 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "# define path to training, validation and test data for both raster and vector\n",
    "path_to_raster_training_data = \"../data.nosync/raster/training_data/elimination/training\"\n",
    "path_to_vector_training_data = \"../data.nosync/vector/training_data/elimination/training\"\n",
    "path_to_raster_validation_data = \"../data.nosync/raster/training_data/elimination/validation\"\n",
    "path_to_vector_validation_data = \"../data.nosync/vector/training_data/elimination/validation\"\n",
    "path_to_raster_test_data = \"../data.nosync/raster/training_data/elimination/test\"\n",
    "path_to_vector_test_data = \"../data.nosync/vector/training_data/elimination/test\"\n",
    "\n",
    "# define input parameters\n",
    "elimination_operators = [\"elimination\"]\n",
    "n_classes = len(elimination_operators)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# construct training DataLoader\n",
    "training_set = BuildingMultimodalDataset(path_to_raster_training_data, path_to_vector_training_data, operators=elimination_operators)\n",
    "training_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# construct validation DataLoader (no shuffling)\n",
    "validation_set = BuildingMultimodalDataset(path_to_raster_validation_data, path_to_vector_validation_data, operators=elimination_operators)\n",
    "validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# construct test DataLoader (no shuffling)\n",
    "test_set = BuildingMultimodalDataset(path_to_raster_test_data, path_to_vector_test_data, operators=elimination_operators)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"{len(training_set):,} samples in the training set.\")\n",
    "print(f\"{len(validation_set):,} samples in the validation set.\")\n",
    "print(f\"{len(test_set):,} samples in the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a60138b4-6c4c-44d8-a6b0-8c0a9c978bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of node features: {'focal_building': 10, 'context_building': 10, 'road': 2}, 1 operators\n",
      "Models successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the trained raster model\n",
    "raster_model_path = \"../data.nosync/raster/models/elimination\"\n",
    "#raster_model_name = \"CNN_eli_attachRoadsTrue_2190433p_1000s_10ep_bs16.pth\"\n",
    "#raster_model = CNN(n_channels=3, n_classes=1)\n",
    "raster_model_name = \"ViT_eli_attachRoadsTrue_26820129p_1000s_10ep_bs16.pth\"\n",
    "raster_model = ViT(channels=3, num_classes=1)\n",
    "raster_checkpoint = torch.load(os.path.join(raster_model_path, raster_model_name))\n",
    "raster_model.load_state_dict(raster_checkpoint[\"model_state_dict\"])\n",
    "raster_model.eval()\n",
    "    \n",
    "# load the trained vector model\n",
    "vector_model_path = \"../data.nosync/vector/models/elimination\"\n",
    "#vector_model_name = \"HGNN_eli_attachRoadsTrue_253313p_1000s_10ep_bs16.pth\"\n",
    "#vector_model = initialize_gnn(model=\"hgnn\", sample=training_set[2][1], hidden_channels=128, num_layers=2, node_to_predict=\"focal_building\")\n",
    "vector_model_name = \"HGT_eli_attachRoadsTrue_637219p_1000s_10ep_bs16.pth\"\n",
    "vector_model = initialize_gnn(model=\"hgt\", sample=training_set[2][1], hidden_channels=128, num_heads=2, \n",
    "                              num_layers=2, node_to_predict=\"focal_building\")\n",
    "vector_checkpoint = torch.load(os.path.join(vector_model_path, vector_model_name))\n",
    "vector_model.load_state_dict(vector_checkpoint[\"model_state_dict\"])\n",
    "vector_model.eval()\n",
    "\n",
    "print(\"Models successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50162e44-e4b0-4a2b-88df-7b4d102ee71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the multimodal model\n",
    "multimodal_model = MultimodalModel(raster_model, \n",
    "                                   vector_model, \n",
    "                                   dummy_raster_sample=training_set[0][0], \n",
    "                                   dummy_vector_sample=training_set[2][1], \n",
    "                                   n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fbdcf0f-3d62-4098-808f-40409d19e3dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0357]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodal_model(training_set[0][0].unsqueeze(0), training_set[2][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1c8169-24e1-4261-ae05-69c411866c45",
   "metadata": {},
   "source": [
    "### Selection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e667bd-93a1-4456-88a3-78bf9e0110b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000 samples in the training set.\n",
      "250 samples in the validation set.\n",
      "250 samples in the test set.\n"
     ]
    }
   ],
   "source": [
    "# define path to training, validation and test data for both raster and vector\n",
    "path_to_raster_training_data = \"../data.nosync/raster/training_data/selection/training\"\n",
    "path_to_vector_training_data = \"../data.nosync/vector/training_data/selection/training\"\n",
    "path_to_raster_validation_data = \"../data.nosync/raster/training_data/selection/validation\"\n",
    "path_to_vector_validation_data = \"../data.nosync/vector/training_data/selection/validation\"\n",
    "path_to_raster_test_data = \"../data.nosync/raster/training_data/selection/test\"\n",
    "path_to_vector_test_data = \"../data.nosync/vector/training_data/selection/test\"\n",
    "\n",
    "# define input parameters\n",
    "selection_operators = [\"aggregation\", \"typification\", \"displacement\", \"enlargement\"]\n",
    "n_classes = len(selection_operators)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# construct training DataLoader\n",
    "training_set = BuildingMultimodalDataset(path_to_raster_training_data, path_to_vector_training_data, operators=selection_operators)\n",
    "training_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# construct validation DataLoader (no shuffling)\n",
    "validation_set = BuildingMultimodalDataset(path_to_raster_validation_data, path_to_vector_validation_data, operators=selection_operators)\n",
    "validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# construct test DataLoader (no shuffling)\n",
    "test_set = BuildingMultimodalDataset(path_to_raster_test_data, path_to_vector_test_data, operators=selection_operators)\n",
    "test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"{len(training_set):,} samples in the training set.\")\n",
    "print(f\"{len(validation_set):,} samples in the validation set.\")\n",
    "print(f\"{len(test_set):,} samples in the test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d9050ba-ba6e-421c-b9f9-3e30da0f7ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of node features: {'focal_building': 10, 'context_building': 10, 'road': 2}, 4 operators\n",
      "Models successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the trained raster model\n",
    "raster_model_path = \"../data.nosync/raster/models/selection\"\n",
    "#raster_model_name = \"CNN_sel_attachRoadsTrue_8481988p_1000s_10ep_bs16.pth\"\n",
    "#raster_model = CNN(n_channels=3, n_classes=4)\n",
    "raster_model_name = \"ViT_sel_attachRoadsTrue_26844804p_1000s_10ep_bs16.pth\"\n",
    "raster_model = ViT(channels=3, num_classes=4)\n",
    "raster_checkpoint = torch.load(os.path.join(raster_model_path, raster_model_name))\n",
    "raster_model.load_state_dict(raster_checkpoint[\"model_state_dict\"])\n",
    "raster_model.eval()\n",
    "    \n",
    "# load the trained vector model\n",
    "vector_model_path = \"../data.nosync/vector/models/selection\"\n",
    "#vector_model_name = \"HGNN_sel_attachRoadsTrue_278276p_1000s_10ep_bs16.pth\"\n",
    "#vector_model = initialize_gnn(model=\"hgnn\", sample=training_set[0][1], hidden_channels=128, num_layers=2, node_to_predict=\"focal_building\")\n",
    "vector_model_name = \"HGT_sel_attachRoadsTrue_662182p_1000s_10ep_bs16.pth\"\n",
    "vector_model = initialize_gnn(model=\"hgt\", sample=training_set[0][1], hidden_channels=128, num_heads=2, \n",
    "                              num_layers=2, node_to_predict=\"focal_building\")\n",
    "vector_checkpoint = torch.load(os.path.join(vector_model_path, vector_model_name))\n",
    "vector_model.load_state_dict(vector_checkpoint[\"model_state_dict\"])\n",
    "vector_model.eval()\n",
    "\n",
    "print(\"Models successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d9adde2-9c59-40e3-b1d1-cf976b914ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the multimodal model\n",
    "multimodal_model = MultimodalModel(raster_model, \n",
    "                                   vector_model, \n",
    "                                   dummy_raster_sample=training_set[0][0], \n",
    "                                   dummy_vector_sample=training_set[0][1], \n",
    "                                   n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef203ce-9b46-476d-9926-fac996bce5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0339, -0.1297,  0.6741,  0.4333]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multimodal_model(training_set[0][0].unsqueeze(0), training_set[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e29e71-00ee-40c3-894a-e5db0c2c9c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

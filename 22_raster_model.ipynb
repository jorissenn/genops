{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f613cb6e-9dde-45a0-b730-a6883df55bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from auxiliary.visualization import plot_raster\n",
    "from auxiliary.evaluation import calculate_conf_matrix, calculate_metrics\n",
    "from model_components.unet import *\n",
    "from model_components.resunet import *\n",
    "from model_components.attunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb5a9c3-c82b-49fb-8cce-dd26809ce1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, then MPS, otherwise use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227e4d6e-8982-412a-adaf-57a6035fc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8f8d99-729f-4680-96a5-b7b6bfdc5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots\n",
    "plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af7673-18d4-4d02-b65b-7b50406faed5",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61cb6f3-5047-481d-8652-5687a2a8ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a Dataset object for DataLoader\n",
    "class BuildingRasterDataset(Dataset):\n",
    "    def __init__(self, path, n_channels=3, transform=None):\n",
    "        '''Stores the directory and filenames of the individual .npz files.'''\n",
    "        assert n_channels in (2, 3)\n",
    "        \n",
    "        # store directory of individual files\n",
    "        self.path = path\n",
    "        # get filenames of individual files\n",
    "        self.filenames = os.listdir(path)\n",
    "\n",
    "        # store the number of channels of the returned image\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        # store transformation\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Enables dataset length calculation.'''\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Enables indexing, returns uuid and block raster as features and generalization operators as label.'''\n",
    "        # get filename associated with given index\n",
    "        filename = self.filenames[index]\n",
    "\n",
    "        # load the file with the filename\n",
    "        sample = np.load(os.path.join(self.path, filename))\n",
    "\n",
    "        # extract the rasters\n",
    "        target = sample[\"target\"]\n",
    "        context = sample[\"context\"]\n",
    "        road = sample[\"road\"]\n",
    "\n",
    "        # stack the rasters according to n_channels\n",
    "        if self.n_channels == 3:\n",
    "            # stack the rasters to shape (3, n_pixels, n_pixels)\n",
    "            block = np.stack([target, context, road], axis=0)\n",
    "        elif self.n_channels == 2:\n",
    "            # combine context and road\n",
    "            context_road = context + road\n",
    "            # correct overlapping features\n",
    "            context_road[context_road > 1.0] = 1.0\n",
    "\n",
    "            # stack the rasters to shape (2, n_pixels, n_pixels)\n",
    "            block = np.stack([target, context_road], axis=0)\n",
    "\n",
    "        # convert rasters to tensor\n",
    "        block = torch.from_numpy(block).float()\n",
    "\n",
    "        # extract generalization operators and convert to tensors\n",
    "        eli = torch.from_numpy(sample[\"elimination\"]).float()\n",
    "        agg = torch.from_numpy(sample[\"aggregation\"]).float()\n",
    "        typ = torch.from_numpy(sample[\"typification\"]).float()\n",
    "        dis = torch.from_numpy(sample[\"displacement\"]).float()\n",
    "        enl = torch.from_numpy(sample[\"enlargement\"]).float()\n",
    "        sim = torch.from_numpy(sample[\"simplification\"]).float()\n",
    "\n",
    "        if self.transform:\n",
    "            block = self.transform(block)\n",
    "\n",
    "        return block, eli, agg, typ, dis, enl, sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f523-0e33-403f-bf0e-7a25aa95fa6c",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "\n",
    "1) Design model (input, output size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "     * Forward pass: Compute prediction\n",
    "     * Backward pass: Compute gradients\n",
    "     * Update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e688e5-9a9b-45ab-a10c-02a15ad36770",
   "metadata": {},
   "source": [
    "### Model design\n",
    "\n",
    "Stride refers to the number of positions that the convolutional kernel shifts at one step. Input channel size of one layer should always be equal to the output channel size of the previous layer.\n",
    "\n",
    "The application of convolution and pooling layers decreases the size of the image: The output after a convolution can be calculated according to the following formula, where $W$ is the input width, $F$ is the kernel size, $P$ is the padding and $S$ is the stride:\n",
    "\n",
    "$$\\frac{(W-F + 2 P)}{S} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc295f38-bae2-47cd-b2e3-9195931cdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected layers with Global Average Pooling\n",
    "class FCGlobalPooling(nn.Module):\n",
    "    def __init__(self, n_last_out_channels):\n",
    "        super(FCGlobalPooling, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        \n",
    "        # Due to the global average pooling, the number of input features corresponds to the number of output channels of the last\n",
    "        # convolutional layers\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(), # flatten to reshape the tensor from 4D to 2D\n",
    "            nn.Linear(in_features=self.n_last_out_channels, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Fully-connected layers without Global Average Pooling\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, n_last_out_channels, image_size):\n",
    "        super(FC, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # the number of input features of first fully-connected layer are calculated by multiplying number of output channels of last \n",
    "        # convolutional layer by (image size after all pooling operations)^2\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=self.n_last_out_channels*self.image_size*self.image_size, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb00b17-9dc9-44d0-b266-6e21f1da169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 34,882,675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AttUNet(\n",
       "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att5): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att4): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att3): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att2): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc): FCGlobalPooling(\n",
       "    (fc): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=1, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://amaarora.github.io/posts/2020-09-13-unet.html\n",
    "\n",
    "# conventional, simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        #self.fc = FCGlobalPooling(n_last_out_channels=128)\n",
    "        self.fc = FC(n_last_out_channels=128, image_size=32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input dimension = 256\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # input dimension = 128\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # input dimension = 64\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # input dimension = 32\n",
    "        x = self.fc(x) # No sigmoid function necessary, since BCEWithLogitsLoss applies sigmoid internally for loss computation\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for U-net adapted from https://github.com/milesial/Pytorch-UNet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, 1))\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # decoding + concatenation\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        x = self.fc(logits)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for Residual U-net adapted from https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(3, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        #self.sigmoid = nn.Sigmoid() # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(inputs)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(inputs)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        #output = self.sigmoid(output) # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Code for Attention U-net adapted from https://github.com/LeeJunHyun/Image_Segmentation\n",
    "class AttUNet(nn.Module):\n",
    "    def __init__(self,n_channels):\n",
    "        super(AttUNet,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=n_channels,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,1,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification        \n",
    "        output = self.fc(d1)\n",
    "\n",
    "        return output\n",
    "\n",
    "n_channels = 3\n",
    "\n",
    "# Creating model and moving to device\n",
    "#model = CNN(n_channels=n_channels)\n",
    "#model = UNet(n_channels=n_channels)\n",
    "#model = ResUNet(n_channels=n_channels)\n",
    "model = AttUNet(n_channels=n_channels)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {total_params:,}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52663f75-0732-4f3f-b55e-3a68eee493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary cross-entropy loss, applies a sigmoid internally and takes logits as input\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9f7ae-8c3a-434d-bb6e-4300eb067628",
   "metadata": {},
   "source": [
    "### Loss and activation function\n",
    "\n",
    "Softmax is a common activation function, (binary) cross-Entropy is a common loss function for multiclass classification problems, sigmoid is commonly used for binary classification problems. When using the Pytorch implementation: no softmax in the last layer, class labels not one-hot encoded and no softmax. BCELoss requires an activation function at the end! Sigmoid are usually the last layers in binary classification probems.\n",
    "\n",
    "If you don't know which activation function to use, just use ReLU, Leaky ReLU tries to adress vanishing gradient problem. Multiplies input with small negative numbers, as normal ReLU may cause many gradients to become zero, which means that the weights will never be updated. Whenever weights are not updated during training, use Leaky ReLU.\n",
    "\n",
    "I am dealing with a multilabel (for each generalization operator), binary (operator present or absent) classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2f78-e07d-4922-b9f3-b81ba80b9385",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ac2819-465a-4faa-a8e7-5e2cde507c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 samples in the dataset.\n",
      "epoch 1/10, step 1/10\n",
      "epoch 1/10, step 2/10\n",
      "epoch 1/10, step 3/10\n",
      "epoch 1/10, step 4/10\n",
      "epoch 1/10, step 5/10\n",
      "epoch 1/10, step 6/10\n",
      "epoch 1/10, step 7/10\n",
      "epoch 1/10, step 8/10\n",
      "epoch 1/10, step 9/10\n",
      "epoch 1/10, step 10/10\n",
      "epoch 1 finished, loss: 0.623\n",
      "epoch 2/10, step 1/10\n",
      "epoch 2/10, step 2/10\n",
      "epoch 2/10, step 3/10\n",
      "epoch 2/10, step 4/10\n",
      "epoch 2/10, step 5/10\n",
      "epoch 2/10, step 6/10\n",
      "epoch 2/10, step 7/10\n",
      "epoch 2/10, step 8/10\n",
      "epoch 2/10, step 9/10\n",
      "epoch 2/10, step 10/10\n",
      "epoch 2 finished, loss: 0.481\n",
      "epoch 3/10, step 1/10\n",
      "epoch 3/10, step 2/10\n",
      "epoch 3/10, step 3/10\n",
      "epoch 3/10, step 4/10\n",
      "epoch 3/10, step 5/10\n",
      "epoch 3/10, step 6/10\n",
      "epoch 3/10, step 7/10\n",
      "epoch 3/10, step 8/10\n",
      "epoch 3/10, step 9/10\n",
      "epoch 3/10, step 10/10\n",
      "epoch 3 finished, loss: 0.452\n",
      "epoch 4/10, step 1/10\n",
      "epoch 4/10, step 2/10\n",
      "epoch 4/10, step 3/10\n",
      "epoch 4/10, step 4/10\n",
      "epoch 4/10, step 5/10\n",
      "epoch 4/10, step 6/10\n",
      "epoch 4/10, step 7/10\n",
      "epoch 4/10, step 8/10\n",
      "epoch 4/10, step 9/10\n",
      "epoch 4/10, step 10/10\n",
      "epoch 4 finished, loss: 0.442\n",
      "epoch 5/10, step 1/10\n",
      "epoch 5/10, step 2/10\n",
      "epoch 5/10, step 3/10\n",
      "epoch 5/10, step 4/10\n",
      "epoch 5/10, step 5/10\n",
      "epoch 5/10, step 6/10\n",
      "epoch 5/10, step 7/10\n",
      "epoch 5/10, step 8/10\n",
      "epoch 5/10, step 9/10\n",
      "epoch 5/10, step 10/10\n",
      "epoch 5 finished, loss: 0.435\n",
      "epoch 6/10, step 1/10\n",
      "epoch 6/10, step 2/10\n",
      "epoch 6/10, step 3/10\n",
      "epoch 6/10, step 4/10\n",
      "epoch 6/10, step 5/10\n",
      "epoch 6/10, step 6/10\n",
      "epoch 6/10, step 7/10\n",
      "epoch 6/10, step 8/10\n",
      "epoch 6/10, step 9/10\n",
      "epoch 6/10, step 10/10\n",
      "epoch 6 finished, loss: 0.425\n",
      "epoch 7/10, step 1/10\n",
      "epoch 7/10, step 2/10\n",
      "epoch 7/10, step 3/10\n",
      "epoch 7/10, step 4/10\n",
      "epoch 7/10, step 5/10\n",
      "epoch 7/10, step 6/10\n",
      "epoch 7/10, step 7/10\n",
      "epoch 7/10, step 8/10\n",
      "epoch 7/10, step 9/10\n",
      "epoch 7/10, step 10/10\n",
      "epoch 7 finished, loss: 0.408\n",
      "epoch 8/10, step 1/10\n",
      "epoch 8/10, step 2/10\n",
      "epoch 8/10, step 3/10\n",
      "epoch 8/10, step 4/10\n",
      "epoch 8/10, step 5/10\n",
      "epoch 8/10, step 6/10\n",
      "epoch 8/10, step 7/10\n",
      "epoch 8/10, step 8/10\n",
      "epoch 8/10, step 9/10\n",
      "epoch 8/10, step 10/10\n",
      "epoch 8 finished, loss: 0.390\n",
      "epoch 9/10, step 1/10\n",
      "epoch 9/10, step 2/10\n",
      "epoch 9/10, step 3/10\n",
      "epoch 9/10, step 4/10\n",
      "epoch 9/10, step 5/10\n",
      "epoch 9/10, step 6/10\n",
      "epoch 9/10, step 7/10\n",
      "epoch 9/10, step 8/10\n",
      "epoch 9/10, step 9/10\n",
      "epoch 9/10, step 10/10\n",
      "epoch 9 finished, loss: 0.383\n",
      "epoch 10/10, step 1/10\n",
      "epoch 10/10, step 2/10\n",
      "epoch 10/10, step 3/10\n",
      "epoch 10/10, step 4/10\n",
      "epoch 10/10, step 5/10\n",
      "epoch 10/10, step 6/10\n",
      "epoch 10/10, step 7/10\n",
      "epoch 10/10, step 8/10\n",
      "epoch 10/10, step 9/10\n",
      "epoch 10/10, step 10/10\n",
      "epoch 10 finished, loss: 0.371\n",
      "Training time: 12.051 seconds\n"
     ]
    }
   ],
   "source": [
    "# if CUDA is available, use the cluster path, else local path\n",
    "if torch.cuda.is_available():\n",
    "    path_to_data = \"../scratch/raster\"\n",
    "else:\n",
    "    path_to_data = \"../data.nosync/raster\"\n",
    "\n",
    "# number of epochs and batch size\n",
    "num_epochs = 10\n",
    "batch_size = 1\n",
    "\n",
    "# composing various random transforms that should be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees=(0,360)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)])\n",
    "\n",
    "# construct DataLoader\n",
    "train_dataset = BuildingRasterDataset(path_to_data, n_channels=n_channels, transform=transform)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"{len(train_dataset):,} samples in the dataset.\")\n",
    "\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "    \n",
    "# saving the losses from every epoch\n",
    "train_losses = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    # tracking loss per epoch\n",
    "    train_running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for i, (block, eli, agg, typ, dis, enl, sim) in enumerate(train_dataloader): \n",
    "        n_batches += 1\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "    \n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "    \n",
    "        # empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # forward pass\n",
    "        pred_operators = model(block) # compute predictions, calls forward method under the hood\n",
    "        loss = criterion(pred_operators, operators) # calculate loss\n",
    "        train_running_loss += loss.item() # tracking running loss to keep track of the loss for every epoch\n",
    "    \n",
    "        # backward pass\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update the parameters\n",
    "    \n",
    "        # print information every few batches\n",
    "        if not (i + 1) % (n_iterations // 10):\n",
    "            print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}\")\n",
    "    \n",
    "    # print information at the end of each epoch\n",
    "    train_loss_epoch = train_running_loss / n_batches\n",
    "    train_losses.append(train_loss_epoch)\n",
    "    print(f\"epoch {epoch+1} finished, loss: {train_loss_epoch:.3f}\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Training time: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238cd359-67bd-41d2-8494-4034d198550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, color=\"orange\", label=\"training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe3dd0-951e-48fc-aca2-4b95f40d966f",
   "metadata": {},
   "source": [
    "### Evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d0f803-c2b1-4bc8-a2e7-6ba22ef76dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIMINATION: Accuracy: 0.900, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "AGGREGATION: Accuracy: 0.700, Precision: 0.600, Recall: 0.750, F1-score: 0.667\n",
      "TYPIFICATION: Accuracy: 0.900, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "DISPLACEMENT: Accuracy: 0.800, Precision: 0.800, Recall: 1.000, F1-score: 0.889\n",
      "ENLARGEMENT: Accuracy: 0.800, Precision: 0.800, Recall: 1.000, F1-score: 0.889\n",
      "SIMPLIFICATION: Accuracy: 0.900, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BuildingRasterDataset(path_to_data, n_channels=n_channels)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# stores the confusion matrices for every operator\n",
    "metrics = {}\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    metrics[operator_name] = {}\n",
    "    metrics[operator_name][\"tp\"] = 0\n",
    "    metrics[operator_name][\"fp\"] = 0\n",
    "    metrics[operator_name][\"tn\"] = 0\n",
    "    metrics[operator_name][\"fn\"] = 0\n",
    "\n",
    "# prediction evaluations should not be part of the computational graph, gradients should not be tracked\n",
    "with torch.no_grad():\n",
    "    for block, eli, agg, typ, dis, enl, sim in test_dataloader:\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # prediction on the trained model results in logits, sigmoid needs to be applied to obtain probabilities\n",
    "        pred_operators = torch.sigmoid(model(block))\n",
    "        pred_operators_labels = (pred_operators > 0.5).float()  # thresholding\n",
    "\n",
    "        # calculating metrics for the individual operators\n",
    "        for i, operator_name in enumerate(operator_order):\n",
    "            operator = operators[:, i]\n",
    "            pred_operator = pred_operators_labels[:, i]\n",
    "\n",
    "            tp, fp, tn, fn = calculate_conf_matrix(operator, pred_operator)\n",
    "\n",
    "            metrics[operator_name][\"tp\"] += tp\n",
    "            metrics[operator_name][\"fp\"] += fp\n",
    "            metrics[operator_name][\"tn\"] += tn\n",
    "            metrics[operator_name][\"fn\"] += fn\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    accuracy, precision, recall, f1_score = calculate_metrics(metrics[operator_name][\"tp\"],\n",
    "                                                              metrics[operator_name][\"fp\"],\n",
    "                                                              metrics[operator_name][\"tn\"],\n",
    "                                                              metrics[operator_name][\"fn\"])\n",
    "    \n",
    "    print(f\"{operator_name.upper()}: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f963fc6-62a7-4512-99dc-4277f8bf2b01",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "https://debuggercafe.com/multi-label-image-classification-with-pytorch-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35044e0b-5696-4bef-9f99-ffe005fa3de8",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "* Investigate effect of building size on the prediction quality? Other \"confounding\" factors.\n",
    "* See whether including the roads actually increases the prediction performance.\n",
    "* Investigate effects of imbalanced data / operator distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcc3c9-902c-4ef0-ba6d-779b08e7cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

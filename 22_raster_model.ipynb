{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f613cb6e-9dde-45a0-b730-a6883df55bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:45:25.563815Z",
     "iopub.status.busy": "2024-05-25T16:45:25.563475Z",
     "iopub.status.idle": "2024-05-25T16:45:38.288601Z",
     "shell.execute_reply": "2024-05-25T16:45:38.288127Z",
     "shell.execute_reply.started": "2024-05-25T16:45:25.563798Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from auxiliary.visualization import plot_raster\n",
    "from auxiliary.evaluation import calculate_conf_matrix, calculate_metrics\n",
    "from model_components.unet import *\n",
    "from model_components.resunet import *\n",
    "from model_components.attunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb5a9c3-c82b-49fb-8cce-dd26809ce1af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:45:38.412859Z",
     "iopub.status.busy": "2024-05-25T16:45:38.412471Z",
     "iopub.status.idle": "2024-05-25T16:45:38.550114Z",
     "shell.execute_reply": "2024-05-25T16:45:38.549483Z",
     "shell.execute_reply.started": "2024-05-25T16:45:38.412844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, then MPS, otherwise use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227e4d6e-8982-412a-adaf-57a6035fc166",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:45:38.551353Z",
     "iopub.status.busy": "2024-05-25T16:45:38.551205Z",
     "iopub.status.idle": "2024-05-25T16:45:38.562784Z",
     "shell.execute_reply": "2024-05-25T16:45:38.562399Z",
     "shell.execute_reply.started": "2024-05-25T16:45:38.551338Z"
    }
   },
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8f8d99-729f-4680-96a5-b7b6bfdc5408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:45:38.563608Z",
     "iopub.status.busy": "2024-05-25T16:45:38.563371Z",
     "iopub.status.idle": "2024-05-25T16:45:38.572493Z",
     "shell.execute_reply": "2024-05-25T16:45:38.572143Z",
     "shell.execute_reply.started": "2024-05-25T16:45:38.563594Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define DIN font for plots\n",
    "plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af7673-18d4-4d02-b65b-7b50406faed5",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61cb6f3-5047-481d-8652-5687a2a8ad60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:46:02.757175Z",
     "iopub.status.busy": "2024-05-25T16:46:02.756649Z",
     "iopub.status.idle": "2024-05-25T16:46:02.764854Z",
     "shell.execute_reply": "2024-05-25T16:46:02.764171Z",
     "shell.execute_reply.started": "2024-05-25T16:46:02.757153Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting up a Dataset object for DataLoader\n",
    "class BuildingRasterDataset(Dataset):\n",
    "    def __init__(self, path, n_channels=3, transform=None):\n",
    "        '''Stores the directory and filenames of the individual .npz files.'''\n",
    "        assert n_channels in (2, 3)\n",
    "        \n",
    "        # store directory of individual files\n",
    "        self.path = path\n",
    "        # get filenames of individual files\n",
    "        self.filenames = os.listdir(path)\n",
    "\n",
    "        # store the number of channels of the returned image\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        # store transformation\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Enables dataset length calculation.'''\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Enables indexing, returns uuid and block raster as features and generalization operators as label.'''\n",
    "        # get filename associated with given index\n",
    "        filename = self.filenames[index]\n",
    "\n",
    "        # load the file with the filename\n",
    "        sample = np.load(os.path.join(self.path, filename))\n",
    "\n",
    "        # extract the rasters\n",
    "        target = sample[\"target\"]\n",
    "        context = sample[\"context\"]\n",
    "        road = sample[\"road\"]\n",
    "\n",
    "        # stack the rasters according to n_channels\n",
    "        if self.n_channels == 3:\n",
    "            # stack the rasters to shape (3, n_pixels, n_pixels)\n",
    "            block = np.stack([target, context, road], axis=0)\n",
    "        elif self.n_channels == 2:\n",
    "            # combine context and road\n",
    "            context_road = context + road\n",
    "            # correct overlapping features\n",
    "            context_road[context_road > 1.0] = 1.0\n",
    "\n",
    "            # stack the rasters to shape (2, n_pixels, n_pixels)\n",
    "            block = np.stack([target, context_road], axis=0)\n",
    "\n",
    "        # convert rasters to tensor\n",
    "        block = torch.from_numpy(block).float()\n",
    "\n",
    "        # extract generalization operators and convert to tensors\n",
    "        eli = torch.from_numpy(sample[\"elimination\"]).float()\n",
    "        agg = torch.from_numpy(sample[\"aggregation\"]).float()\n",
    "        typ = torch.from_numpy(sample[\"typification\"]).float()\n",
    "        dis = torch.from_numpy(sample[\"displacement\"]).float()\n",
    "        enl = torch.from_numpy(sample[\"enlargement\"]).float()\n",
    "        sim = torch.from_numpy(sample[\"simplification\"]).float()\n",
    "\n",
    "        if self.transform:\n",
    "            block = self.transform(block)\n",
    "\n",
    "        return block, eli, agg, typ, dis, enl, sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f523-0e33-403f-bf0e-7a25aa95fa6c",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "\n",
    "1) Design model (input, output size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "     * Forward pass: Compute prediction\n",
    "     * Backward pass: Compute gradients\n",
    "     * Update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e688e5-9a9b-45ab-a10c-02a15ad36770",
   "metadata": {},
   "source": [
    "### Model design\n",
    "\n",
    "Stride refers to the number of positions that the convolutional kernel shifts at one step. Input channel size of one layer should always be equal to the output channel size of the previous layer.\n",
    "\n",
    "The application of convolution and pooling layers decreases the size of the image: The output after a convolution can be calculated according to the following formula, where $W$ is the input width, $F$ is the kernel size, $P$ is the padding and $S$ is the stride:\n",
    "\n",
    "$$\\frac{(W-F + 2 P)}{S} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc295f38-bae2-47cd-b2e3-9195931cdcff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:46:05.965674Z",
     "iopub.status.busy": "2024-05-25T16:46:05.965238Z",
     "iopub.status.idle": "2024-05-25T16:46:05.970642Z",
     "shell.execute_reply": "2024-05-25T16:46:05.970299Z",
     "shell.execute_reply.started": "2024-05-25T16:46:05.965657Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fully-connected layers with Global Average Pooling\n",
    "class FCGlobalPooling(nn.Module):\n",
    "    def __init__(self, n_last_out_channels):\n",
    "        super(FCGlobalPooling, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        \n",
    "        # Due to the global average pooling, the number of input features corresponds to the number of output channels of the last\n",
    "        # convolutional layers\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(), # flatten to reshape the tensor from 4D to 2D\n",
    "            nn.Linear(in_features=self.n_last_out_channels, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Fully-connected layers without Global Average Pooling\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, n_last_out_channels, image_size):\n",
    "        super(FC, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # the number of input features of first fully-connected layer are calculated by multiplying number of output channels of last \n",
    "        # convolutional layer by (image size after all pooling operations)^2\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=self.n_last_out_channels*self.image_size*self.image_size, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bb00b17-9dc9-44d0-b266-6e21f1da169a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:46:31.510205Z",
     "iopub.status.busy": "2024-05-25T16:46:31.509911Z",
     "iopub.status.idle": "2024-05-25T16:46:31.537430Z",
     "shell.execute_reply": "2024-05-25T16:46:31.537069Z",
     "shell.execute_reply.started": "2024-05-25T16:46:31.510188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 162,374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc): FCGlobalPooling(\n",
       "    (fc): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://amaarora.github.io/posts/2020-09-13-unet.html\n",
    "\n",
    "# conventional, simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=128)\n",
    "        #self.fc = FC(n_last_out_channels=128, image_size=32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input dimension = 256\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # input dimension = 128\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # input dimension = 64\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # input dimension = 32\n",
    "        x = self.fc(x) # No sigmoid function necessary, since BCEWithLogitsLoss applies sigmoid internally for loss computation\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for U-net adapted from https://github.com/milesial/Pytorch-UNet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, 1))\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # decoding + concatenation\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        x = self.fc(logits)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for Residual U-net adapted from https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(3, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        #self.sigmoid = nn.Sigmoid() # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(inputs)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(inputs)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        #output = self.sigmoid(output) # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Code for Attention U-net adapted from https://github.com/LeeJunHyun/Image_Segmentation\n",
    "class AttUNet(nn.Module):\n",
    "    def __init__(self,n_channels):\n",
    "        super(AttUNet,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=n_channels,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,1,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification        \n",
    "        output = self.fc(d1)\n",
    "\n",
    "        return output\n",
    "\n",
    "n_channels = 3\n",
    "\n",
    "# Creating model and moving to device\n",
    "model = CNN(n_channels=n_channels)\n",
    "#model = UNet(n_channels=n_channels)\n",
    "#model = ResUNet(n_channels=n_channels)\n",
    "#model = AttUNet(n_channels=n_channels)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {total_params:,}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52663f75-0732-4f3f-b55e-3a68eee493cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:46:35.870026Z",
     "iopub.status.busy": "2024-05-25T16:46:35.869663Z",
     "iopub.status.idle": "2024-05-25T16:46:35.873205Z",
     "shell.execute_reply": "2024-05-25T16:46:35.872752Z",
     "shell.execute_reply.started": "2024-05-25T16:46:35.870008Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary cross-entropy loss, applies a sigmoid internally and takes logits as input\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9f7ae-8c3a-434d-bb6e-4300eb067628",
   "metadata": {},
   "source": [
    "### Loss and activation function\n",
    "\n",
    "Softmax is a common activation function, (binary) cross-Entropy is a common loss function for multiclass classification problems, sigmoid is commonly used for binary classification problems. When using the Pytorch implementation: no softmax in the last layer, class labels not one-hot encoded and no softmax. BCELoss requires an activation function at the end! Sigmoid are usually the last layers in binary classification probems.\n",
    "\n",
    "If you don't know which activation function to use, just use ReLU, Leaky ReLU tries to adress vanishing gradient problem. Multiplies input with small negative numbers, as normal ReLU may cause many gradients to become zero, which means that the weights will never be updated. Whenever weights are not updated during training, use Leaky ReLU.\n",
    "\n",
    "I am dealing with a multilabel (for each generalization operator), binary (operator present or absent) classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2f78-e07d-4922-b9f3-b81ba80b9385",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ac2819-465a-4faa-a8e7-5e2cde507c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T16:47:46.566171Z",
     "iopub.status.busy": "2024-05-25T16:47:46.565737Z",
     "iopub.status.idle": "2024-05-25T17:01:15.124156Z",
     "shell.execute_reply": "2024-05-25T17:01:15.123700Z",
     "shell.execute_reply.started": "2024-05-25T16:47:46.566151Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10,000 samples in the dataset.\n",
      "epoch 1/10, step 62/625\n",
      "epoch 1/10, step 124/625\n",
      "epoch 1/10, step 186/625\n",
      "epoch 1/10, step 248/625\n",
      "epoch 1/10, step 310/625\n",
      "epoch 1/10, step 372/625\n",
      "epoch 1/10, step 434/625\n",
      "epoch 1/10, step 496/625\n",
      "epoch 1/10, step 558/625\n",
      "epoch 1/10, step 620/625\n",
      "epoch 1 finished, loss: 0.506\n",
      "epoch 2/10, step 62/625\n",
      "epoch 2/10, step 124/625\n",
      "epoch 2/10, step 186/625\n",
      "epoch 2/10, step 248/625\n",
      "epoch 2/10, step 310/625\n",
      "epoch 2/10, step 372/625\n",
      "epoch 2/10, step 434/625\n",
      "epoch 2/10, step 496/625\n",
      "epoch 2/10, step 558/625\n",
      "epoch 2/10, step 620/625\n",
      "epoch 2 finished, loss: 0.490\n",
      "epoch 3/10, step 62/625\n",
      "epoch 3/10, step 124/625\n",
      "epoch 3/10, step 186/625\n",
      "epoch 3/10, step 248/625\n",
      "epoch 3/10, step 310/625\n",
      "epoch 3/10, step 372/625\n",
      "epoch 3/10, step 434/625\n",
      "epoch 3/10, step 496/625\n",
      "epoch 3/10, step 558/625\n",
      "epoch 3/10, step 620/625\n",
      "epoch 3 finished, loss: 0.481\n",
      "epoch 4/10, step 62/625\n",
      "epoch 4/10, step 124/625\n",
      "epoch 4/10, step 186/625\n",
      "epoch 4/10, step 248/625\n",
      "epoch 4/10, step 310/625\n",
      "epoch 4/10, step 372/625\n",
      "epoch 4/10, step 434/625\n",
      "epoch 4/10, step 496/625\n",
      "epoch 4/10, step 558/625\n",
      "epoch 4/10, step 620/625\n",
      "epoch 4 finished, loss: 0.463\n",
      "epoch 5/10, step 62/625\n",
      "epoch 5/10, step 124/625\n",
      "epoch 5/10, step 186/625\n",
      "epoch 5/10, step 248/625\n",
      "epoch 5/10, step 310/625\n",
      "epoch 5/10, step 372/625\n",
      "epoch 5/10, step 434/625\n",
      "epoch 5/10, step 496/625\n",
      "epoch 5/10, step 558/625\n",
      "epoch 5/10, step 620/625\n",
      "epoch 5 finished, loss: 0.455\n",
      "epoch 6/10, step 62/625\n",
      "epoch 6/10, step 124/625\n",
      "epoch 6/10, step 186/625\n",
      "epoch 6/10, step 248/625\n",
      "epoch 6/10, step 310/625\n",
      "epoch 6/10, step 372/625\n",
      "epoch 6/10, step 434/625\n",
      "epoch 6/10, step 496/625\n",
      "epoch 6/10, step 558/625\n",
      "epoch 6/10, step 620/625\n",
      "epoch 6 finished, loss: 0.452\n",
      "epoch 7/10, step 62/625\n",
      "epoch 7/10, step 124/625\n",
      "epoch 7/10, step 186/625\n",
      "epoch 7/10, step 248/625\n",
      "epoch 7/10, step 310/625\n",
      "epoch 7/10, step 372/625\n",
      "epoch 7/10, step 434/625\n",
      "epoch 7/10, step 496/625\n",
      "epoch 7/10, step 558/625\n",
      "epoch 7/10, step 620/625\n",
      "epoch 7 finished, loss: 0.451\n",
      "epoch 8/10, step 62/625\n",
      "epoch 8/10, step 124/625\n",
      "epoch 8/10, step 186/625\n",
      "epoch 8/10, step 248/625\n",
      "epoch 8/10, step 310/625\n",
      "epoch 8/10, step 372/625\n",
      "epoch 8/10, step 434/625\n",
      "epoch 8/10, step 496/625\n",
      "epoch 8/10, step 558/625\n",
      "epoch 8/10, step 620/625\n",
      "epoch 8 finished, loss: 0.448\n",
      "epoch 9/10, step 62/625\n",
      "epoch 9/10, step 124/625\n",
      "epoch 9/10, step 186/625\n",
      "epoch 9/10, step 248/625\n",
      "epoch 9/10, step 310/625\n",
      "epoch 9/10, step 372/625\n",
      "epoch 9/10, step 434/625\n",
      "epoch 9/10, step 496/625\n",
      "epoch 9/10, step 558/625\n",
      "epoch 9/10, step 620/625\n",
      "epoch 9 finished, loss: 0.448\n",
      "epoch 10/10, step 62/625\n",
      "epoch 10/10, step 124/625\n",
      "epoch 10/10, step 186/625\n",
      "epoch 10/10, step 248/625\n",
      "epoch 10/10, step 310/625\n",
      "epoch 10/10, step 372/625\n",
      "epoch 10/10, step 434/625\n",
      "epoch 10/10, step 496/625\n",
      "epoch 10/10, step 558/625\n",
      "epoch 10/10, step 620/625\n",
      "epoch 10 finished, loss: 0.445\n",
      "Training time: 808.476 seconds\n"
     ]
    }
   ],
   "source": [
    "# if CUDA is available, use the cluster path, else local path\n",
    "if torch.cuda.is_available():\n",
    "    path_to_data = \"../scratch/raster\"\n",
    "else:\n",
    "    path_to_data = \"../data.nosync/raster\"\n",
    "\n",
    "# number of epochs and batch size\n",
    "num_epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "# composing various random transforms that should be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees=(0,360)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)])\n",
    "\n",
    "# construct DataLoader\n",
    "train_dataset = BuildingRasterDataset(path_to_data, n_channels=n_channels, transform=transform)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(f\"{len(train_dataset):,} samples in the dataset.\")\n",
    "\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "    \n",
    "# saving the losses from every epoch\n",
    "train_losses = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "    \n",
    "for epoch in range(num_epochs):\n",
    "    # tracking loss per epoch\n",
    "    train_running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for i, (block, eli, agg, typ, dis, enl, sim) in enumerate(train_dataloader): \n",
    "        n_batches += 1\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "    \n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "    \n",
    "        # empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # forward pass\n",
    "        pred_operators = model(block) # compute predictions, calls forward method under the hood\n",
    "        loss = criterion(pred_operators, operators) # calculate loss\n",
    "        train_running_loss += loss.item() # tracking running loss to keep track of the loss for every epoch\n",
    "    \n",
    "        # backward pass\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update the parameters\n",
    "    \n",
    "        # print information every few batches\n",
    "        if not (i + 1) % (n_iterations // 10):\n",
    "            print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}\")\n",
    "    \n",
    "    # print information at the end of each epoch\n",
    "    train_loss_epoch = train_running_loss / n_batches\n",
    "    train_losses.append(train_loss_epoch)\n",
    "    print(f\"epoch {epoch+1} finished, loss: {train_loss_epoch:.3f}\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Training time: {end_time - start_time:.3f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238cd359-67bd-41d2-8494-4034d198550f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T17:01:55.281133Z",
     "iopub.status.busy": "2024-05-25T17:01:55.280927Z",
     "iopub.status.idle": "2024-05-25T17:01:55.671371Z",
     "shell.execute_reply": "2024-05-25T17:01:55.670875Z",
     "shell.execute_reply.started": "2024-05-25T17:01:55.281118Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n",
      "findfont: Font family 'DIN Alternate' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, color=\"orange\", label=\"training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe3dd0-951e-48fc-aca2-4b95f40d966f",
   "metadata": {},
   "source": [
    "### Evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3d0f803-c2b1-4bc8-a2e7-6ba22ef76dec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-25T17:02:48.137965Z",
     "iopub.status.busy": "2024-05-25T17:02:48.137628Z",
     "iopub.status.idle": "2024-05-25T17:03:13.995098Z",
     "shell.execute_reply": "2024-05-25T17:03:13.994712Z",
     "shell.execute_reply.started": "2024-05-25T17:02:48.137949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIMINATION: Accuracy: 0.903, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "AGGREGATION: Accuracy: 0.736, Precision: 0.763, Recall: 0.749, F1-score: 0.756\n",
      "TYPIFICATION: Accuracy: 0.766, Precision: 0.574, Recall: 0.060, F1-score: 0.109\n",
      "DISPLACEMENT: Accuracy: 0.814, Precision: 0.830, Recall: 0.968, F1-score: 0.894\n",
      "ENLARGEMENT: Accuracy: 0.775, Precision: 0.775, Recall: 0.987, F1-score: 0.868\n",
      "SIMPLIFICATION: Accuracy: 0.814, Precision: 0.649, Recall: 0.110, F1-score: 0.188\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BuildingRasterDataset(path_to_data, n_channels=n_channels)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# stores the confusion matrices for every operator\n",
    "metrics = {}\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    metrics[operator_name] = {}\n",
    "    metrics[operator_name][\"tp\"] = 0\n",
    "    metrics[operator_name][\"fp\"] = 0\n",
    "    metrics[operator_name][\"tn\"] = 0\n",
    "    metrics[operator_name][\"fn\"] = 0\n",
    "\n",
    "# prediction evaluations should not be part of the computational graph, gradients should not be tracked\n",
    "with torch.no_grad():\n",
    "    for block, eli, agg, typ, dis, enl, sim in test_dataloader:\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # prediction on the trained model results in logits, sigmoid needs to be applied to obtain probabilities\n",
    "        pred_operators = torch.sigmoid(model(block))\n",
    "        pred_operators_labels = (pred_operators > 0.5).float()  # thresholding\n",
    "\n",
    "        # calculating metrics for the individual operators\n",
    "        for i, operator_name in enumerate(operator_order):\n",
    "            operator = operators[:, i]\n",
    "            pred_operator = pred_operators_labels[:, i]\n",
    "\n",
    "            tp, fp, tn, fn = calculate_conf_matrix(operator, pred_operator)\n",
    "\n",
    "            metrics[operator_name][\"tp\"] += tp\n",
    "            metrics[operator_name][\"fp\"] += fp\n",
    "            metrics[operator_name][\"tn\"] += tn\n",
    "            metrics[operator_name][\"fn\"] += fn\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    accuracy, precision, recall, f1_score = calculate_metrics(metrics[operator_name][\"tp\"],\n",
    "                                                              metrics[operator_name][\"fp\"],\n",
    "                                                              metrics[operator_name][\"tn\"],\n",
    "                                                              metrics[operator_name][\"fn\"])\n",
    "    \n",
    "    print(f\"{operator_name.upper()}: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f963fc6-62a7-4512-99dc-4277f8bf2b01",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "https://debuggercafe.com/multi-label-image-classification-with-pytorch-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35044e0b-5696-4bef-9f99-ffe005fa3de8",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "* Investigate effect of building size on the prediction quality? Other \"confounding\" factors.\n",
    "* See whether including the roads actually increases the prediction performance.\n",
    "* Investigate effects of imbalanced data / operator distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcc3c9-902c-4ef0-ba6d-779b08e7cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genops",
   "language": "python",
   "name": "genops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

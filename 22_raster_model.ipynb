{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f613cb6e-9dde-45a0-b730-a6883df55bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from auxiliary.visualization import plot_raster\n",
    "from auxiliary.evaluation import calculate_conf_matrix, calculate_metrics\n",
    "from model_components.unet import *\n",
    "from model_components.resunet import *\n",
    "from model_components.attunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb5a9c3-c82b-49fb-8cce-dd26809ce1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, then MPS, otherwise use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227e4d6e-8982-412a-adaf-57a6035fc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8f8d99-729f-4680-96a5-b7b6bfdc5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots\n",
    "plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af7673-18d4-4d02-b65b-7b50406faed5",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dda95da-6983-416f-b00f-fbe4bd018f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a Dataset object for DataLoader\n",
    "class BuildingRasterDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        '''Loads and unpacks the data from the compressed .npz format'''\n",
    "        data = np.load(path)\n",
    "        \n",
    "        # Read raster maps\n",
    "        blocks_rasterized = data[\"blocks\"].copy()\n",
    "        # Read generalization operators\n",
    "        targets_eli = data[\"elimination\"].copy()\n",
    "        targets_agg = data[\"aggregation\"].copy()\n",
    "        targets_typ = data[\"typification\"].copy()\n",
    "        targets_dis = data[\"displacement\"].copy()\n",
    "        targets_enl = data[\"enlargement\"].copy()\n",
    "        targets_sim = data[\"simplification\"].copy()\n",
    "        \n",
    "        # Read target uuids\n",
    "        self.uuid = data[\"uuids\"].copy()\n",
    "\n",
    "        # Check whether all parts have the same dimensionality\n",
    "        assert blocks_rasterized.shape[0] == self.uuid.shape[0] == targets_eli.shape[0] == targets_agg.shape[0] == targets_typ.shape[0] \\\n",
    "        == targets_dis.shape[0] == targets_enl.shape[0] == targets_sim.shape[0]\n",
    "\n",
    "        # Convert numpy array to tensor with shape (n_samples, 3, height, width)\n",
    "        self.block = torch.from_numpy(blocks_rasterized).float()\n",
    "        \n",
    "        # Convert generalization operators to tensor\n",
    "        self.elimination = torch.from_numpy(targets_eli).float()\n",
    "        self.aggregation = torch.from_numpy(targets_agg).float()\n",
    "        self.typification = torch.from_numpy(targets_typ).float()\n",
    "        self.displacement = torch.from_numpy(targets_dis).float()\n",
    "        self.enlargement = torch.from_numpy(targets_enl).float()\n",
    "        self.simplification = torch.from_numpy(targets_sim).float()\n",
    "\n",
    "        # store transformation\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Enables dataset length calculation'''\n",
    "        return self.uuid.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Enables indexing, returns uuid and block raster as features and generalization operators as label'''\n",
    "        uuid = self.uuid[index]\n",
    "        block = self.block[index]\n",
    "        eli = self.elimination[index]\n",
    "        agg = self.aggregation[index]\n",
    "        typ = self.typification[index]\n",
    "        dis = self.displacement[index]\n",
    "        enl = self.enlargement[index]\n",
    "        sim = self.simplification[index]\n",
    "\n",
    "        if self.transform:\n",
    "            block = self.transform(block)\n",
    "\n",
    "        return uuid, block, eli, agg, typ, dis, enl, sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f523-0e33-403f-bf0e-7a25aa95fa6c",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "\n",
    "1) Design model (input, output size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "     * Forward pass: Compute prediction\n",
    "     * Backward pass: Compute gradients\n",
    "     * Update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e688e5-9a9b-45ab-a10c-02a15ad36770",
   "metadata": {},
   "source": [
    "### Model design\n",
    "\n",
    "Stride refers to the number of positions that the convolutional kernel shifts at one step. Input channel size of one layer should always be equal to the output channel size of the previous layer.\n",
    "\n",
    "The application of convolution and pooling layers decreases the size of the image: The output after a convolution can be calculated according to the following formula, where $W$ is the input width, $F$ is the kernel size, $P$ is the padding and $S$ is the stride:\n",
    "\n",
    "$$\\frac{(W-F + 2 P)}{S} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc295f38-bae2-47cd-b2e3-9195931cdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected layers with Global Average Pooling\n",
    "class FCGlobalPooling(nn.Module):\n",
    "    def __init__(self, n_last_out_channels):\n",
    "        super(FCGlobalPooling, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        \n",
    "        # Due to the global average pooling, the number of input features corresponds to the number of output channels of the last\n",
    "        # convolutional layers\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(), # flatten to reshape the tensor from 4D to 2D\n",
    "            nn.Linear(in_features=self.n_last_out_channels, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Fully-connected layers without Global Average Pooling\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, n_last_out_channels, image_size):\n",
    "        super(FC, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # the number of input features of first fully-connected layer are calculated by multiplying number of output channels of last \n",
    "        # convolutional layer by (image size after all pooling operations)^2\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=self.n_last_out_channels*self.image_size*self.image_size, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb00b17-9dc9-44d0-b266-6e21f1da169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 34,882,675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AttUNet(\n",
       "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att5): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att4): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att3): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att2): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc): FCGlobalPooling(\n",
       "    (fc): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=1, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://amaarora.github.io/posts/2020-09-13-unet.html\n",
    "\n",
    "# conventional, simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        #self.fc = FCGlobalPooling(n_last_out_channels=128)\n",
    "        self.fc = FC(n_last_out_channels=128, image_size=32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input dimension = 256\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # input dimension = 128\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # input dimension = 64\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # input dimension = 32\n",
    "        x = self.fc(x) # No sigmoid function necessary, since BCEWithLogitsLoss applies sigmoid internally for loss computation\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for U-net adapted from https://github.com/milesial/Pytorch-UNet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, 1))\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # decoding + concatenation\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        x = self.fc(logits)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for Residual U-net adapted from https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(3, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        #self.sigmoid = nn.Sigmoid() # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(inputs)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(inputs)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        #output = self.sigmoid(output) # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Code for Attention U-net adapted from https://github.com/LeeJunHyun/Image_Segmentation\n",
    "class AttUNet(nn.Module):\n",
    "    def __init__(self,n_channels):\n",
    "        super(AttUNet,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=n_channels,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,1,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification        \n",
    "        output = self.fc(d1)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Creating model and moving to device\n",
    "#model = CNN(n_channels=3)\n",
    "#model = UNet(n_channels=3)\n",
    "#model = ResUNet(n_channels=3)\n",
    "model = AttUNet(n_channels=3)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {total_params:,}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52663f75-0732-4f3f-b55e-3a68eee493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary cross-entropy loss, applies a sigmoid internally and takes logits as input\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9f7ae-8c3a-434d-bb6e-4300eb067628",
   "metadata": {},
   "source": [
    "### Loss and activation function\n",
    "\n",
    "Softmax is a common activation function, (binary) cross-Entropy is a common loss function for multiclass classification problems, sigmoid is commonly used for binary classification problems. When using the Pytorch implementation: no softmax in the last layer, class labels not one-hot encoded and no softmax. BCELoss requires an activation function at the end! Sigmoid are usually the last layers in binary classification probems.\n",
    "\n",
    "If you don't know which activation function to use, just use ReLU, Leaky ReLU tries to adress vanishing gradient problem. Multiplies input with small negative numbers, as normal ReLU may cause many gradients to become zero, which means that the weights will never be updated. Whenever weights are not updated during training, use Leaky ReLU.\n",
    "\n",
    "I am dealing with a multilabel (for each generalization operator), binary (operator present or absent) classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2f78-e07d-4922-b9f3-b81ba80b9385",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ac2819-465a-4faa-a8e7-5e2cde507c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, step 5/25\n",
      "epoch 1/10, step 10/25\n",
      "epoch 1/10, step 15/25\n",
      "epoch 1/10, step 20/25\n",
      "epoch 1/10, step 25/25\n",
      "epoch 1 finished, loss: 0.540\n",
      "epoch 2/10, step 5/25\n",
      "epoch 2/10, step 10/25\n",
      "epoch 2/10, step 15/25\n",
      "epoch 2/10, step 20/25\n",
      "epoch 2/10, step 25/25\n",
      "epoch 2 finished, loss: 0.474\n",
      "epoch 3/10, step 5/25\n",
      "epoch 3/10, step 10/25\n",
      "epoch 3/10, step 15/25\n",
      "epoch 3/10, step 20/25\n",
      "epoch 3/10, step 25/25\n",
      "epoch 3 finished, loss: 0.474\n",
      "epoch 4/10, step 5/25\n",
      "epoch 4/10, step 10/25\n",
      "epoch 4/10, step 15/25\n",
      "epoch 4/10, step 20/25\n",
      "epoch 4/10, step 25/25\n",
      "epoch 4 finished, loss: 0.474\n",
      "epoch 5/10, step 5/25\n",
      "epoch 5/10, step 10/25\n",
      "epoch 5/10, step 15/25\n",
      "epoch 5/10, step 20/25\n",
      "epoch 5/10, step 25/25\n",
      "epoch 5 finished, loss: 0.471\n",
      "epoch 6/10, step 5/25\n",
      "epoch 6/10, step 10/25\n",
      "epoch 6/10, step 15/25\n",
      "epoch 6/10, step 20/25\n",
      "epoch 6/10, step 25/25\n",
      "epoch 6 finished, loss: 0.485\n",
      "epoch 7/10, step 5/25\n",
      "epoch 7/10, step 10/25\n",
      "epoch 7/10, step 15/25\n",
      "epoch 7/10, step 20/25\n",
      "epoch 7/10, step 25/25\n",
      "epoch 7 finished, loss: 0.472\n",
      "epoch 8/10, step 5/25\n",
      "epoch 8/10, step 10/25\n",
      "epoch 8/10, step 15/25\n",
      "epoch 8/10, step 20/25\n",
      "epoch 8/10, step 25/25\n",
      "epoch 8 finished, loss: 0.485\n",
      "epoch 9/10, step 5/25\n",
      "epoch 9/10, step 10/25\n",
      "epoch 9/10, step 15/25\n",
      "epoch 9/10, step 20/25\n",
      "epoch 9/10, step 25/25\n",
      "epoch 9 finished, loss: 0.473\n",
      "epoch 10/10, step 5/25\n",
      "epoch 10/10, step 10/25\n",
      "epoch 10/10, step 15/25\n",
      "epoch 10/10, step 20/25\n",
      "epoch 10/10, step 25/25\n",
      "epoch 10 finished, loss: 0.474\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "data = \"../data.nosync/raster_training_data.npz\"\n",
    "\n",
    "# composing various random transforms that should be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees=(0,360)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)])\n",
    "\n",
    "train_dataset = BuildingRasterDataset(data, transform=transform)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "\n",
    "# saving the losses from every epoch\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # tracking loss per epoch\n",
    "    train_running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for i, (uuid, block, eli, agg, typ, dis, enl, sim) in enumerate(train_dataloader): \n",
    "        n_batches += 1\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        pred_operators = model(block) # compute predictions, calls forward method under the hood\n",
    "        loss = criterion(pred_operators, operators) # calculate loss\n",
    "        train_running_loss += loss.item() # tracking running loss to keep track of the loss for every epoch\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update the parameters\n",
    "\n",
    "        # print information every few batches\n",
    "        if not (i + 1) % 5:\n",
    "            print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}\")\n",
    "\n",
    "    # print information at the end of each epoch\n",
    "    train_loss_epoch = train_running_loss / n_batches\n",
    "    train_losses.append(train_loss_epoch)\n",
    "    print(f\"epoch {epoch+1} finished, loss: {train_loss_epoch:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238cd359-67bd-41d2-8494-4034d198550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, color=\"orange\", label=\"training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe3dd0-951e-48fc-aca2-4b95f40d966f",
   "metadata": {},
   "source": [
    "### Evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d0f803-c2b1-4bc8-a2e7-6ba22ef76dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIMINATION: Accuracy: 0.660, Precision: 0.660, Recall: 1.000, F1-score: 0.795\n",
      "AGGREGATION: Accuracy: 0.790, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "TYPIFICATION: Accuracy: 0.920, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "DISPLACEMENT: Accuracy: 0.690, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "ENLARGEMENT: Accuracy: 0.680, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "SIMPLIFICATION: Accuracy: 0.970, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BuildingRasterDataset(data)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# stores the confusion matrices for every operator\n",
    "metrics = {}\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    metrics[operator_name] = {}\n",
    "    metrics[operator_name][\"tp\"] = 0\n",
    "    metrics[operator_name][\"fp\"] = 0\n",
    "    metrics[operator_name][\"tn\"] = 0\n",
    "    metrics[operator_name][\"fn\"] = 0\n",
    "\n",
    "# prediction evaluations should not be part of the computational graph, gradients should not be tracked\n",
    "with torch.no_grad():\n",
    "    for uuid, block, eli, agg, typ, dis, enl, sim in test_dataloader:\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # prediction on the trained model results in logits, sigmoid needs to be applied to obtain probabilities\n",
    "        pred_operators = torch.sigmoid(model(block))\n",
    "        pred_operators_labels = (pred_operators > 0.5).float()  # thresholding\n",
    "\n",
    "        # calculating metrics for the individual operators\n",
    "        for i, operator_name in enumerate(operator_order):\n",
    "            operator = operators[:, i]\n",
    "            pred_operator = pred_operators_labels[:, i]\n",
    "\n",
    "            tp, fp, tn, fn = calculate_conf_matrix(operator, pred_operator)\n",
    "\n",
    "            metrics[operator_name][\"tp\"] += tp\n",
    "            metrics[operator_name][\"fp\"] += fp\n",
    "            metrics[operator_name][\"tn\"] += tn\n",
    "            metrics[operator_name][\"fn\"] += fn\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    accuracy, precision, recall, f1_score = calculate_metrics(metrics[operator_name][\"tp\"],\n",
    "                                                              metrics[operator_name][\"fp\"],\n",
    "                                                              metrics[operator_name][\"tn\"],\n",
    "                                                              metrics[operator_name][\"fn\"])\n",
    "    \n",
    "    print(f\"{operator_name.upper()}: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f963fc6-62a7-4512-99dc-4277f8bf2b01",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "https://debuggercafe.com/multi-label-image-classification-with-pytorch-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35044e0b-5696-4bef-9f99-ffe005fa3de8",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "* Investigate effect of building size on the prediction quality? Other \"confounding\" factors.\n",
    "* See whether including the roads actually increases the prediction performance.\n",
    "* Investigate effects of imbalanced data / operator distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcc3c9-902c-4ef0-ba6d-779b08e7cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

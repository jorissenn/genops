{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f613cb6e-9dde-45a0-b730-a6883df55bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from auxiliary.visualization import plot_raster\n",
    "from auxiliary.evaluation import calculate_conf_matrix, calculate_metrics\n",
    "from auxiliary.misc import send_notification\n",
    "from model_components.unet import *\n",
    "from model_components.resunet import *\n",
    "from model_components.attunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb5a9c3-c82b-49fb-8cce-dd26809ce1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, then MPS, otherwise use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    torch.cuda.empty_cache()\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227e4d6e-8982-412a-adaf-57a6035fc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8f8d99-729f-4680-96a5-b7b6bfdc5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots if working locally\n",
    "if not torch.cuda.is_available():\n",
    "    plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af7673-18d4-4d02-b65b-7b50406faed5",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f61cb6f3-5047-481d-8652-5687a2a8ad60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a Dataset object for DataLoader\n",
    "class BuildingRasterDataset(Dataset):\n",
    "    def __init__(self, path, n_channels=3, transform=None):\n",
    "        '''Stores the directory and filenames of the individual .npz files.'''\n",
    "        assert n_channels in (2, 3)\n",
    "        \n",
    "        # store directory of individual files\n",
    "        self.path = path\n",
    "        # get filenames of individual files\n",
    "        self.filenames = os.listdir(path)\n",
    "        # for testing purposes: take only the first 100 files\n",
    "        #self.filenames = os.listdir(path)[:1000]\n",
    "\n",
    "        # store the number of channels of the returned image\n",
    "        self.n_channels = n_channels\n",
    "\n",
    "        # store transformation\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Enables dataset length calculation.'''\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Enables indexing, returns uuid and block raster as features and generalization operators as label.'''\n",
    "        # get filename associated with given index\n",
    "        filename = self.filenames[index]\n",
    "\n",
    "        # load the file with the filename\n",
    "        sample = np.load(os.path.join(self.path, filename))\n",
    "\n",
    "        # extract the rasters\n",
    "        target = sample[\"target\"]\n",
    "        context = sample[\"context\"]\n",
    "        road = sample[\"road\"]\n",
    "\n",
    "        # stack the rasters according to n_channels\n",
    "        if self.n_channels == 3:\n",
    "            # stack the rasters to shape (3, n_pixels, n_pixels)\n",
    "            block = np.stack([target, context, road], axis=0)\n",
    "        elif self.n_channels == 2:\n",
    "            # combine context and road\n",
    "            context_road = context + road\n",
    "            # correct overlapping features\n",
    "            context_road[context_road > 1.0] = 1.0\n",
    "\n",
    "            # stack the rasters to shape (2, n_pixels, n_pixels)\n",
    "            block = np.stack([target, context_road], axis=0)\n",
    "\n",
    "        # convert rasters to tensor\n",
    "        block = torch.from_numpy(block).float()\n",
    "\n",
    "        # extract generalization operators and convert to tensors\n",
    "        eli = torch.from_numpy(sample[\"elimination\"]).float()\n",
    "        agg = torch.from_numpy(sample[\"aggregation\"]).float()\n",
    "        typ = torch.from_numpy(sample[\"typification\"]).float()\n",
    "        dis = torch.from_numpy(sample[\"displacement\"]).float()\n",
    "        enl = torch.from_numpy(sample[\"enlargement\"]).float()\n",
    "        sim = torch.from_numpy(sample[\"simplification\"]).float()\n",
    "\n",
    "        if self.transform:\n",
    "            block = self.transform(block)\n",
    "\n",
    "        return block, eli, agg, typ, dis, enl, sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f523-0e33-403f-bf0e-7a25aa95fa6c",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "\n",
    "1) Design model (input, output size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "     * Forward pass: Compute prediction\n",
    "     * Backward pass: Compute gradients\n",
    "     * Update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e688e5-9a9b-45ab-a10c-02a15ad36770",
   "metadata": {},
   "source": [
    "### Model design\n",
    "\n",
    "Stride refers to the number of positions that the convolutional kernel shifts at one step. Input channel size of one layer should always be equal to the output channel size of the previous layer.\n",
    "\n",
    "The application of convolution and pooling layers decreases the size of the image: The output after a convolution can be calculated according to the following formula, where $W$ is the input width, $F$ is the kernel size, $P$ is the padding and $S$ is the stride:\n",
    "\n",
    "$$\\frac{(W-F + 2 P)}{S} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc295f38-bae2-47cd-b2e3-9195931cdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification head with global average pooling and fully-connected layers\n",
    "class ClassificationHead(nn.Module):\n",
    "    def __init__(self, n_last_out_channels, n_classes):\n",
    "        super(ClassificationHead, self).__init__()\n",
    "        \n",
    "        # Due to the global average pooling, the number of input features corresponds to the number of output channels of the last\n",
    "        # convolutional layers\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)), # averaging output feature across spatial dimensions resulting in single feature vector\n",
    "            nn.Flatten(), # flatten to reshape the tensor from 4D to 2D\n",
    "            nn.Dropout(0.5), # reduce overfitting, rate typically between 0.3 and 0.5\n",
    "            nn.Linear(in_features=n_last_out_channels, out_features=512), # intermediate fully-connected layer for classification\n",
    "            nn.ReLU(inplace=True), # rectified linear unit activation function\n",
    "            nn.Linear(in_features=512, out_features=n_classes) # final fully-connected layer with one neuron per class to predicted\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb00b17-9dc9-44d0-b266-6e21f1da169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Residual U-Net with 8,222,530 parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResUNet(\n",
       "  (c11): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (br1): batchnorm_relu(\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (c12): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (c13): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (r2): residual_block(\n",
       "    (b1): batchnorm_relu(\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (c1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (b2): batchnorm_relu(\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (s): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (r3): residual_block(\n",
       "    (b1): batchnorm_relu(\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (c1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (b2): batchnorm_relu(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (s): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (r4): residual_block(\n",
       "    (b1): batchnorm_relu(\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (c1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    (b2): batchnorm_relu(\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (c2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (s): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
       "  )\n",
       "  (d1): decoder_block(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (r): residual_block(\n",
       "      (b1): batchnorm_relu(\n",
       "        (bn): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (c1): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (b2): batchnorm_relu(\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (c2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (s): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (d2): decoder_block(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (r): residual_block(\n",
       "      (b1): batchnorm_relu(\n",
       "        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (c1): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (b2): batchnorm_relu(\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (c2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (s): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (d3): decoder_block(\n",
       "    (upsample): Upsample(scale_factor=2.0, mode='bilinear')\n",
       "    (r): residual_block(\n",
       "      (b1): batchnorm_relu(\n",
       "        (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (c1): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (b2): batchnorm_relu(\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (c2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (s): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (output): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (classification_head): ClassificationHead(\n",
       "    (fc): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Dropout(p=0.5, inplace=False)\n",
       "      (3): Linear(in_features=1, out_features=512, bias=True)\n",
       "      (4): ReLU(inplace=True)\n",
       "      (5): Linear(in_features=512, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conventional, simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # appending classification head\n",
    "        self.classification_head = ClassificationHead(n_last_out_channels=128, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input dimension = 256\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # input dimension = 128\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # input dimension = 64\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # input dimension = 32\n",
    "        x = self.classification_head(x) # No sigmoid function necessary, since BCEWithLogitsLoss applies sigmoid internally for loss computation\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_n_parameters(self):\n",
    "        n_parameters = sum(p.numel() for p in self.parameters())\n",
    "        return n_parameters\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"CNN with {self.get_n_parameters():,} parameters\"\n",
    "\n",
    "# Code for U-net adapted from https://github.com/milesial/Pytorch-UNet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, 1))\n",
    "\n",
    "        # appending classification head\n",
    "        self.classification_head = ClassificationHead(n_last_out_channels=1, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # decoding + concatenation\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        # passing the segmentation output through the classification head\n",
    "        x = self.classification_head(logits)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_n_parameters(self):\n",
    "        n_parameters = sum(p.numel() for p in self.parameters())\n",
    "        return n_parameters\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"U-Net with {self.get_n_parameters():,} parameters\"\n",
    "\n",
    "# Code for Residual U-net adapted from https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(3, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        #self.sigmoid = nn.Sigmoid() # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # appending classification head\n",
    "        self.classification_head = ClassificationHead(n_last_out_channels=1, n_classes=n_classes)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(inputs)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(inputs)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        #output = self.sigmoid(output) # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # passing the segmentation output through the classification head\n",
    "        output = self.classification_head(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_n_parameters(self):\n",
    "        n_parameters = sum(p.numel() for p in self.parameters())\n",
    "        return n_parameters\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Residual U-Net with {self.get_n_parameters():,} parameters\"\n",
    "\n",
    "# Code for Attention U-net adapted from https://github.com/LeeJunHyun/Image_Segmentation\n",
    "class AttUNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(AttUNet,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=n_channels,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,1,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "        # appending classification head\n",
    "        self.classification_head = ClassificationHead(n_last_out_channels=1, n_classes=n_classes)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        # passing the segmentation output through the classification head\n",
    "        output = self.classification_head(d1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def get_n_parameters(self):\n",
    "        n_parameters = sum(p.numel() for p in self.parameters())\n",
    "        return n_parameters\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Attention U-Net with {self.get_n_parameters():,} parameters\"\n",
    "\n",
    "n_channels = 3\n",
    "n_classes = 1\n",
    "\n",
    "# Creating model and moving to device\n",
    "#model = CNN(n_channels=n_channels, n_classes=n_classes)\n",
    "#model = UNet(n_channels=n_channels, n_classes=n_classes)\n",
    "model = ResUNet(n_channels=n_channels, n_classes=n_classes)\n",
    "#model = AttUNet(n_channels=n_channels, n_classes=n_classes)\n",
    "\n",
    "print(f\"Using {model}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52663f75-0732-4f3f-b55e-3a68eee493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary cross-entropy loss, applies a sigmoid internally and takes logits as input\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9f7ae-8c3a-434d-bb6e-4300eb067628",
   "metadata": {},
   "source": [
    "### Loss and activation function\n",
    "\n",
    "Softmax is a common activation function, (binary) cross-Entropy is a common loss function for multiclass classification problems, sigmoid is commonly used for binary classification problems. When using the Pytorch implementation: no softmax in the last layer, class labels not one-hot encoded and no softmax. BCELoss requires an activation function at the end! Sigmoid are usually the last layers in binary classification probems.\n",
    "\n",
    "If you don't know which activation function to use, just use ReLU, Leaky ReLU tries to adress vanishing gradient problem. Multiplies input with small negative numbers, as normal ReLU may cause many gradients to become zero, which means that the weights will never be updated. Whenever weights are not updated during training, use Leaky ReLU.\n",
    "\n",
    "I am dealing with a multilabel (for each generalization operator), binary (operator present or absent) classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2f78-e07d-4922-b9f3-b81ba80b9385",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ac2819-465a-4faa-a8e7-5e2cde507c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000 samples in the training set.\n",
      "1,000 samples in the validation set.\n",
      "epoch 1/20, step 6/63\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 73\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# backward pass\u001b[39;00m\n\u001b[1;32m     72\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# backpropagation\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# update the parameters\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# print information every few batches\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m (n_iterations \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m10\u001b[39m):\n",
      "File \u001b[0;32m/Library/anaconda3/envs/genops/lib/python3.11/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/Library/anaconda3/envs/genops/lib/python3.11/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m/Library/anaconda3/envs/genops/lib/python3.11/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     adam(\n\u001b[1;32m    167\u001b[0m         params_with_grad,\n\u001b[1;32m    168\u001b[0m         grads,\n\u001b[1;32m    169\u001b[0m         exp_avgs,\n\u001b[1;32m    170\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    171\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    172\u001b[0m         state_steps,\n\u001b[1;32m    173\u001b[0m         amsgrad\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mamsgrad\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    174\u001b[0m         has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    175\u001b[0m         beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    176\u001b[0m         beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    177\u001b[0m         lr\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    178\u001b[0m         weight_decay\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    179\u001b[0m         eps\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    180\u001b[0m         maximize\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    181\u001b[0m         foreach\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforeach\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    182\u001b[0m         capturable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcapturable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    183\u001b[0m         differentiable\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    184\u001b[0m         fused\u001b[38;5;241m=\u001b[39mgroup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfused\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    185\u001b[0m         grad_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad_scale\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    186\u001b[0m         found_inf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    187\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/Library/anaconda3/envs/genops/lib/python3.11/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m func(params,\n\u001b[1;32m    317\u001b[0m      grads,\n\u001b[1;32m    318\u001b[0m      exp_avgs,\n\u001b[1;32m    319\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    320\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    321\u001b[0m      state_steps,\n\u001b[1;32m    322\u001b[0m      amsgrad\u001b[38;5;241m=\u001b[39mamsgrad,\n\u001b[1;32m    323\u001b[0m      has_complex\u001b[38;5;241m=\u001b[39mhas_complex,\n\u001b[1;32m    324\u001b[0m      beta1\u001b[38;5;241m=\u001b[39mbeta1,\n\u001b[1;32m    325\u001b[0m      beta2\u001b[38;5;241m=\u001b[39mbeta2,\n\u001b[1;32m    326\u001b[0m      lr\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m    327\u001b[0m      weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m    328\u001b[0m      eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    329\u001b[0m      maximize\u001b[38;5;241m=\u001b[39mmaximize,\n\u001b[1;32m    330\u001b[0m      capturable\u001b[38;5;241m=\u001b[39mcapturable,\n\u001b[1;32m    331\u001b[0m      differentiable\u001b[38;5;241m=\u001b[39mdifferentiable,\n\u001b[1;32m    332\u001b[0m      grad_scale\u001b[38;5;241m=\u001b[39mgrad_scale,\n\u001b[1;32m    333\u001b[0m      found_inf\u001b[38;5;241m=\u001b[39mfound_inf)\n",
      "File \u001b[0;32m/Library/anaconda3/envs/genops/lib/python3.11/site-packages/torch/optim/adam.py:391\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    388\u001b[0m     param \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(param)\n\u001b[1;32m    390\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m--> 391\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m    392\u001b[0m exp_avg_sq\u001b[38;5;241m.\u001b[39mmul_(beta2)\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if CUDA is available, use the cluster path, else local path\n",
    "if torch.cuda.is_available():\n",
    "    path_to_training_data = \"../scratch/raster/elimination/training\"\n",
    "    path_to_validation_data = \"../scratch/raster/elimination/validation\"\n",
    "else:\n",
    "    path_to_training_data = \"../data.nosync/raster/elimination/training\"\n",
    "    path_to_validation_data = \"../data.nosync/raster/elimination/validation\"\n",
    "\n",
    "# number of epochs and batch size\n",
    "n_epochs = 20\n",
    "batch_size = 16\n",
    "\n",
    "# composing various random transforms that should be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees=(0,360)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)])\n",
    "\n",
    "# construct training DataLoader\n",
    "training_set = BuildingRasterDataset(path_to_training_data, n_channels=n_channels, transform=transform)\n",
    "training_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# construct validation DataLoader (no transformations, no shuffling)\n",
    "validation_set = BuildingRasterDataset(path_to_validation_data, n_channels=n_channels, transform=None)\n",
    "validation_loader = DataLoader(dataset=validation_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f\"{len(training_set):,} samples in the training set.\")\n",
    "print(f\"{len(validation_set):,} samples in the validation set.\")\n",
    "\n",
    "total_samples = len(training_set)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "    \n",
    "# saving the losses from every epoch\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "    \n",
    "for epoch in range(n_epochs):\n",
    "    # tracking loss per epoch\n",
    "    training_running_loss = 0.0\n",
    "    n_training_batches = 0\n",
    "    validation_running_loss = 0.0\n",
    "    n_validation_batches = 0\n",
    "\n",
    "    # training phase\n",
    "    model.train()\n",
    "    for i, (block, eli, agg, typ, dis, enl, sim) in enumerate(training_loader):\n",
    "        n_training_batches += 1\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "    \n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        #operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "        operators = torch.stack([eli], dim=1).float()\n",
    "    \n",
    "        # empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # forward pass\n",
    "        pred_operators = model(block) # compute predictions, calls forward method under the hood\n",
    "        loss = criterion(pred_operators, operators) # calculate loss\n",
    "        training_running_loss += loss.item() # tracking running loss to keep track of the loss for every epoch\n",
    "    \n",
    "        # backward pass\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update the parameters\n",
    "    \n",
    "        # print information every few batches\n",
    "        if not (i + 1) % (n_iterations // 10):\n",
    "            print(f\"epoch {epoch+1}/{n_epochs}, step {i+1}/{n_iterations}\")\n",
    "\n",
    "    # validation phase\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for block, eli, agg, typ, dis, enl, sim in validation_loader:\n",
    "            n_validation_batches += 1\n",
    "            # moving the features to device\n",
    "            block = block.to(device)\n",
    "            eli = eli.to(device)\n",
    "            agg = agg.to(device)\n",
    "            typ = typ.to(device)\n",
    "            dis = dis.to(device)\n",
    "            enl = enl.to(device)\n",
    "            sim = sim.to(device)\n",
    "\n",
    "            # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "            #operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "            operators = torch.stack([eli], dim=1).float()\n",
    "\n",
    "            # prediction on the trained model results in logits\n",
    "            pred_operators_logits = model(block)\n",
    "            # calculate and store validation loss\n",
    "            loss = criterion(pred_operators_logits, operators)\n",
    "            validation_running_loss += loss.item()\n",
    "    \n",
    "    # print information at the end of each epoch\n",
    "    training_loss_epoch = training_running_loss / n_training_batches\n",
    "    training_losses.append(training_loss_epoch)\n",
    "    validation_loss_epoch = validation_running_loss / n_validation_batches\n",
    "    validation_losses.append(validation_loss_epoch)\n",
    "    \n",
    "    print(f\"epoch {epoch+1} finished, training loss: {training_loss_epoch:.3f}, validation loss: {validation_loss_epoch:.3f}\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Training time: {end_time - start_time:,.3f} seconds\")\n",
    "\n",
    "# if working on ScienceCluster, send notification that training has finished\n",
    "if torch.cuda.is_available():\n",
    "    send_notification(model=model, \n",
    "                      email_address=\"joris.senn@uzh.ch\", \n",
    "                      n_samples=len(training_set), \n",
    "                      n_epochs=n_epochs, \n",
    "                      batch_size=batch_size, \n",
    "                      time=end_time-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238cd359-67bd-41d2-8494-4034d198550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAINCAYAAAAJGy/3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB77UlEQVR4nO3deZyN5f/H8deZlTEzB0P2LTMykbImpE2FSiQhCYm0l6VSUkKEVLQnlSI/ldCiRfUlbSpK2fcl+zIzZsbs5/fHJ4MsM5iZ+yzv5+Mxj7nv48yZz6kzM+d9X9f1uVwej8eDiIiIiIiInFCQ0wWIiIiIiIh4OwUnERERERGRPCg4iYiIiIiI5EHBSUREREREJA8KTiIiIiIiInlQcBIREREREcmDgpOIiIiIiEgeFJxERERERETyoOAkIiIiIiKSB8eC0+zZs4mPjycqKoo2bdqwYcOGo/59/vz5uFyuYz4SExNz77N06VJcLhdvvPFGUZcvIiIiIiIBJMSJb7ps2TI6depEhw4d6NevHxMnTqRz584sWrTomPuOHj2aMmXK5J4XL14893jUqFFUqlSJHj16nNL3z8nJYdu2bURFReFyuU7/iYiIiIiIiE/zeDwcOHCAihUrEhR04nElR4LTvHnzCA4OZurUqYSEhBATE0P37t1JSEigZMmSR923S5cuVKtW7ZjHWLt2LR988AHjx48nLCzslL7/tm3bqFKlypk8BRERERER8SNbtmyhcuXKJ/x3R4JTQkICkZGRhITYty9VqhQAiYmJxwSn3r1788svv1CtWjVefvllWrZsCcAzzzxD6dKl6dOnT57fLz09nfT09Nxzj8cD2H+c6OjognhKIiIiIiLig5KSkqhSpQpRUVEnvZ8jwelUZGRkMGzYMN566y06d+7M+vXr2bt3L1OmTGHYsGHs2rWL6tWr8+mnn3LNNdcc9zFGjRrFsGHDjrk9OjpawUlERERERPJcwuO1wal+/fosXLiQ888/n8jISM4991zatGnDypUreeedd4iIiOCuu+5i//79eT7W4MGD6d+/f+75oVQpIiIiIiKSH14bnKKjo2nevHnueaVKlQBISUnhjTfeoF+/fng8HpKSkgBITk7G4/EcNymGh4cTHh5eNIWLiIiIiIjfcaQdudvtJjk5maysLIDcUaMjp839/vvv9OnThz179gCwd+9eALKzs0lNTWX8+PGULFmSevXqAdZEYvPmzUX5NEREREREJEA4MuLUqlUrHnroIbp160azZs2YOHEijRo1Ys+ePcycOZMePXpQpUoVpk+fzrp167juuuuYPHkytWrV4oILLuB///tf7mPt2LGDLl26MGrUKMqXL+/E0xERERERL5SdnU1mZqbTZYjDgoODCQkJOeNtiFyeQy3mitisWbMYPHgwW7dupXnz5rzyyissWLCAnj17kpycTIkSJZg/fz79+/dn+fLlNGzYkDfeeIP4+PijHmfTpk15Nof4r6SkJNxuN4mJiWoOISIiIuKHkpOT2bp1Kw691RUvExERQYUKFY67jVF+s4FjwclJCk4iIiIi/is7O5s1a9YQERFB2bJlz3ikQXyXx+MhIyOD3bt3k52dTVxc3DGb3OY3G3htcwgRERERkdORmZmJx+OhbNmyFC9e3OlyxGHFixcnNDSUTZs2kZGRQbFixU7rcRxpDiEiIiIiUtg00iSH/HeU6bQeowDqEBERERER8WsKTiIiIiIiInlQcBIRERER8XGbNm3C5XLx2Wef5Xnfd955B5fLRUpKSoF9//nz5+NyuVi2bFmBPaa3UXASEREREXFYSkoKLpeLd95557S+PiYmhkmTJlGvXr0879usWTMmTZpEeHj4aX2vQKWueiIiIiLi3zweyE515nsHR0ARNKmIjIykd+/e+bpvXFwccXFxhVyR/9GIk4iIiIj4t+xUmBHpzEc+A9u1114LQM+ePXnnnXdyp9M99NBDlC1blurVq7Np0yZ69uxJdHQ00dHRXH755blT4/47Va9GjRq0a9eOZs2aERUVRfv27dm/fz9w9FS9Q1/Xr18/YmNjKVWqFA8//HBuXX/99ReNGzcmOjqaDh06ULt2bXr16pXn80lKSuLmm28mIiKCUqVK8cgjj5CTkwPAjz/+SOPGjSlWrBjlypWjf//+HDhwAIBJkyZx9tlnEx4eTmxsLK+++qrXbGKs4CQiIiIi4rB7770XgF69etGsWbPc23/++Wcee+wx7r33XkqUKEFqaiqDBg3iqaeeYuPGjdx5550nfMyvvvqKK6+8kr59+zJnzhyGDx9+wvt+/vnn3HXXXbRs2ZIxY8YwZ84cAG6//XbWrVvH4MGDKVWqFKtWrcrX8xkwYACffvopgwcPpkePHowdO5bXXnsNgFtuuYXMzEzGjRtHjx49mD9/PqmpqWzatIm+ffvSoEEDxo0bx8UXX8yXX36ZG7icpql6IiIiIuLfgiPgpmTnvnc+XH311QBccsklxMXF8eOPPwIwdepUqlSpknu/GTNmsG/fPjIzM9myZQvvvffeCR/z5ptvZtiwYQAsWbKEpUuXnvC+I0aM4NZbb+Wee+4hOjqapUuX0q5dO5YuXcqjjz7K4MGDAfj+++/z9Xw++ugj7rnnHh5//HEAVq5cycyZM7nzzjtJTk6mYcOGXHnllZQrV44xY8YAsHz5cjweD40aNeLaa6/l9ttv96oNjDXi5CRPDmydDTu+cboSEREREf/lckFICWc+znB9U+nSpXOP//jjD84++2xiYmIoX74848ePP+loTExMzFHH2dnZed43LCyMqKio3Pump6dTqlSp3Pu53e581Z2UlESFChVyz8uVK5c7He+1117j559/pnbt2pQqVYoGDRqwbds2zj33XIYMGcKoUaM4++yziYqKonPnzl4z4qTg5KRVE2BBe1jykC1aFBERERE5gZEjR1KsWDFmzpzJF198QdeuXQv9e4aHh7N3797c84SEhHx9ndvtZtu2bbnnO3bsICoqCoCmTZuyZcsWEhMTWbx4MatXr+bNN98E4K677iIhIYHdu3czefJkZsyYwQ8//FBwT+gMaKqek6rfAn8Ohv2LYdd8KHep0xWJiIiIiANCQ0MJCgri22+/5fLLLz/ufaKjo9m/fz8bNmwgJCSExYsXF3pd559/Ps899xxBQUGsXr2adevWcfHFFx9zv4gIm5L40UcfUaVKFTp27MhLL71EREQEe/fuZd68ebz00kssWbKEiy66iLZt29KiRQs2bNjAwYMHiYmJ4eWXX2bAgAH06tWLWrVq8e233wJHj7o5ScHJScXKwNm9YM0rsGKsgpOIiIhIgAoLC+Phhx/mueeeO2FwGjlyJP/88w+PP/440dHRxMfHHzUaVBgmTZpE9+7deeaZZ7jyyitP2Ma8fv36tG/fnhEjRnD99dfz7LPPkp6ezujRoylWrBgDBgygb9++BAUF8eKLLzJhwgQ+++wzypYty8CBA7njjjtIS0tjy5YtTJs2jcmTJ3P22WfzzjvvUKdOnUJ9jvnl8nhLf78ilJSUhNvtJjExkejoaGeLObAWPqkFeKDt31DSO14YIiIiIr4qLS2NDRs2UKNGDYoVK+Z0OT4vJyeHoKAgcnJyqFKlCj169ODpp592uqxTcrLXRH6zgdY4OS0qFqp0sOOV452tRURERETkCOPHj6du3bqMGzeOTp06sX37dq655hqny3KEgpM3qD3QPm98Dw5ud7YWEREREZF/HdpAd8iQIaxcuZJp06bRvHlzp8tyhNY4eYOyF0GZZrDnR1g1ES7wraFPEREREfFPTZs25ZdffnG6DK+gESdvET/IPq95BTId2qBNRERERESOS8HJW1S6DqLiIDMB1k92uhoRERERETmCgpO3CAqG2v3teOVzkJPlbD0iIiIiIpJLwcmb1OgB4WUgZSNs+cjpakRERERE5F8KTt4kpDjUuseOV4yFwNtiS0RERETEKyk4eZu4uyC4GOz7HXYtcLoaERERERFBwcn7FCsLNXra8YqxjpYiIiIiIt7N5XLx0ksvAfDOO+/gcrlISUk57n3Lli3LsGHDTunxN23ahMvl4rPPPjvjWgvzMYuCgpM3qt0fcMG2zyBxudPViIiIiIgPaNasGZMmTSI8PPyMHufIgBUTE8OkSZOoV69eQZTo07QBrjeKjoPK7WHrx7ByPFw4yemKRERERHyXxwOpqc5874gIcLmK5FvFxcURFxdXoI8ZGRlJ7969C/QxfZVGnLxV/ED7vOFdOLjD2VpEREREfFlqKkRGOvORz8CWk5ND1apVueuuu3Jve+mllwgNDWX48OFUrFiR4sWLU69ePT7++OPjPsZ/p+rNnz+f+Ph4SpcuzZ133klmZmbufUePHn3cx+zVqxd79uzhySefZNiwYcdMq9u+fTtt2rShWLFilCtXjueeey73MWvUqEG7du1o1qwZUVFRtG/fnv379+f53DMzM7nvvvtwu925QS0tLQ2AlStXcskllxAREUHp0qXp1asXu3btAmDOnDnUqVOH8PBwqlSpwogRI8jIyMjXf+/ToeDkrco2gzIXQU4GrJ7odDUiIiIiUoiCgoK45ZZb+Oijj8jOzgZgxowZtG7dmpSUFDp06MC4ceMoU6YMXbp04eDBgyd9vJycHG655RZSU1MZPHgw27dvJzExEYDs7GwSEhKO+5i9evUiMjKSdu3a0a5du2Me99Zbb+WPP/7gqaeeonXr1vTv35+5c+fm/vtXX33FlVdeSd++fZkzZw7Dhw/P87mPGTOGV199lX79+vHggw8ybdo0nnjiCQDuuusuNm/ezOjRo7nnnntYvHgxe/fuJT09nc6dO1OuXDmeffZZrr/+er7++uujwmFB01Q9bxY/CL6/Ada8AucOhtBIpysSERER8T0REZCc7Nz3zqdbb72VUaNG8b///Y/4+HgWLlzIjBkz6NixI8nJyaSkpFC+fHm+++47Nm7cSHx8/Akfa/fu3WzdupVJkybRu3dv7r//ftxuNwDBwcGMHj36uI/ZsmVLihUrRoMGDahfvz6bNm3KfcykpCTmzZvHa6+9Rt++fQH45ZdfmDlzJm3atAHg5ptvzl0ftWTJEpYuXZrn8/7oo4+48cYbeeaZZ3JrnzlzJs888wzJyclUrlyZyy+/nPLly/PUU08BcODAATIyMqhbty6tW7emR48eREVF5fu/9enQiJM3q9QOImMhYz+sf8vpakRERER8k8sFJUo483EK65tq165N48aNmTFjBh9++CFut5tWrVpxySWXEBUVRfny5bnxxhsBG1E6mfT0dMAaPQCEhYURGWkX4Q8cOHBaj5mUlARAhQoVcm8rV64cBw4cyD2PiYk56vjQ6Flej3uixxw/fjy7du3ivPPOo2zZssTGxvL3338TFRXFiy++yPvvv09cXBxut5vLL7/8hB0FC4KCkzcLCob4/na88jnIyXK2HhEREREpVD169OCjjz5i6tSpdOnShffee49Fixbx9ttvM3fuXEaNGpWvxznUWW/nzp0AZGRk5IaRKVOmnNZjRkdHA7Bt27bc23bs2HHGIz1ut/uEjxkbG8uqVatITk5m+fLlZGdn566rat++Pbt372bfvn3MmzeP7777jpkzZ55RLSejqXrerkYPWDoUUjbAlplQ7SanKxIRERGRQtKlSxcefPBBFi1axAsvvMCaNWvIzMxkzZo1pKamMn/+/KPuHxERwfz583Onyh1StmxZKleuzLBhw9i/fz8LFy7MHYWKjo4+6WMWK1aMn3/+mVWrVlGsWLHc26Ojo7nyyit58sknSUxMZPny5axevZoXXnjhlJ5jxL/TF+fOnUvDhg3p2LEjTz75JI888gihoaFMmTKF+++/n23btlGnTh0aNGhA69at2bdvHzt37iQmJobPPvuM9u3bc/PNN1O/fn0WL14MHD3iVdAUnLxdSATE3Q1/D4MV46BqpyJraSkiIiIiRSsmJoZrrrmGZcuW0bRpUxo3bszPP//Myy+/TGZmJpdffvlR93/00UcZPXo0zZs3p2TJkrm3BwUF8f7773P33XczcuRI2rdvnztidPPNN5/0MQcPHszDDz/M9OnT6dmz51H/NmXKFPr27cvQoUMpVaoU48aNo3Xr1qf0HMuWLUu/fv148803ufLKKxk0aBB79uzh1VdfJScnh65du/LEE09QvHhx3nrrLUaPHs3QoUOJjo6mW7duPPHEE4SHhzNy5EgmTZrE9OnTqVSpEmPHjqVt27anVMupcHk8Hk+hPbqXSkpKwu12k5iYmPsC8mppu2B2NchOg1bz4ayWTlckIiIi4rXS0tLYsGEDNWrUOGrERALXyV4T+c0GWuPkC4qdZVP2wEadRERERESkSCk4+Yra/QEX/PMJJK5wuhoRERERkYCi4OQromtB5evteOV4Z2sREREREQkwCk6+JH6gfd4wBQ7ucLYWEREREZEAouDkS8o0g5imkJMBq19yuhoRERERrxaAPdDkBAritaDg5EtcLjh3kB2veRmyCm9nZBERERFfFRwcDNimryIAqampAISGhp72Y2gfJ19T6XqIrAnJ62DdW3DOPU5XJCIiIuJVQkJCiIiIYPfu3YSGhhIUpLGCQOXxeEhNTWXXrl2ULFkyN1SfDgUnXxMUbB32frvbmkTE3Wm3iYiIiAgALpeLChUqsGHDBjZt2uR0OeIFSpYsSfny5c/oMRScfNHZPeGvoZCyAbbOhKqdnK5IRERExKuEhYURFxen6XpCaGjoGY00HaLg5ItCIiDubvj7KVg+FqrcaOufRERERCRXUFAQxYoVc7oM8ROa8Omrat0NQeGw71fYvdDpakRERERE/JqCk68qdhac3cOOV4xzthYRERERET+n4OTLavcHXPDPHEhc6XQ1IiIiIiJ+S8HJl0WfA5Xb2fHK8c7WIiIiIiLixxScfF3tgfZ5wxQ4uNPZWkRERERE/JSCk68r2xxiLoScdFjzktPViIiIiIj4JQUnX+dyQfwgO179EmSlOFuPiIiIiIgfUnDyB5XbQ+TZkLEP1r/tdDUiIiIiIn5HwckfBAX/22EPaxKRk+1sPSIiIiIifkbByV+c3RPCSkPyetg6y+lqRERERET8ioKTvwgpAbXutuMVY8HjcbYeERERERE/ouDkT+LuhqBw2PsL7P7B6WpERERERPyGgpM/KV4OatxqxyvHOVuLiIiIiIgfUXDyN4eaRGydA0mrnK1FRERERMRPKDj5G3dtqNQO8FiHPREREREROWMKTv4ofqB9Xv8OpO1ythYRERERET+g4OSPyraAmCaQkw6rX3K6GhERERERn6fg5I9cLogfZMdrXoKsVGfrERERERHxcQpO/qpyByhRA9L3wvq3na5GRERERMSnKTj5q6Dgwx32Vo6HnGxn6xERERER8WEKTv6sZi8IKw3J6+Cf2U5XIyIiIiLisxSc/FlICYi7y46XjwWPx9l6RERERER8lIKTv6t1DwSFwd6fYc+PTlcjIiIiIuKTFJz8XfFyUONWO14xztlaRERERER8lIJTIDjUJGLrbEha7WwtIiIiIiI+SMEpELjjodJ1gMc67ImIiIiIyClRcAoU8QPt84Z3IG2Xs7WIiIiIiPgYBadAUfZiKN0YstNg9ctOVyMiIiIi4lMUnAKFy3V41GnNS5CV6mw9IiIiIiI+RMEpkFS5AUrUgPQ9NmVPRERERETyRcEpkASFQO0H7XjFeMjJdrYeEREREREfoeAUaM7uBWGlIHkt/DPH6WpERERERHyCglOgCY2EuLvseMVYZ2sREREREfERCk6BqNY9EBQGe36C3T86XY2IiIiIiNdTcApExctDje52vGKcs7WIiIiIiPgABadAVXuAfd46C5LWOFqKiIiIiIi3U3AKVO54qHgt4IGV452uRkRERETEqyk4BbJDG+JueBvSdjtaioiIiIiIN1NwCmRntYTSjSA7Dda87HQ1IiIiIiJeS8EpkLlch0edVr8IWQedrUdERERExEspOAW6Kh2hRHVI3wMb3nG6GhERERERr6TgFOiCQqD2g3a8cjzkZDtbj4iIiIiIF1JwEjj7NggtCQfWwD+fOF2NiIiIiIjXUXASCI2EuDvteKU2xBURERER+S8FJzHn3AtBYbD7B9j9k9PViIiIiIh4FceC0+zZs4mPjycqKoo2bdqwYcOGo/59/vz5uFyuYz4SExPZvn071113HVFRUZxzzjlMmTLFoWfhR4pXgOq32LFGnUREREREjhLixDddtmwZnTp1okOHDvTr14+JEyfSuXNnFi1adMx9R48eTZkyZXLPixcvTvv27VmzZg3Dhg3jt99+o2fPnsTGxtKsWbOifBr+J34ArJ8MWz6GA2shKtbpikREREREvIIjwWnevHkEBwczdepUQkJCiImJoXv37iQkJFCyZMmj7tulSxeqVauWe56Tk0OHDh1o2bIlF1xwAR6Phy+++IJ58+YpOJ0p97lQ8RrY9pl12GusTXFFRERERMChqXoJCQlERkYSEmK5rVSpUgAkJiYec9/evXsTFRVF3bp1WbBgAUFBQdx3331ccMEF7Ny5k6lTp5KQkEBs7IlHR9LT00lKSjrqQ07g0Ia469+CtN3O1iIiIiIi4iW8vjlERkYGw4YNw+Vy0blzZw4ePJj7b02bNqV79+40btyYLl26nPAxRo0ahdvtzv2oUqVKUZTum866BEo3hOw0WPOK09WIiIiIiHgFrw1O9evXZ+HChXz++ef079+fsWPHsmPHDlauXJl7n7feeotBgwaxaNEiPv300xM+1uDBg0lMTMz92LJlS1E8Bd/kckHtf0edVr8IWQdPfn8RERERkQDgtcEpOjqa5s2bExkZCUClSpUASElJyb3PpZdeypgxY6hTpw4zZ8484WOFh4cTHR191IecRNUboUQ1SN8NG9SxUERERETEkeDkdrtJTk4mKysLgP379wMcFWh+//13+vTpw549ewDYu3cvAFFRUdx33318/fXXAHg8HtLS0o5pKiFnICgEznnQjlc+C54cZ+sREREREXGYI8GpVatWZGdn061bN1544QWefPJJGjVqxJ49e3jzzTfJysqiSpUqTJ8+nZtuuonnnnuOe++9l1q1alG3bl1Wr17NzTffzLhx4+jatSvr16/nxhtvdOKp+K+at0FoSTiwBv75xOlqREREREQc5Uhwqlu3LjNmzGDp0qUMGTKE2NhYZsyYwY8//sjtt99Oeno6Z511Fp9++imJiYk8+uijuN1uZs2aRXBwMFOmTKFFixYMGzaMJUuW8N5779GiRQsnnor/Co2CuH52vEIb4oqIiIhIYHN5PB6P00UUtaSkJNxuN4mJiVrvdDIHt8PsapCTCVf9BGWaOl2RiIiIiEiBym828NrmEOIFileA6rfYsUadRERERCSAKTjJydUeYJ+3zIQD65ytRURERETEIQpOcnIl60CFNoAHVj7ndDUiIiIiIo5QcJK8nTvIPq+fDGl7nK1FRERERMQBCk6St7MuhVINIPsgrHnF6WpERERERIqcgpPkzeWC+IF2vHoiZKc5W4+IiIiISBFTcJL8qdoJIqpC+m7Y8K7T1YiIiIiIFCkFJ8mfoBCo/aAdr3wWPDnO1iMiIiIiUoQUnCT/avaGUDckrYJ/PnW6GhERERGRIqPgJPkXGgVx/exYG+KKiIiISABRcJJTU+s+CAqF3d/Dnl+crkZEREREpEgoOMmpiagI1bvZsUadRERERCRAKDjJqas9wD5vnQkH1jlbi4iIiIhIEVBwklNXsi5UaG2d9VY973Q1IiIiIiKFTsFJTk/8IPu8bjKk73W2FhERERGRQqbgJKen3GVQqj5kp8KaV5yuRkRERESkUCk4yelxuSB+oB2vngjZac7WIyIiIiJSiBSc5PRV7QQRVSBtF2x4z+lqREREREQKjYKTnL6gUKj9oB2vHGfNIkRERERE/JCCk5yZmrdDqBuSVsE/nzldjYiIiIhIoVBwkjMTGgWxd9jxSm2IKyIiIiL+ScFJztw599m0vV0LYM8ip6sRERERESlwCk5y5iIqQbWb7VijTiIiIiLihxScpGDED7DPWz6C5PXO1iIiIiIiUsAUnKRglDwPKlxtnfVWPu90NSIiIiIiBUrBSQpO/CD7vO5NSN/rbC0iIiIiIgVIwUkKTrnLodQFkJ0Ka151uhoRERERkQKj4CQFx+WC2gPtePVEyE5zth4RERERkQKi4CQFq9pNEFEF0nbCxqlOVyMiIiIiUiAUnKRgBYXCOQ/Y8Ypx1ixCRERERMTHKThJwYu9HUKjIWklbPvc6WpERERERM6YgpMUvNBoiL3DjldoQ1wRERER8X0KTlI4zrkPXCGwaz7s/dXpakREREREzoiCkxSOiMpQ/WY71qiTiIiIiPg4BScpPLUH2OctH0LyBmdrERERERE5AwpOUnhK1YPyV1lnvZXPO12NiIiIiMhpU3CSwnXuIPu8/k1I3+dsLSIiIiIip0nBSQpXuSug5PmQlQJrX3W6GhERERGR06LgJIXL5YL4gXa8agJkpztbj4iIiIjIaVBwksJXrbN12UvbCRunOl2NiIiIiMgpU3CSwhcUCuc8YMcrxlmzCBERERERH6LgJEUjtg+ERkPSCtg21+lqREREREROiYKTFI3QaIjta8faEFdEREREfIyCkxSdWveBKwR2/Q/2/uZ0NSIiIiIi+abgJEWnRBWo1tWONeokIiIiIj5EwUmKVvwA+7zlA0je6GgpIiIiIiL5peAkRavU+VD+Suust+p5p6sREREREckXBScpeoc2xF03CTL2O1uLiIiIiEg+KDhJ0St/JZSsB1kpsOZVp6sREREREcmTgpMUPZfr8KjTqgmQne5sPSIiIiIieVBwEmdU7QzFK0HaDtg4zelqREREREROSsFJnBEcBrUfsOOV48DjcbQcEREREZGTUXAS59TsAyFRkLgcts11uhoRERERkRNScBLnhLkhtq8dr9SGuCIiIiLivRScxFnn3A+uENj5Hez73elqRERERESOS8FJnFWiClTrYscrnnW2FhERERGRE1BwEufFD7DPm2dAyiZnaxEREREROQ4FJ3FeqQugfCvwZMPK552uRkRERETkGApO4h1q/7sh7ro3IGO/s7WIiIiIiPyHgpN4hwpXQcnzICsF1rzmdDUiIiIiIkdRcBLv4HIdHnVaPQGy052tR0RERETkCApO4j2qdYHiFeHgdtj0vtPViIiIiIjkUnAS7xEcZvs6AawYBx6Ps/WIiIiIiPxLwUm8S+wdEBIFictg+xdOVyMiIiIiAig4ibcJc0NsHzteMc7ZWkRERERE/qXgJN7nnPvBFQw7v4V9i52uRkREREREwUm8UImq1igCYMWzztYiIiIiIoKCk3ir2gPs8+b/g5RNztYiIiIiIgFPwUm8U+n6UO4K8GTDyhecrkZEREREApyCk3iv+H83xF33BmQkOFqKiIiIiAQ2BSfxXhWuBnddyEqGta87XY2IiIiIBDAFJ/FeLtfhUadVL0B2hrP1iIiIiEjAUnAS71atKxSvCAe3wab3na5GRERERAKUgpN4t+AwOOc+O14xDjweZ+sRERERkYCk4CTeL/YOCImExL9h+5dOVyMiIiIiAUjBSbxfWEmo2ceOV4xztBQRERERCUwKTuIbat8PrmDY+Q3sW+J0NSIiIiISYBScxDeUqAZVb7Ljlc86W4uIiIiIBBwFJ/Edh1qTb5oOKZudrUVEREREAoqCk/iO0g2g3OXgybZ9nUREREREioiCk/iWQ6NOa1+HjARHSxERERGRwKHgJL6lQmtw14WsZFj7htPViIiIiEiAUHAS3+JyQfwAO145DnZ972w9IiIiIhIQFJzE91TrClG1IG0XzGsJP/eGtD1OVyUiIiIifkzBSXxPcDhc9RPE9rXz9ZPhs9qw7i3weJytTURERET8koKT+Kbw0tDkNbjyByh5HqTvhV9ug3mXQMIyp6sTERERET+j4CS+rWwzaP071B8LwRGw+3uYewH88ShkpTpdnYiIiIj4CQUn8X1Bodam/NoVUPl68GTB8lHwWR3453OnqxMRERERP6DgJP6jRFVoOcs+IqpAykaYfw18fyOkbnW4OBERERHxZQpO4n8qXw/XLIf4QeAKhi0fwafxsPJ5yMlyujoRERER8UGOBafZs2cTHx9PVFQUbdq0YcOGDUf9+/z583G5XMd8JCYmcvDgQfr27Uvp0qWpWrUqI0aMcOhZiNcKjYT6Y6D1YihzkW2Yu/hB+LIJ7FnkdHUiIiIi4mNCnPimy5Yto1OnTnTo0IF+/foxceJEOnfuzKJFx76hHT16NGXKlMk9L168OEOHDuXtt99m0KBBZGRkMHToUCpWrMhtt91WlE9DfEGpenDlQlj3JvzxMOxfAl81hbg74fyREFbS6QpFRERExAc4EpzmzZtHcHAwU6dOJSQkhJiYGLp3705CQgIlS5Y86r5dunShWrVqR922fv16Bg4cyMiRIwFYvHgxn376qYKTHJ8rCGL72BS+JYNgwxRY87JN4WvwHFTrAi6X01WKiIiIiBdzZKpeQkICkZGRhIRYbitVqhQAiYmJx9y3d+/eREVFUbduXRYsWADAjBkzePrppwHIzMxk8+bNREVFnfD7paenk5SUdNSHBKBiZ8FF78AV30L0OZC2E368Gb67CpLWOF2diIiIiHgxr28OkZGRwbBhw3C5XHTu3JmDBw8e9e8PPPAAmzZt4v777z/hY4waNQq32537UaVKlcIuW7xZucugzZ9QbzgEF4Md8+Dz8+CvYZCd7nR1IiIiIuKFvDY41a9fn4ULF/L555/Tv39/xo4dy44dO1i5cmXufaZMmcLLL7/M+PHjadCgwQkfa/DgwSQmJuZ+bNmypSiegniz4HCoOwTa/g3lr4KcdPjrSfi8Huz4xunqRERERMTLeG1wio6Opnnz5kRGRgJQqVIlAFJSUgBYsmQJ/fr1o3v37txzzz0nfazw8HCio6OP+hABIKomXPYFNP8/KFYeDqyGb1vBj7fAwZ1OVyciIiIiXsKR4OR2u0lOTiYry/bU2b9/P8BRgeb333+nT58+7NmzB4C9e/cCEBUVxb59++jYsSPnnHMOr732WhFXL37H5YJqN8G1K6HWvYALNk6FT8+BNa+CJ8fpCkVERETEYS6Px+Mp6m/6999/06BBAzp06ECzZs2YOHEipUqVYtq0aSxYsIAePXqwb98+atasSePGjbnuuuuYPHkyGRkZLF++nI4dOzJ79mwee+wxatSoAUCFChVo27Ztvr5/UlISbrebxMREjT7Jsfb+BovugP2L7TzmQmjyKpS6wNGyRHzCwZ2Q+Dck/GWfk1ZC6SZwwdO2plBERMTL5DcbOBKcAGbNmsXgwYPZunUrzZs355VXXmHBggX07NmT5ORkSpQowfz58+nfvz/Lly+nYcOGvPHGG8THx1OjRg02btx41ONdeumlfPfdd/n63gpOkqecbGtZ/udjkHXAWprXuh/qDYPQE3dwFAkYmQcgcZkFpIS/IfHfz+m7j3//mAuh5cdQvELR1ikiIpIHrw9OTlJwknxL3QaLH4TNM+w8ojI0nACV22vvJwkM2RlwYNXhgHRoJCll4wm+wAVRseCuCyXPg2LlYOkQyNgPxStBy1kQ06gIn4CIiMjJKTidhIKTnLJtX8Bvd0PyejuveC00mgiR1R0tS6TAeHIsDP03ICWtAk/W8b+meMXDAankv5+j4yEk4uj7HVgL89tB0gqbrtf0bajWubCfkYiISL4oOJ2EgpOclqyDsGwkrBgDOZkQXBzOewJq94egUKerE8kfjwfSdh2eWncoICUug6yU439NqNuCkfuIgOSuA+Ex+f++GYm24fS2z+28zmNQ7ymbBisiIuIgBaeTUHCSM5K4An69E3bNt3N3HWj8KpzVwtm6RP4rMwkSlh0bktL3HP/+QeHgjv9PQKprU1QLYmpqTjb8ORhWjLXzyu3honchNPLMH1tEROQ0KTidhIKTnDGPBza8C0sGHH4TWrM3XPDMqV2FFykI2ek2pe5QMMpdh7TpBF/w7zqkQ8Ho0OeoWAgKKfx610+BRX0gJ8O+d8s5mvYqIiKOUXA6CQUnKTDp++CPR2DdG3YeHgP1x0GNHmoeIQXPkwPJG44NSEmrT74O6ciAVLLu8dchFbU9P8OC9pC2E8LLwMUfwVktna1JREQCkoLTSSg4SYHb/QMs6mdvYsHeADZ+BdznOluX+CaPxwLFkQEp4d91SNmpx/+aUPexAcldF8JLF23tpyJ1K8y/3vZMCwqFRi9D7O1OVyUiIgFGwekkFJykUORkwsrn4a8n7c2tKwTiB0HdIc5f3RfvlZn0byj6++g9kdL3Hv/+QeEWyP/bza54Jd8c5cxKhZ97HW75X+s+aPBs0UwZFBERQcHppBScpFClbILf7oV/PrHzEjWg0YtQqa2zdYmzstMhaeXRm8Um/AWpm49/f1cQRMYe280usqb/hQqPxzpWLn3czstfCS3+D8JKOVuXiIgEBAWnk1BwkiKxdbYFqNQtdl7lRmj4PERUcrQsKWSeHNvv68gudgl/wYHV4Mk+/tcUr3R0F7vc/ZCKF23tTtvyMfzU3dqiR8VZ0wh3baerEhERP1eowSklJYXU1FTKli3Ljh07ePPNNylTpgx9+/bF5QNTRRScpMhkJsPfw2Dlc/amOSQS6o2AWnf736hBoPF4IG3HsQEpcflJ1iGVPDYguet49zqkorb/T1hwvY3chrqh+XSo2NrpqkRExI8VanAaMGAACxYs4Ndff6Vhw4asXr2atLQ0Bg0axNNPP31GhRcFBScpcvv/tOYRe3+281L1be+nMk2crUvyJzsd9i2GhKVHd7PLax3Sf5s1+Oo6pKKWtgu+7wi7F9qUxQvGQu0H9d9ORMRf/PUX7NoFV1zhdCVAIQen8uXL07NnTwYPHkypUqVYvHgxb775JrNnz2bz5hPM1/ciCk7iCE8OrJsESx6GzATABXF3wfkjIcztdHVypIxE2PMj7Poedn8Pe3+FnPRj75e7Duk/ASkyFoKCi75uf5KdAb/dBevetPOze9rFhuBwR8sSEZEC0KYNfPEFPP00DB7sdDX5zganNVcoMTGRatWqsXPnTlwuF7GxsZx99tns3r37tAsW8XuuIIjtC5Xbw+KBsPFdWPMSbPkIGjwH1TrrirpTDu6wgHQoKCUstaB7pGJnQakGRzdrCMR1SEUlOAyavAEl68HiB2H927Zf1cUzoXg5p6sTEZHTtXChhaaQELjpJqerOSWnNeLUpEkTsrKyiIuL4+eff2bTpk107NiRdevW8ccffxRCmQVLI07iFXZ8a1fUk1bZefkrofHLEBXrbF3+zuOB5HWHQ9Ku7yF57bH3izwbyl4MZ11sn6PiFGydsv0rWNjZRmojqkDL2VC6vtNViYjIqfJ44LLLYP586NsXXnvN6YqAQp6q9+OPP3LLLbeQkpLC66+/zoUXXkiNGjV46aWXuO22286o8KKg4CReIzsdlo+xVsw56bY2ps6jcO7DmpJUUHKybQRp98LDQSltx3/u5LKRjbMuhrItLChFVHSkXDmBpNUw/zrrThgcARe9A1VvdLoqERE5Fd98A61aQVgYrF0LVao4XRHgQDvyP/74gwsuuKAgHqrQKTiJ1zmwFn69C3Z8bedRtaDxK1D+cmfr8kXZabYm6VBI2vOjbTJ7pKAwiGlsAansxVC2GYSVdKRcOQUZCfBDF9j+pZ3XfQLOG2rTYEVExLt5PNCsGfz8M9x3H7zwgtMV5SrU4LRx40a2bt1KixYtWLBgAcOHD6dMmTJMmDCBsmXLnlHhRUHBSbySxwObZ8DvDxweEal+C9QfpzUdJ5OfRg4hURaODk29i2kCwcWcqVfOTE4WLHkIVj1n51U62uhTSAln6xLxZVkHYftcKHWBTVMWKQyffgrXXQfFi8P69VC+vNMV5SrU4NSxY0c2bNjA4sWLqVixItWrV2fNmjW0atWK999//4wKLwoKTuLVMhJh6RBY/RLgsb1/LhgNsX10ZR3y2cih3L8jSS0sKJWsp32z/M26yfBrP8jJtDd7LWdDiapOVyXiWw5uh9Uvw9pXIX0PBIXCOQ9C3ccgVO+PpADl5EDDhvDHH/DQQ/DMM05XdJRCDU5ut5uHH36Y22+/nfLly7N27VreffddXnzxRZ/orKfgJD5h76+299P+xXYe0xSavAqlzne2rqKU70YONQ83cSh7sTXYUCMH/7f7B/j+Btv3qdhZcPHHNrIoIie3b4ltzL55ul18ALtIl5lgx8XKwfmj4OweumAnBePDD6FTJ4iKgg0bICbG6YqOUqjtyD0eDxEREfzzzz8EBQVRqVIlwsLCSEtLO+2CReQ/YhrD1YusZfmfQ2zz3C8awjn3w3nDIDTS6QoLXm4jh0MjSgvzaOTw76iSGjkEprLN4epfYX47SPgTvrkMmrxmez6JyNFysmHbpxaYds0/fHvZ5nDOA7ZVxvYvrf3/gTXwy23296fhBF2QkDOTnQ1Dh9rxgw96XWg6Fac14nTttdfyyy+/UKZMGSIjI1m0aBEXXnghbrebr7/+ujDqLFAacRKfk/qP/THb/IGdR1SGhhOh8vW+PbKiRg5SELJS4KceticaQO3+cMEYbUIsApB5ANa/Basm2Ag+gCsEqnaywFSmydH3z86A1RPh76cO/z6udjPUf8b+9oicqvfeg+7doVQpG21yu52u6BiFOlVv586dDB48mJSUFIYNG0ZMTAwXXnghU6ZMoUWLFmdUeFFQcBKftW0u/Ho3pGyw80rXQaOJUKKas3Xl1zGNHBZBTsbR9wmJsiugh1qDq5GD5IcnB/56Cv4eZucVWkPz9xWyJXAlb7QAtG7S4QAUVso2Yq91T94h6OBOW2+77k3AY9sAnPsIxA/Uxt+Sf5mZEB8P69bBqFHwyCNOV3RcRdaOPCMjg7CwMA4ePEjx4r7xg6TgJD4tK9X2fVox1uamB0fAeU9A7QdtYa83Objdptvlp5HDoal3JetppEBO3+YPbPQp+yBEnwMt50B0LaerEikaHg/s+cmm422defj3bVQtqP0A1Lj11DtQ7lsMv99vv8vBLtTVHwtVbvTtGQ9SNCZNgj594KyzrJNeCe/sgFqowSkhIYE777yTWbNm5QanG264gRdffJFSpUqdUeFFQcFJ/ELicvj1Tti1wM7dda15RNnmztTj8dh+VLuPbOSw7tj7qZGDFLZ9i2HB9ZC61Ra8t5gBFa50uiqRwpOTCZs/hFXP20j+IeWusItqFducWZOHQ9tlLBkEqVvstrNaQsMXrKulyPGkp0NcHGzZAs89Bw884HRFJ1SowalDhw4sWLCAhx56iHLlyrF9+3bGjRvHZZddxocffnhGhRcFBSfxGx4PbJgCSwZaK1mAmrdb+/LwQl58eTqNHM66GIpXKNy6RMDa1n9/g119dwVDg/FQ616FdPEvGfth7euw+kW7UAAQFA7Vu9kIU8nzCvb7ZaXabIflz9iorivI/ubUGwHFvH8fTyliL74I994LlSrB2rVQzHun3RdqcIqIiGDo0KE8csQ8xVGjRjFy5EiSk5NPr+IipOAkfid9L/zxiM1lBwgvYxvn1ri14N4o5ruRQ5PDIanMRVpjIs7JTodFd8CGd+y85u3Q6CUIDnO2LpEzlbTKmj2sfxuyU+22YmdB3N0Q18+OC1PKZvjjYdg03c5D3XDek1Drbu+bMi7OSE2FmjVhxw545RXo18/pik6qUNuRlyhRgn/++eeo27Zu3UpkpB+2RxbxBeExcOEb1oZ5UT9I/Bt+7mmdlBq/Au74U3/M/DRyCI2GMs0OjyjFNFYjB/EeweHQ9C276v7HQ3ZhIWkVXPyRro6L7/F4YOe3tn5p22eHby9Zz6bjVetqr/miUKKqNV+Ju8vWP+1fYp1f174GDZ6Diq2Lpg7xXi+9ZKGpenW47TanqykwpzXiNHz4cJ544gmaNWtGhQoV2LZtGz/99BOjRo3i4YcfLow6C5RGnMSv5WTaH9a/nrSpFEGhED8I6jwGIREn/rqD2w+HpN0LYf+fwH9+PaiRg/iqbXPhhy42SlqimjWNKFXP6apE8padBhun2fqlhL/+vdEFla61duLlLnN2CmpOtl2kW/qYbUYNUPEamx6rxiyBKSkJzj4b9u6Ft96Cnj2drihPhd5Vb+rUqcycOTP3G3Xs2JGuXbuedsFFScFJAkLyRvjtXtvwEKBEDWj8sl0JzHcjh9jDbcHVyEF8XeIK2yw3ea11FrvoXajSwemqRI7v4E5Y8wqsfeVwIAmOgLN72Ubo0XHO1vdfGYmwbASsesEu4LlCrM66j0OY9+3bI4Vo+HDb8LZWLVi2DEJOa4JbkSqyduSHbN68mT///JPrrruuIB6uUCk4ScDweGDrbPj93sMLh8tcBMkbjt/IodT5R4wotVAjB/E/6fvgh86wY56d1xtuo7G6ICDeYv9SWPWcjTIdmh4dUcWam8TebnsxebOk1bC4/+HphOFl4fynLfBphoL/27cPatSwUaf334cuXZyuKF+KPDhNnjyZPn36kJ2dXRAPV6gUnCTgZCbDX0/YlUDPvz+jxzRyaKarghIYcrLsjd3qiXZetTM0nXzyqawihcmTA9s+t2nWO789fHvMhbZ+qcoNvtd0YdtcW/eUtMrOS9W39uVnXexsXVK4HnsMnn4azjsP/vgDgs6gDX4RKtTmECLiY0IjocGz1jxi1/e2WF6NHCRQBYVAown2c/DrXbD5/2z6XstZEFHZ6eokkGQmW9fHVS/AgTV2mysYqnS0wFSmqbP1nYmKbaB8K1j9kq253b8E5rW0CxX1x1iDCfEvu3bBCy/Y8fDhPhOaToWCk0ggKXlewe/rIeKrYvtA9DnwfUfY9zt80Rhafuzbb1bFN6Rssb2X1r4OmQl2W6jbXpO17vWfUBEUavtJVe8GSx+357v5/+CfORD/EJz7kEZ6/ckzz0BKCjRqBO3aOV1NofC/KCgiIpJfZ7WEqxfZBYW0HTDvUtjwrtNVib/a8wss7AJzasCKMRaaImOh4URovxXqj/Wf0HSkYmWhyavQZjGcdYl1fP17GHxaGzZOt/W44tv++QdeftmOR4zw23Wj+R5xGj58+En/ffHixWdcjIiISJGLrAFX/gA/dbdmKj/dam2fzx+lxexy5nKyYOvHtn5pz0+Hbz/rUpuOV/GawHmdlboArvgOtnwESwZCyib4sSusecnWP5Vu4HSFcrqefhrS0qBFC7jqKqerKTT5bg4RlI95ii6XS80hRETEN3lyYOlQWDbSziteA82n2UbPIqcqI8E2XV41EVI3221BYbZRbe0HLEQEsqyDsPJZWDYKslMBF9TsDfVGQPFyTlcnp2LjRms9npkJ//sfXHKJ0xWdsiLvqudLFJxEROSENr4Pv9xmG49Gx8Mlc2wPM5H8OLDWmj2sfwuyUuy28LIQd6d9FC/vbH3eJnUr/PEIbJxq56HRUHeorfUKDnO2Nsmf226zjW5btYKvv3a6mtOi4HQSCk4iInJSe3+FBe3h4DYIKw0tPoDylztdlXgrjwd2zbfpeP98Avz71spdx6bjVe+mLqZ52f0j/H4/7PvNzqPioMFzULGt366X8QurV0N8POTkwE8/QVPfbK6T32yg5hAiIiL/FdMYrv7V9jrL2AffXQWrX3a6KvE22emw/h34ogF8c5l1i8Njb/Yv+wra/mXTzxSa8la2GVz9C1w4GYqVs/bs86+F/7WFxBVOVycn8uSTFpquvdZnQ9Op0IiTRpxEROREsg7Coj6HpxHF9rM9oHxtM1IpWGm7Yc2rsOZl68YIEFwcavSAc+4Hd21n6/N1mUnw90hY9RzkZIIrBGrdA+c9AWElna5ODvnrLzj/fBtxXbwY6td3uqLTpql6J6HgJCIi+ebxWOvoPwYDHuuG1uIDKFbG6cqkqCX8Dauehw3vQU663Va8kr2pj+0D4TGOlud3ktZY971/5th5eBlrHlHz9sDpROjNbrgBPv4YbrwRPvjA6WrOiILTSSg4iYjIKdv6Cfx4M2QlQ4kacMknULKO01VJYfPkwLYvLDDtOGLhe+lGtn6paieNQBa27V/B4gchcbmdlzzf2peX873ubX7j999to9ugIPj7b1vn5MO0xklERKQgVb4OrvoZIs+GlA3wVVMLU+KfslJtOt5ndWD+NRaaXEFQpSNcudA2Tq5+s0JTUahwFbT5AxpOgNCSkPAnfHMpLLwJkjc6W1ugevxx+9ytm8+HplOhESeNOImIyKlI3wvf3wi7/ge44Pyn4dyH1fnLX6T+A6tfgrWvWWMQgJAomx52zr22YbI4J20P/PUErH3VRgODi0HtgVDnEQgp4XR1geGHH2yj2+BgWLUKatZ0uqIzpql6J6HgJCIiZyQn01onr3nFzqt3gyZvQEhxZ+uS07f3N2snvnkGeLLsthI1rNlDzV7aCNnbJPxlP4M7v7Pz4pWg/hjbYFgXMQrX5ZfDd99Bnz7w+utOV1MgFJxOQsFJREQKxJpX4Ld7wZMNpRtDy1kQUdHpqiS/crJh6yxbv7R74eHbz2oJ5zwAldqpCYE383js/9/iATZ9FqBMM1v/FNPI0dL81rffwhVXQFgYrFkDVas6XVGB0BonERGRwhZ3J1z+tW2Su+9X+LKxbZ4r3i0zyUaXPomFhTdaaHKFQPVboPVv0Go+VOmg0OTtXC77/3TtcpsyG1IC9vxoP4c/3wYHdzhdoX/xeOCxx+z4jjv8JjSdCo04acRJRETO1IF1sKCddf0KLmabeFbv6nRV8l/J62HVBFg3GbIO2G1hpSGuH8TdrdFCX5f6j20bsPFdOw+JhLqP23TL4HBna/MHn31mG90WLw7r1kGFCk5XVGA0Ve8kFJxERKTAZSbBD91g26d2XudRqDfcOrGJczweG1Fa+Rz8M9saCgBEx0PtB2yUKSTC0RKlgO352dY/7V1k55E1ocF4qHSd1j+drpwcaz++ZAkMGgRjxjhdUYFScDoJBScRESkUOdnw56O2YS5A5evhonchNMrZugJRdoY1elj1POz7/fDt5a+y/ZcqXKVQ6888ObZR8Z+PwMHtdlv5K6Hh8+A+19HSfNJHH9lGt5GRsGEDlPGvDcAVnE5CwUlERArVhvfgl9shJx3cdeGSOWpjXVTS9sC6162l+MFtdltwMaje3aZsadPiwJJ5AJaNgpXPQk4GuIIh7i4470kIL+10db4hOxvq1YPly23/pqeecrqiAqfgdBIKTiIiUuj2/AIL2kPaDgiPgRYfQblLnK7KP+Rkw8GttrYseT0kr7OPA+sgcZkFVoDiFWztUmxfKFbW2ZrFWcnrYfFA2PqxnYeVtqm0sX0hKMTZ2rzd1Klwyy1QqhSsXw8lSzpdUYFTcDoJBScRESkSqVstPO373bq2NX7J3qhJ3rJSjwhF6/8NSf9+pGy0vbROpFR9m45XtTMEhxVZyeIDdnwDvz8AiX/bubuutS8vf7mjZXmtzEw491xYuxaefhoGDz79x/J4IGM/pG6GlE2Qshkqt4MS1Qqu3tOk4HQSCk4iIlJkslLhl96wabqd17oHGjynq9weD6TvPnbU6FBQOrQu5USCQqFEdVv4H1kTIs+GqJoQVQuia6sJgJxYThasfR2WPg4Z++y2KjdA/bH2OpLD3nwTbr8dypa10abIyBPfNyfTOhumbrZQlLLp2OOslKO/psUHUPXGwn0O+aDgdBIKTiIiUqQ8Hlj2NCwdYuflroAWM/x/jUVOpr1p+u90ukPnWckn//pQt4WiqCPC0aHz4pW1z5KcmfR98NeTsOZl28Q6KBziB8C5gyH0JAEhUKSnQ61asHkzjB8Pd9928lB0cNvhrpUnU+wsiKgKJapCrXuh3KWF/lTyouB0EgpOIiLiiC2z4Kdb7KprZKw1jXDHO13Vmck8cJzpdP8Go5RN9ob0hFwQUenoUaMjg1JYKY0cSeFLWAaLH4Ad8+y8eAW44Bmo3i1wOi/mZEPa9qOD0NufwdjvISYEXogAV1LejxMUBhFVLBSVqHY4IB06jqgCIcUL//mcIgWnk1BwEhERx+xfapvlpmyC0Gho9j5Uaut0VSfm8di0uRONGqXvPvnXB4X/JxCdfURQqm4d70Sc5vHAP3NgcX97bQPEXGjrn8pc6GxtBSEr5cQjRSmbbT2mJ+vw/dOB/kAC0Ato9e/tYaUtBJWo+m8oOvK4KhQr55NhU8HpJBScRETEUWm74fuOsPt7wAX1x0DtAc6NrmSn25uo3FC07ujGDNkHT/714TFHhKEj1htF1rSr9z74RkoCVHa67f3194jDU0lr3Arnj4KIio6WdkKeHEjbdeJQlLLp8Fquk3GFQERlC0CzkuGlxVApBha+BaVibbTIT6cwKjidhIKTiIg4LjsDfrsb1k2y8xo9oMmrhTcCk5Fw/GB0YB2kbgFO8nbAFWRXlI87anQ2hLkLp2YRpxzcbptZr3/bzkNKQJ3HrFtjUY+SZh20n9Eju9EdFZC22B5VeQl1n2Ck6N/jYhVs3eCBA1CjBuzdC5MnQ69ehf8cHabgdBIKTiIi4hU8Hlj9Iix+0NYCxTSFlh9D8fKn8Vg51tHqyM50R7bwzth/8q8PjjiiCcN/1huVqGZd7EQCzd5f4bf7YO/Pdl6iBjR4Fiq3L5gRYo8H0vccHYpSNkPqEQEpbVfej+MKguIVj7+u6FBAyu8FjhEjbKPbuDjb9DbE/zuAKjidhIKTiIh4le1fw8KbIDPBpsq0nA2lGxx7v6yDkLLhONPp1kHyhryvOhcrd/zpdJE1rdOVGjGIHMvjgY3T4I+HrHMcQLnLoeHzUPK8k39tdoZt1nyiUJSyOe+psGAjXicKRSWqWWgqiIsb+/fbaFNiIkybBl27nvlj+gAFp5NQcBIREa+TtNqaRiStguDicN6TFoSOnF536E3bibhCbG+j47Xvjjzb3nyJyOnJTIblz8CKsZCTbqM8sf3g7J42te/IUHTo+OAOTjoN9pDiFU4ciiKqFl2HySFDYORIqFsX/vwTggJjfaKC00koOImIiFfKSIAfusL2L058n9DoE48aRVTWxroihS15Ayx5CLZ8mL/7Bxc7fge63BbdlSE4vHBrzo/du220KSUFPv4Y2rd3uqIik99soN+uIiIi3iKsJFzyKSwfBTv/Z2+u/tuIITxGU+pEnBRZAy7+wH5G/3jEps8euZbov40Xwsv4xs/sM89YaGrYEK6/3ulqvJJGnDTiJCIiIiKBbNs2qFkT0tJg7lxo3drpiopUfrNBYExcFBERERGR43v6aQtNzZvD1Vc7XY3XUnASEREREQlUGzfC66/b8YgRvjGt0CEKTiIiIiIigWr4cMjMhCuugEsvdboar6bgJCIiIiISiFavhnfesePhw52txQcoOImIiIiIBKJhwyA7G665Bi66yOlqvJ6Ck4iIiIhIoPn7b3j/fTvWaFO+KDiJiIiIiASaJ54AjwduvBHq13e6Gp+g4CQiIiIiEkh+/x1mzrQOesOGOV2Nz1BwEhEREREJJEOH2udu3eDcc52txYcoOImIiIiIBIoff4TPP4fgYJuuJ/mm4CQiIiIiEigef9w+9+oFsbHO1uJjFJxERERERALBt9/aR1jY4QAl+abgJCIiIiLi7zweGDLEjvv2hapVna3HByk4iYiIiIj4u7lz4aefoFgxePRRp6vxSQpOIiIiIiL+7MjRpnvugQoVnK3HRyk4iYiIiIj4s48/hiVLIDISHn7Y6Wp8loKTiIiIiIi/ys4+vG/Tgw9CmTLO1uPDFJxERERERPzV//0fLFsGJUtC//5OV+PTFJxERERERPxRVtbhTW4HDbLwJKdNwUlERERExB9NmQJr19r0vPvuc7oan6fgJCIiIiLib9LTYdgwOx482BpDyBlRcBIRERER8TeTJsHmzdZ6/M47na7GLyg4iYiIiIj4k9RUGDHCjocMgeLFna3HTyg4iYiIiIj4k1degR07oFo16N3b6Wr8hoKTiIiIiIi/OHAARo+246FDITzc2Xr8iIKTiIiIiIi/mDAB9uyBuDi49Vanq/ErjgWn2bNnEx8fT1RUFG3atGHDhg1H/fv8+fNxuVzHfCQmJgIwYcIEwsPD6dSpkxPli4iIiIh4l/37YexYOx42DEJCnK3HzzjyX3PZsmV06tSJDh060K9fPyZOnEjnzp1ZtGjRMfcdPXo0ZcqUyT0vXrw4mzZt4vHHH6d06dJFWbaIiIiIiPcaPx4SE6FuXejc2elq/I4jwWnevHkEBwczdepUQkJCiImJoXv37iQkJFDyPzsad+nShWrVqh11m9vt5vfff6dPnz5FWLWIiIiIiJfavRuef96On3oKgrQip6A58l80ISGByMhIQv4dPixVqhRA7jS8I/Xu3ZuoqCjq1q3LggULAChZsiSxsbH5/n7p6ekkJSUd9SEiIiIi4jfGjIHkZGjQANq3d7oav+T1UTQjI4Nhw4bhcrno3LkzBw8ePOXHGDVqFG63O/ejSpUqhVCpiIiIiIgDtm+HF1+04xEjwOVyth4/5bUrxurXr8/ChQs5//zziYyM5Nxzz6VNmzasXLmS+vXrn9JjDR48mP79++eeJyUlKTyJiIiIiH8YORLS0qBZM2jd2ulq/JbXBqfo6GiaN2+ee16pUiUAUlJSTvmxwsPDCVcPexERERHxN5s2weuv27FGmwqVI1P13G43ycnJZGVlAbB//37AwtIhh5o/7NmzB4C9e/cCEBUVVcTVioiIiIh4qeHDITMTLr8cLrvM6Wr8miPBqVWrVmRnZ9OtWzdeeOEFnnzySRo1asSePXt48803ycrKokqVKkyfPp2bbrqJ5557jnvvvZdatWpRt25dJ0oWEREREfEua9bA22/b8YgRjpYSCBwJTnXr1mXGjBksXbqUIUOGEBsby4wZM/jxxx+5/fbbSU9P56yzzuLTTz8lMTGRRx99FLfbzaxZswgODnaiZBERERER7zJsGGRnwzXXwEUXOV2N33N5PB6P00UUtaSkJNxuN4mJiUdNDxQRERER8QnLlsF554HHA7//bm3I5bTkNxt4fTtyERERERH5jyeesNDUsaNCUxFRcBIRERER8SWLF8NHH1kHvWHDnK4mYCg4iYiIiIj4kqFD7fPNN0OdOs7WEkAUnEREREREfMVPP8Fnn0FwsE3XkyKj4CQiIiIi4iuGDLHPPXtCXJyjpQQaBScREREREV/w7bf2ERoKjz/udDUBR8FJRERERMTbeTyHw1LfvlCtmrP1BCAFJxERERERb/fFF/Djj1CsGDz6qNPVBCQFJxERERERb+bxHF7bdM89ULGis/UEKAUnkUCTnu50BSIiInIqZs2yvZsiI+Ghh5yuJmApOIkEiu+/h6ZNIToaXnzR6WpEREQkP7KzD69teuABKFvW0XICmYKTiL9btQrat4eWLeGXXyAjA+69F+6+G7KynK5ORERETmbGDFi2DEqWhAEDnK4moCk4ifirXbssHNWpA7NnQ1AQ3HEHDBsGLhe8/DK0bQsJCU5XKiIiIseTlXV4k9uBAy08iWNCnC5ARApYaio89xw88wwcOGC3XXutnZ97rp3XqwfdusHXX8NFF8Enn0BsrHM1i4iIyLHefRfWrIEyZeC++5yuJuBpxEnEX2Rnw9tvQ61a1nnnwAFo2BC++86C0aHQBDZ1b+FCqFwZVq6ECy+E+fOdqlxERET+Kz3dZokAPPIIREU5W48oODkqJweeego2bnS6EvF1X30FDRpAr17wzz9QtSpMnQqLFsGllx7/a+rXt39v3Bj27YMrr4TJk4u0bBERETmBN9+ETZugQgW4806nqxEUnJz1ySc2bzUuDnr2tCv/Iqdi6VK4+mr7WLoU3G4YM8YaQtx8s61rOpkKFWyk6aabIDMTeveGQYNs9EpERESccfAgjBhhx489BhERztYjgIKTsypWhFatbOHfO+/YVKpOnWDJEqcrE2/3zz9w221wwQU22hQaai1K162z4FOsWP4fq3hxmD798OLTceOgQ4fD66NERESkaL3yCmzfbjNIbr/d6WrkXwpOTmrc2Bbn//KLrTnxeODDD23KVdu2tgZF5EhJSbZ+KS4O3nrLXjOdOsGKFdYQIibm9B7X5YInn4T334fwcBsNbdHCpgiIiIhI0UlOhlGj7PiJJ+zvsngFBSdv0KQJfPwx/PWXdToLCoK5c+Hii+GSS+DLL+0NsgSuzExrHx4bCyNH2hB+8+bw00+2v0PNmgXzfbp0sal75crZ1L8mTeDnnwvmsUVERCRvEybAnj32N//WW52uRo6g4ORN6taF996D1auhb18IC4MFC6B1axudmjnTGkpI4PB4bA+m886zPZl277bRpo8+gu+/h6ZNC/57XnihNY04/3zbC+rSS2HatIL/PuL/Dr1+58/XxR8RkfxISICxY+142DAI0c5B3kTByRvVrAmvvQbr18ODD9qCwN9/h44dLVy9+66NQIh/W7TIRhzbt7dmD2XKwMSJtnv4DTfY9LrCUrWqTRVt187aoXbrBkOHKrhL/u3cCdddZ6/fSy+1kD97tl5DIiInM368hac6daBzZ6erkf9QcPJmlSrZD9DGjbauxe22tSy33mp79bz6KqSlOV2lFLQNG6BrVxv5+f57a/TwyCOwdi3cc481gigKkZE2yjlokJ0PH25T+VJTi+b7i+/65BMbJf3sMxs5L17cLgS0b28jmdOmWVMcERE5bM8eW68Mtl1NcLCz9cgxFJx8Qdmy9qZ182ZbLFi2rIWpO++Es8+GZ5+1hYTi2/btgwEDoHZt63LncllIXr3a/r+73UVfU3CwtTefPNkC2wcf2CjYtm1FX4t4v5QU6NfPRip377bw9Ntv9vvq0UchOhr+/ttGMM85B15/3UY0RUTE/t4mJ9s+ix06OF2NHIfL4wm8iedJSUm43W4SExOJjo52upxTl5pqm6KNHQtbtthtpUvD/ffbiETp0s7WJ6cmPR1efNGaPuzfb7ddcYX9/61f39najrRggU0R3LvXRkPnzLEOkCIAv/5qgWjNGjsfMMD2IDmyNX5CgjU5ee45u7IKti3DgAG2rjMyssjLFhHxCtu321KNgwdttL5tW6crCij5zQYacfJFERFw7702devNN61ZwL591rKyWjV46CHYscPpKiUvHo+NLMXHw8CBFprq1oXPP7c29d4UmgBatrTW+fHxto/UxRfbVD4JbFlZFpCaNbPQVKkSzJtn+4H9dz+xkiVt5GnTJnjhBahc2UYvBwyA6tVtZP3QxQMRkUDy9NMWmi66CNq0cboaOQGNOPniiNN/ZWfb/k9PP20tpMF6/vfubSGqWjVn65NjLVhgYenXX+28QgV709izp/fPaU5MhJtuso13wV53jzxSuM0qxDutXw/du8OPP9r5TTfZpo35HfXOyLBmN6NH24UgsFGnu+6yxjjlyxdO3SIi3mTTJrsInpkJ33wDl1/udEUBRyNOgSQ42Dqv/PEHfPqpXa1ITz+870/PnrBypdNVClh3vPbtbZ3Qr79CiRLWbnTNGgu63h6awNZaffaZTQsFG0Ho2VNrVQKJxwPvvAMXXGChKTraAtD06ac2VTgszF73K1fa19arZ/P7x4yxEai779YmzCLi/0aMsNB02WUKTV5OI07+MOL0Xx6P7ZsycqRNmQEbDejY0d7ketsUsECwaxc8+aQths/OtoB0++12my9fVX/5ZbjvPntOzZvbRs5lyzpdlRSmvXutAcSHH9r5xRfDlCkWdM6Ux2OhfOTIwxsvh4TY2qlHHrHGKSIi/mTtWvvdlp0NP/xg056lyGnEKZC5XLZvytdf25qU66+3NyQffmiL+du2tT16pPClptqbwJo1bQpTdrbtbfPXX9ZO3pdDE9iUqrlzbRTqhx+gSRPrmib+6euvbVToww8t0IwaBd99VzChCex317XX2ijWd9/BlVfaGqp33oFzz4Ubb7Q97URE/MWwYfbeoG1bhSYfoODk75o0gVmz7I16t24QFGRvdC++2KaLffmlhSopWNnZ8NZbtt/WkCE2/ahhQ3szOGeONVjwF1deaaMDNWta2+lmzazBhfiPtDRbc3TVVdbM4Zxz7P/5I48UzvTSQxd/vvrK9n/q0MF+T330ETRqBK1b2x5nIiK+bPlymDrVjp96ytlaJF8UnAJF3brw3nu2J1Dfvra2YMECewPSuLF1R8vJcbpK//DVVzayd9tt1n2uWjX7xbhokb0Z9Ee1a9vo5iWXwIEDNqr2/PMK5f7gzz8trDz/vJ3fdRcsXmwXAorCod9Pf/8Nt9xiQe3LL63L48UX24Ugvc5ExBc98YT9/rrhhqL7nSpnRMEp0NSsCa+9Zt2wHnzQWpv//rutf6pb1xZ4Z2Y6XaVvWroUrr7aPpYutelrY8fawvebb7bRPn8WE2Oh8fbbLYQ/+KCthdHryTfl5Njm2k2awLJlcNZZtv7opZfs90ZRq1PHfj+tXm2vq7Awm3Lctq294fjwQxvpFRHxBUuW2O8tl8um64lP8PN3cnJClSrB+PE2tWrIEHuTv2IF3HqrTS979VWbniN527oVevWyDmNffQWhofDAA7BunbUc/+9eNv4sLMwaYDz7rP0xeP11G9Xct8/pyuRUbNkCrVrZ6zcjA9q1s+m+3rAh49ln23rBDRts/6cSJewNSKdOFq7eflthXUS839Ch9rlrV7twLT5BXfX8save6UhMtDcj48fD7t12W4UK9sbkjjtsbxU5WlKStU0eP942rQPbx+bpp21kL9B9+qn9QUhOtv0pPv3UQrl4t//7PxvRSUiwkaXnn7dRRG/dp2vvXpg4ESZMOLx5btWqMGiQtTovXtzZ+kRE/uvnn23rmOBgW+ekv42Oy282UHBScDpaaiq8+aZNMduyxW4rXRruv9/27TmVPVr8VWYmvPGGtRI/FDKbN4dx46BpU0dL8zpLl9p6p82boVQpm5agPSq8U2Ki/Yy/956dN2lix3FxztaVXwcO2DTkZ5+FHTvstrPOgv794c47ba8pERFv0KqVbXR72232nkscp+B0EgpO+ZCRYW+aRo+2zVnBRp3uusvWrvh6G+3T4fFYR7yHH7aNbMHeVD7zjG1q661X5J22c6d1RfvpJ2th/dJL1qBEvMeCBdC9uwXcoCCbvjtkiE079TVpadbRcswYm4oMNhX53nvtAlCZMo6WJyIB7rvv7AJiaKit2Syo7RzkjGgfJzkzYWF2JWTFCpg+3fZuSU62NyM1atiV6U2bnK6y6CxaZB3j2re30FSmDLz4oi2a79BBoelkypWDb7+1dvhZWTb184EHtJDfG2RkwODB1u1x82ZbP7RwoS1U9sXQBLam8M477Q3JlCnW+j8xEUaMsA6X/ftbt0sRkaLm8cDjj9tx374KTT5II04accofj8c6ao0caXNzwUYPunWzvVxq13a2vsKyYQM8+qiFR7A3ZQ8+aKNObreztfkaj8fWfw0ZYudt2th/V/0MOmPFCvv5XbLEzm+7zdYzRUU5WlaBy8mxveyefvrw5rmhodCzJzz0EMTGOlmdiASSL76wv33FilkDqYoVna5I/qURJylYLhdcey38+KMNM7dqZaMH77wD555rHa0OvQHzB/v2WWOM2rXtzb3LBT162FXsp59WaDodLhc89hh88IEt2J871zbL3bDB6coCi8dj0yUbNLCf2dKlbWPZN9/0v9AENvXwhhvg119t/6dLLjm8TvGcc2yrgL/+crpKEfF3Hs/hC4d3363Q5KMUnOTUuFw2refrr23D0+uvt18GH35ob8TatoUffnC6ytOXnm6Ly2NjrVteRoaFxMWLrc1xlSpOV+j7brzR1tRUrGhTHZs08e3XjC/ZsQOuucam2qalwVVXWWi44QanKyt8Lpc93//97/D+Tzk58P77NhX5+uvtd5qISGGYPdtGvUuUsFkr4pMUnOT0NWliU2D++uvwBq9z50KLFnZV96uvLFT5Ao/HRpbi423vmv37bV+FuXPteVxwgdMV+pdGjWzdWIMGsGePLZR9912nq/Jvs2fDeefZazo83Np3z50bmFc9mze3qcdLltgWAi6XNX5p2hSuuMK6XfnK7y4R8X45OYfXNj3wAJQt62g5cvoUnOTM1a0LU6faNLa+fa2xxIIFcPXV0LgxzJxpvzS81YIFcOGFtufQhg22f9WkSfDHH7Z5qxo/FI5Kley//Q032MjerbfaejJvfq34ouRk6NPHGpvs2QPnn29XPe+91y52BLILLrB9q1autDVeISHWyKRVKwtRc+bo9SgiZ27GDPj7b5vmP2CA09XIGQjwv5pSoGrWtH1U1q+3BgoREfYGrWNHC1fvvmvrorzFqlX2ZvKSS2z9Q4kS8NRT1n69d2/bmE4KV4kStubp0UftfNQom8qXkuJsXf7il1+gfn27EOByWTOEX36BOnWcrsy71Kpla7zWrbNAWayYjYhef70FzWnTvOt3l4j4jqwseOIJOx440PY0FJ+lrnrq6FV4du+26UATJ1o7YLBW5g89ZB2tihVzpq5du2zz2tdft5bYwcFw++12WyDuT+Ut3nvPAmtGhr3ZnzMHKld2uirflJVlTUyeespe41WqWGvuSy91ujLfsGuXdRh86SVISrLbzj7b1iX06GFTHUVE8uOtt2xEOybGZrX4YxMeP6ANcE9CwamIJSbCK69Ys4Xdu+22ChVsuPqOO2xj3aKQmgrPPWeb+iYn223XXWcb2MbHF00NcnI//mijgLt322tk9myb7in5t24d3HLL4W0DunaFl1+GkiUdLcsnJSTYf7vnnrNpjmBrwgYOtGnJJUo4Wp6IeLmMDBvR3rQJxo613x3ilRScTkLBySGpqTYdZuxY2LLFbitdGu6/37p8lS5dON83O9uutj/++OGNLxs1sjp0Bd77bNxogfbvv21UcsoUa3cvJ+fx2JXN++6zqY5ut73pv/lmpyvzfSkpNt1x7NjDv0NiYg7/7tLUGxE5nldegbvustks69bZEgbxStrHSbxPRIStH1i71gJUXJztl/TEE1Ctmk2D2bGjYL/nV19Z57bbbrM3PNWq2XqFX35RaPJW1atbe/JrrrGW2TfdBMOHq8vZyezZY2sJe/e2N/mXXAJ//qnQVFBKlLCQtG6dBajYWNi7F4YOtd8pjzwCO3c6XaWIeJODB2HECDseMkShyU8oOEnRCwuzILNihbUAr1fPps6NGWNroO65x4a1z8TSpdbV7+qr7bhkSbtavHKlTV0K9G5i3i462qbpPfignQ8datPP0tKcrcsbffmltRn/+GMIDbWpp998Y2/opWCFh1s4XbnS9n867zw4cMD+m1evXjC/u0TEP7z6KmzbBlWr2jpq8Qt69yjOCQ6Gzp2t7fcnn1j737Q0W5AdGwu9etkblFOxdat93QUX2GhTaKi9+V671uYWO9WQQk5dcLCti3v9dWsTPW2ajRIW9Kikrzp40KbltW5t/03i420k9aGH1BGysAUHQ5cuNqp3vN9dPXue+u8uEfEfycnWJRbswp8ayvgNBSdxnssF115rjQEO7aGSlQVvvw3nnmvrW5YsOfljJCXZUHitWvZ1Ho9N8Vqxwt58x8QUxTORwtCnj4XgUqUsGDRpYqOIgWzJEmjY0DpWgk2B/f1360YoRefI313ffQdXXmm/u9555/DvrsWLna5SRIraxInW5Cg21vYoFL+h4CTew+WCyy6Dr7+2N8jXX28B6MMPbZ1S27a29uVImZm2AD42FkaOtKvwLVpYR7H/+z/bW0p832WX2WuiVi1rLNKsmV3pDzTZ2Tal9cIL7aJA+fIwd661/S9e3OnqApfLZaOhX31lr9P27Q//7mrYENq0ge+/d7pKESkKCQn2expsm5PQUCerkQKm4CTeqUkTmDUL/vrLFrgHBdkbxBYtbOH7V1/ZGpjzzoO777YrO3Fxts5jwQJ7Yyn+JS7OAvEVV1gDhOuvh3HjAqdpxObN9twfftguGLRvbz8frVs7XZkcqUkT+z3099+2Li84GL74Alq2hIsvtuNAec2KBKLnnrPwdO65NqVX/IrakasduW9Yt84WYL/9tr1pPFKZMnZVp29fXdkJBJmZtrbn1Vft/LbbrOVrWJizdRWmadOspW1ionV4mzDB1vK5XE5XJnlZv96uPr/1lu3pAjal8tFHoUMHrUcT8Sd79thm2QcO2Ihzx45OVyT5pHbk4l9q1rQmAevXW7OHiAhr9PDooxaq7r5boSlQhIba9MwXXrCRyMmT4aqrrD20v0lIsBHXbt0sNDVtag0JbrtNoclXnH22hfwNG2zT7xIlbI1ap05Qp87xLwaJiG8aM8ZCU/36dmFE/I5GnDTi5JsSE229R2Ftmiu+Ye5c68x44ICF608/hdq1na6qYPzvf7aoeMsWG5UYOtQuFISEOF2ZnIm9e23h+IQJsH+/3Va1qnVDvO02rVUT8VXbt9vfoYMH7W/RNdc4XZGcAo04iX9zuxWaxBbd//ST7f+1bp2NyHz1ldNVnZn0dHsTffnlFppiY60pytChCk3+ICbGphZv2mRXp8uVs/Vr99xje0E984x1CRUR3zJqlIWmpk2tmZX4JQUnEfFtdepYJ7MWLWwksm1b20/HFy1bZo1Nxo61BgJ9+ti0LjU78T9RUTBoEGzcaFNPq1WDXbvgkUfs+PHHbfPMnBynKxWRvGzeDK+9ZscjR2oqtR/TVD1N1RPxD+npcMcdtocO2Lq355/3jVGanBx48UUbaUpPt4YnkyZZ50AJDJmZMH26XbVeseLw7S4XREdDyZL24XYfPs7PbW63b/wMiPiyvn3hjTds64xvv3W6GjkN+c0GCk4KTiL+w+Ox6U+DB9vxVVfZfl4lSzpd2Ylt22ZrW7780s7btLGGF+XLO1uXOCMnx7ZiGD0afv21YB4zMvL4ASs/IczthvDwgqlDxB+tXWtra7OzYeFCaN7c6YrkNCg4nYSCk4ifmzXLOtGlptoftE8/9c7NkGfOtCuVe/dal8hnn4U779Q0DzFpaTb9NDHROiwe+ZGf21JSCqaOYsVObZTrv+fFi+s1Lf7rlltg6lS76PX5505XI6dJwekkFJxEAsCSJdCuHWzdagvyZ860TUi9wYED8MADNrIE0KABvPcexMc7Wpb4mcxMazSRV8A6UQhLTCyYOkJDT3+qYcmSNmKm4CXeJisL+ve3LpkAv/0GDRs6W5OctvxmA018FhH/VL8+LFpk64R+/RVatbL9dG67zdm6fvrJrlCuX29vBh9+GIYN8+8NfMUZoaF20SAm5vS+PjvbQv6pjHL997acHAtwu3fbx+kICjq1wFWxIjRqZF8nUhiSkqBLF9sSA6yhj0JTQFBwEhH/VaECzJ8PPXvCjBnQu7ctvB892vZGKkqZmTBihH3k5NjePe++6z2jYCL/FRx8OJCcDo8HkpNPf6phQoL93OTk2J5Xh/a9yo927eznS7NKpKBt3AjXXmtdUIsXt9dZx45OVyVFRFP19EtVxP95PDaqM2yYnV93nc1Jj4oqmu+/Zg10725t08FGnF580a6Oi8jxeTy2zutUpxouWWLdKc89F+bM8c71jeKbfvoJ2re3rQMqVLDXV6NGTlclBUBrnE5CwUkkQE2fbqNP6elQr5790atWrfC+n8cDb75p65lSUuzK/Suv2BQPESkcixbZm9vt26FUKRttbtXK6arE173/PvTqZX8/LrgAPvkEKld2uiopIPnNBpoALCKBo0sXm7pXrhwsXQpNmsDPPxfO99q9Gzp0sE1sU1Jsf4+lSxWaRApbkya2UL9JE5ve17o1TJhgFzJETtWhGQs332yhqV07+P57haYApeAkIoHlwgvtivT559t0i0svhWnTCvZ7zJ0L550Hs2db04dx42DePKhSpWC/j4gcX8WKdpHk1lutycX998Ptt9sbX5H8SkuzrS2efNLOBw60Dq2RkY6WJc5RcBKRwFO1qm1U2K6dvZHq1g2GDrVF6GciNRXuuQfatoWdO6FOHQtpAwaow5dIUStWDN5+G8aPt5+/yZNt5HfHDqcrE1+wcydcfrlN0QsJgTfesO55Rd1YSLyK/pKLSGCKjLQrh4MG2fnw4TaNLjX19B5v8WJrR/vSS3b+wAM2Xej88wukXBE5DS4XPPigbUxasqQt7m/c2H42RU7k779tdsJPP9nr5ssvbcRSAp6Ck4gEruBgGDPGrkSHhsIHH8All8C2bfl/jOxsa29+4YWwcqVNEfrqK3juObviLSLOu/pqG/2tXds2xb744oKfoiv+4YsvoFkz2LQJYmOtG+rllztdlXgJBScRkV69bA1STMzhReWLF+f9dRs32tSfwYNtF/mOHa0BxJVXFnrJInKK4uKsGcw11xxeu/LII3bxQwRsm4hrrrGNny+5xF4vtWo5XZV4EQUnERGwjWh/+QXi4+Gff+yK9MyZx7+vxwPvvWfT8L7/3qb9vf22jVjFxBRp2SJyCtxua9ryyCN2/swzttYxMdHZusRZWVm2PvXee22ta69eNnNAv8/lPxScREQOqVnT5rRfdZWtderYEUaNOrqN8f790LWrbWiblGRTOv78E3r0sPUUIuLdgoPt53raNJtO+/nn0LQprF7tdGXihMRE2xT9pZfsd/gzz9j+e2FhTlcmXkjBSUTkSG43fPaZXX0EePTRw5vmfvutbZz7f/9nXZZGjLCWx2ef7WjJInIauna17pqVK9v6xCZNrAmABI4NG6B5c1vXVLw4fPQRPPSQLoLJCbk8nsDbES6/uwOLSIB7+WW47z5bAxEbC2vX2u21atlUvcaNna1PRM7cjh02uvzjj9a2fMwY6N9fb5793Y8/Qvv2tll5xYowZ451RpWAlN9soBEnEZETuesu28zW7T4cmvr1s8YRCk0i/qF8eRtNvu02W98ycKBNvU1Lc7oyKSzTplmnvN27oX5967io0CT5oOAkInIyV15pnZV694ZPP4VXXoESJZyuSkQKUng4TJoEEybYGqh33z31rQnE+3k88OST1lExPd1GnL7/HipVcroy8RGaqqepeiIiInLIN99Ap07WCKZCBfj4Y9unTXzbwYM2qjh9up0/9JA1CQnSGIJoqp6IiIjIqbviCvj1V6hTB7Zvt5GnKVOcrkrOxM6dNjVv+nRr7DNpknXPU2iSU6RXjIiIiMiRDm1NcP31NqWrRw9b+5SV5XRlcqr++ss6Jv78M5QqBV9/bVOvRU6DgpOIiIjIf0VF2SbYQ4bY+bPPwrXX2hQ+8Q2ff27txjdvhrg4C0+XXup0VeLDFJxEREREjicoCIYPhxkzICLC9nm68ELb90m8l8djjT6uuw4OHLCw9PPPtpWEyBlQcBIRERE5mU6d4IcfoGpVWLPGwtPnnztdlRxPVpZtYH7//dZe/rbbLPCWLu10ZeIHFJxERERE8nLBBdY04uKLISnJpu0984yNboh3SEyEa66xzctdLtvMeNIkCAtzujLxEwpOIiIiIvlx1lkwbx7ccYcFpkcegVtusVbX4qz166FZM/jqK5tWOXMmDBpkAUqkgCg4iYiIiORXWBi8+qqNaoSEwLRpNgq1davTlQWuH36w6ZPLl0PFirapbfv2TlclfkjBSURERORU3XmnjT7FxMDvv0OjRvDjj05XFXimTrU9mvbsgQYNYNEi+yxSCBScRERERE7HJZfAb79BvXq2yepll8HkyU5XFRhycmDoUJsqmZEBHTrAggVQqZLTlYkfU3ASEREROV3Vq9tUsY4d7Q18797W0U2b5Raegweha1drFQ/w8MPw4YdQooSzdYnfcyw4zZ49m/j4eKKiomjTpg0bNmw46t/nz5+Py+U65iMxMZGMjAzuu+8+ypYtS8WKFXnsscfIyclx6JmIiIhIQIuMtL2ehg2z8wkToHVr2LvX2br80Y4dNrI3Y4atMZs8GUaPtj23RApZiBPfdNmyZXTq1IkOHTrQr18/Jk6cSOfOnVm0aNEx9x09ejRlypTJPS9evDhPPvkkkydP5pFHHiElJYXRo0dTqVIl7rrrrqJ8GiIiIiImKMimjp13HnTvDt98A02awJw5UKeO09X5h6VLbVPbzZttX6aPPrLNbUWKiCPBad68eQQHBzN16lRCQkKIiYmhe/fuJCQkULJkyaPu26VLF6pVq3bUbXPnzqVr164MGTIEgF9//ZWvvvpKwUlERESc1aED/PQTXH+9tchu2hTee8/O5fR99hl06QLJyVCrFnz6KcTFOV2VBBhHxjUTEhKIjIwkJMRyW6lSpQBITEw85r69e/cmKiqKunXrsmDBgtyvPzJglSpV6rhfe0h6ejpJSUlHfYiIiIgUivPOs+5ul11mb/Tbt4eRI7VZ7unweOCFF6BdO/tvedllFkwVmsQBXj8hNCMjg2HDhuFyuejcuTMHT2OTuVGjRuF2u3M/qlSpUgiVioiIiPyrTBn48ku45x47HzIEOneGlBRn6/IlmZlw993wwAPWRe/22+2/aenSTlcmAcqRqXr5Ub9+fRYuXMj5559PZGQk5557Lm3atGHlypWn/FiDBw+mf//+uedJSUkKTyIiIlK4QkNh4kRrV3733fDBB7BmDcyaBf9ZhiD/kZAAN90EX38NLheMHQv9+9uxiEO8NjhFR0fTvHnz3PNK//blTzmNKzXh4eGEh4cXWG0iIiIi+danD8THww03wB9/QOPG1tjg4oudrsw7rV8P114LK1ZARARMm6Y1YuIVHJmq53a7SU5OJuvfPQ72798PWFg65Pfff6dPnz7s2bMHgL3/tvSMiorC7Xbnfs2hr3e73UVVvoiIiMipadHCNsutXx9274bLL4fXX3e6Ku+zcCFceKGFpkqV7FyhSbyEIyNOrVq14qGHHqJbt240a9aMiRMn0qhRI/bs2cPMmTPp0aMHVapUYfr06axbt47rrruOyZMnU6tWLerWrUubNm2YOHEi1atXJyUlhe+++44JEyY48VRERERE8qdqVQsCvXrZPkR33AF//gnPP2/T+gLdu+/aOqaMDGjY0Fq5V6zodFUiuVwejzMtXmbNmsXgwYPZunUrzZs355VXXmHBggX07NmT5ORkSpQowfz58+nfvz/Lly+nYcOGvPHGG8THx5ORkcHAgQOZNm0aoaGh3HbbbQwfPpygfG5+lpSUhNvtJjEx8ahRLhEREZFC5/HAqFHWMMLjsb2IPvjAGkoEopwc2wNr5Eg7v+EGC1EREc7WJQEjv9nAseDkJAUnERERcdwnn8DNN1ub7erVYfZsayQRSA4ehJ49bQQO4JFHLEDl82K4SEHIbzbQq1JERETECdddBz//DDVrwsaN0KwZzJzpdFVFZ8cOG22bMcOmKr71lo3EKTSJl9IrU0RERMQpderYZrmtWtkeTx07wpNP2vQ1f7Z0KTRpYs+9dGmYN89GnkS8mIKTiIiIiJNKl4a5c22jV4Bhw6BTJ5vC548++wyaN4ctW+Ccc+CXX6BlS6erEsmTgpOIiIiI00JC4LnnYPJkCAuzKXvNmsGGDU5XVnA8Husg2K6dhcLLL4effoLYWKcrE8kXBScRERERb9GrF/zvf1CuHPz1l22W+913Tld15jIz4c474cEHbRpinz7wxRdQqpTTlYnkm4KTiIiIiDe56CLbLLdhQ9i7F668El5+2UZsfFFCArRtC6+9Bi4XPPusHWvvKvExCk4iIiIi3qZyZfj+e2tXnp0Nd98N/frZ5rC+ZN06C4Lz5kGJEjBrFvTvbwFKxMcoOImIiIh4o+LF4b334JlnLGi8/jpccQXs2uV0Zfnz/fdw4YWwcqUFwYULbX2TiI9ScBIRERHxVi4XPPQQfPopREdb+GjcGJYscbqyk5syxULe3r3QqJG1Hb/gAqerEjkjCk4iIiIi3q5tW2vbXasWbN5s7bxnzHC6qmPl5MCQIdCjhzWE6NgR5s+HChWcrkzkjCk4iYiIiPiC2rUtPLVuDQcPQufOFlK8ZbPc1FSraeRIO3/0UQt3ERHO1iVSQBScRERERHxFyZI2bW/gQDsfORI6dICkJEfLYvt2uPRS+PBD65b3zjtWW5Deaor/0KtZRERExJcEB8PYsbaOKDwc5syxznXr1jlTz59/WhOIX3+FmBj45hu49VZnahEpRApOIiIiIr6oe3dYsAAqVoTly61pxLx5RVvDJ5/YeqstWw5PJbz44qKtQaSIKDiJiIiI+KomTWykp0kT2L/f1j+98ELhb5br8cD48XD99ZCSYh30fvwRatYs3O8r4iAFJxERERFfVrGida679VbbLPeBB6B3b0hPL5zvl5lpm/EOGGAB6o47YO5cKFWqcL6fiJdQcBIRERHxdcWKwdtv2yhQUBC89RZcdhns2FGw32f/fmjTxjbjdbns+73yijWEEPFzCk4iIiIi/sDlggcfhM8/t+57P/1km8/+9lvBPP7atdaE4ptvoEQJmD3bvp/LVTCPL+LlFJxERERE/MnVV8OiRdas4Z9/rFnDtGln9pgLFljnvFWroEoV+OEHuO66gqlXxEcoOImIiIj4m7g4+PlnuOYaSEuDbt3g4YdtDdSpeucdaNUK9u2zzn2//ALnn1/wNYt4OQUnEREREX/kdtt0ukcesfMxY6BdO0hMzN/X5+TAo49Cz57WEKJTJ2tCUaFCoZUs4s0UnERERET8VXAwjBplU/WKFbP1T02bwurVJ/+61FS46Sb7WoAhQ2D6dChevPBrFvFSCk4iIiIi/q5rV1i4ECpXhpUrbd+nL788/n23b4dLLoGPPoKwMJgyBYYPt259IgFMPwEiIiIigaBhQ9sst1kzm67Xti08++zRm+X+8YeFqt9+g5gY66DXvbtjJYt4EwUnERERkUBRvjx8+61tkJuTAwMHQo8e1kBizhxo0QK2brWOfL/8YuciAig4iYiIiASW8HB44w2YMMHWQL37LtSrB+3bQ0oKXHml7QFVs6bTlYp4FQUnERERkUDjcsG999o6p9KlYc0am7LXrx989pltoCsiRwlxugARERERccgVV9hmuY89BpdfDn36WKgSkWMoOImIiIgEspo1rdW4iJyUpuqJiIiIiIjkQcFJREREREQkDwpOIiIiIiIieVBwEhERERERyYOCk4iIiIiISB4UnERERERERPKg4CQiIiIiIpIHBScREREREZE8KDiJiIiIiIjkQcFJREREREQkDwpOIiIiIiIieVBwEhERERERyYOCk4iIiIiISB4UnERERERERPKg4CQiIiIiIpIHBScREREREZE8KDiJiIiIiIjkQcFJREREREQkDyFOF+AEj8cDQFJSksOViIiIiIiIkw5lgkMZ4UQCMjgdOHAAgCpVqjhciYiIiIiIeIMDBw7gdrtP+O8uT17Ryg/l5OSwbds2oqKicLlcjtaSlJRElSpV2LJlC9HR0Y7WIv5PrzcpanrNSVHS602Kml5z/sHj8XDgwAEqVqxIUNCJVzIF5IhTUFAQlStXdrqMo0RHR+sHToqMXm9S1PSak6Kk15sUNb3mfN/JRpoOUXMIERERERGRPCg4iYiIiIiI5EHByWHh4eE88cQThIeHO12KBAC93qSo6TUnRUmvNylqes0FloBsDiEiIiIiInIqNOIkIiIiIiKSBwUnERERERGRPCg4iYiIiIiI5EHByUGzZ88mPj6eqKgo2rRpw4YNG5wuSfzc9OnTiY2Nxe12c/311/PPP/84XZIEgIYNG9KsWTOnyxARKVCff/45derUITIykksvvZTly5c7XZIUMgUnhyxbtoxOnTpRr149RowYwZo1a+jcubPTZYkf+/vvv+nevTtxcXE8+eST/Pnnn3Tt2tXpssTPffnllyxevJghQ4Y4XYoEkI4dO1KxYkXS0tKcLkX81IYNG+jYsSPVq1fn6aefZvfu3bRv3x71XPNvIU4XEKjmzZtHcHAwU6dOJSQkhJiYGLp3705CQgIlS5Z0ujzxQ3/++SfnnXceH3/8McWKFaNMmTLceuutJCYm5mu3bJHT8fTTT1O/fn3atm3rdCkSIP78808+/vhjJkyYQLFixZwuR/zUggULSEtL4/333yc6OpoaNWrQrl07tmzZQtWqVZ0uTwqJRpwckpCQQGRkJCEhll1LlSoFQGJiopNliR/r1q0bixcvzn0jsXbtWkJDQ/XGQgrNDz/8wIIFC3jsscecLkUCyBNPPEGlSpXo06eP06WIH4uLiwPgjTfeYN26dbz//vu43W5iYmIcrkwKk0acRALQDz/8wKhRo7jvvvu0aZ8UmpEjRxIfH0+HDh247LLLKFOmDB988IHTZYkfW7JkCbNnz+b111/X7zYpVM2aNaNdu3YMHDiQgQMHAjB+/HhKlCjhcGVSmDTiJBJgduzYQadOnWjYsCFPP/200+WIn1qyZAlz587l0UcfJShIf2qkaAwfPhyAoUOHcs455yioS6H57rvvmDNnDr179+aDDz6gRYsWjBgxgn379jldmhQi/TUTCSBZWVl06tSJnJwcPvroI8LCwpwuSfzUqFGjqFy5Mm3atCExMZGsrCwyMjJIT093ujTxU1u3bmX27Nlce+21jB8/nkqVKtG9e3d27drldGnihz766COqVKnCG2+8wY033sjbb7/Nvn37+O6775wuTQqRpuo5xO12k5ycTFZWFiEhIezfvx+A6OhohysTfzZgwAB+/vlnvv32WypWrOh0OeLHfv31V7Zu3UqZMmWOun306NE88cQTDlUl/ux///sfOTk5vPfee7jdburVq0fdunVZvHgxrVu3dro88TNut5v09HQyMzMJCwsjOTkZ0Ps4f6fg5JBWrVrx0EMP0a1bN5o1a8bEiRNp1KhRbpMIkYI2a9YsJkyYwKWXXsrq1atZvXo1AJ07dyYyMtLh6sTfTJ8+/ahW0A888ABut5uePXs6V5T4tQMHDgCQlpaG2+0mIyMD0BtZKRydOnVizJgxXHvttbRp04ZXX32VKlWqcNFFFzldmhQil0cN5x0za9YsBg8ezNatW2nevDmvvPIKNWrUcLos8VPDhg3jySefPOb2jRs3Uq1ataIvSAKKmkNIYdu0aRPx8fHEx8fTqlWr3K0XlixZQnBwsNPliR/65JNPGDx4MBs3bqRx48ZMnDiRunXrOl2WFCIFJxEREfEL8+fPZ8iQIezYsYOmTZsyevRoKlWq5HRZIuInFJxERERERETyoK56IiIiIiIieVBwEhERERERyYOCk4iIiIiISB4UnERERERERPKg4CQiIiIiIpIHBScREREREZE8KDiJiIiIiIjkQcFJRER8ksvlOu7H7NmzC/x7zZ8/H5fLxbJlywr8sUVExDeEOF2AiIjI6WrXrh3t2rU76rYLLrjAmWJERMSvKTiJiIjPatCgAb1793a6DBERCQCaqiciIn5n2LBhlCxZkttvv52SJUsSHx/P/Pnzc//9jTfeoGLFioSHh3PJJZewadOm3H97+eWXiYuLo3jx4rRs2ZJ169Yd9W+VK1emXLlyTJw4sUifk4iIOEvBSUREfFZycjI7d+7M/UhKSsr9t8TERP755x+GDBlCeno63bp1Izs7m4ULF9K3b19atmzJyJEj2bBhA507dwbgtdde4+677+biiy9m5MiRHDhwgE8++ST3MRcsWMCgQYM455xzuO+++1i6dGmRP2cREXGGy+PxeJwuQkRE5FS5XK5jbrv99tt54403GDZsGMOHD2f//v1ERUXx7rvvcuutt7J9+3bGjBnD//3f/7F161ZcLhfTp0+na9eubN26lc6dO1OsWDHmzZsHQE5ODkFBQcyfP59LL72U+fPn07JlSzZv3ky1atV49913ueWWW4r6qYuIiAO0xklERHzWLbfcclRwqVy5cu5xVFQUUVFRAJQuXRqAjIwMkpKSKF++fG7wKleuHAAHDhxg586dtG7dOvcxgoKOnpgRExNz1Ofs7OyCfkoiIuKlFJxERMRnxcbGcvXVVx/335KSkjhw4ABRUVHs27cPgLCwMNxuNzt27MDj8eByudixYwdgQeuss85i5cqVuY9xaMRJREREwUlERHzW4sWLefPNN4+6rVWrVoCFnhtvvJFWrVrx8ssvU6lSJcqWLcsNN9zA+PHj6dq1K40aNWLChAlceOGFVKpUiVtuuYW77rqL3r17U7duXaZMmUKvXr04//zznXh6IiLiRRScRETEZ82ZM4c5c+YcddusWbMAcLvdnHPOOYwePZqKFSvy8ssvExwcTPPmzZk8eTJDhw5l1qxZNGvWjEmTJgFw5513kpOTw/PPP8+0adNo2rQp1157LVu2bCnqpyYiIl5GzSFERMTvDBs2jBdffJHdu3c7XYqIiPgJTdwWERERERHJg4KTiIiIiIhIHjRVT0REREREJA8acRIREREREcmDgpOIiIiIiEgeFJxERERERETyoOAkIiIiIiKSBwUnERERERGRPCg4iYiIiIiI5EHBSUREREREJA8KTiIiIiIiInn4f6CO1GBrs3jOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(training_losses, color=\"orange\", label=\"training loss\")\n",
    "plt.plot(validation_losses, color=\"red\", label=\"validation loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe3dd0-951e-48fc-aca2-4b95f40d966f",
   "metadata": {},
   "source": [
    "### Accuracy metrics after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d0f803-c2b1-4bc8-a2e7-6ba22ef76dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIMINATION: Accuracy: 0.910, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "AGGREGATION: Accuracy: 0.533, Precision: 0.533, Recall: 0.998, F1-score: 0.695\n",
      "TYPIFICATION: Accuracy: 0.767, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "DISPLACEMENT: Accuracy: 0.819, Precision: 0.819, Recall: 1.000, F1-score: 0.900\n",
      "ENLARGEMENT: Accuracy: 0.756, Precision: 0.756, Recall: 1.000, F1-score: 0.861\n",
      "SIMPLIFICATION: Accuracy: 0.791, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n"
     ]
    }
   ],
   "source": [
    "# switch to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# stores the confusion matrices for every operator\n",
    "metrics = {}\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    metrics[operator_name] = {}\n",
    "    metrics[operator_name][\"tp\"] = 0\n",
    "    metrics[operator_name][\"fp\"] = 0\n",
    "    metrics[operator_name][\"tn\"] = 0\n",
    "    metrics[operator_name][\"fn\"] = 0\n",
    "\n",
    "# prediction evaluations should not be part of the computational graph, gradients should not be tracked\n",
    "with torch.no_grad():\n",
    "    for block, eli, agg, typ, dis, enl, sim in validation_loader:\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # prediction on the trained model results in logits, sigmoid needs to be applied to obtain probabilities\n",
    "        pred_operators_logits = model(block)\n",
    "        pred_operators = torch.sigmoid(pred_operators_logits)\n",
    "        pred_operators_labels = (pred_operators > 0.5).float()  # thresholding\n",
    "\n",
    "        # calculating metrics for the individual operators\n",
    "        for i, operator_name in enumerate(operator_order):\n",
    "            operator = operators[:, i]\n",
    "            pred_operator = pred_operators_labels[:, i]\n",
    "\n",
    "            tp, fp, tn, fn = calculate_conf_matrix(operator, pred_operator)\n",
    "\n",
    "            metrics[operator_name][\"tp\"] += tp\n",
    "            metrics[operator_name][\"fp\"] += fp\n",
    "            metrics[operator_name][\"tn\"] += tn\n",
    "            metrics[operator_name][\"fn\"] += fn\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    accuracy, precision, recall, f1_score = calculate_metrics(metrics[operator_name][\"tp\"],\n",
    "                                                              metrics[operator_name][\"fp\"],\n",
    "                                                              metrics[operator_name][\"tn\"],\n",
    "                                                              metrics[operator_name][\"fn\"])\n",
    "    \n",
    "    print(f\"{operator_name.upper()}: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f963fc6-62a7-4512-99dc-4277f8bf2b01",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "https://debuggercafe.com/multi-label-image-classification-with-pytorch-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "656d479a-fe64-49f1-966b-6127ca2fb2b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-30T11:32:21.514322Z",
     "iopub.status.busy": "2024-05-30T11:32:21.514045Z",
     "iopub.status.idle": "2024-05-30T11:32:21.766658Z",
     "shell.execute_reply": "2024-05-30T11:32:21.766106Z",
     "shell.execute_reply.started": "2024-05-30T11:32:21.514302Z"
    }
   },
   "outputs": [],
   "source": [
    "# save the trained model to disk\n",
    "if torch.cuda.is_available():\n",
    "    path_to_models = \"../scratch/raster/models\"\n",
    "else:\n",
    "    path_to_models = \"../data.nosync/raster/models\"\n",
    "\n",
    "type = model.__class__.__name__\n",
    "n_params = model.get_n_parameters()\n",
    "n_samples = len(training_set)\n",
    "# name the model should be stored under: type_nparams_nsamples_nepochs_batchsize.pth\n",
    "model_name = f\"{type}_{n_params}_{n_samples}_{n_epochs}_{batch_size}.pth\"\n",
    "\n",
    "torch.save({\n",
    "            \"epoch\": n_epochs,\n",
    "            \"model_state_dict\": model.state_dict(),\n",
    "            \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            \"loss\": criterion,\n",
    "            }, os.path.join(path_to_models, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35044e0b-5696-4bef-9f99-ffe005fa3de8",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "* Investigate effect of building size on the prediction quality? Other \"confounding\" factors.\n",
    "* See whether including the roads actually increases the prediction performance.\n",
    "* Investigate effects of imbalanced data / operator distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

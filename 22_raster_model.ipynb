{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f613cb6e-9dde-45a0-b730-a6883df55bb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T16:53:37.818633Z",
     "iopub.status.busy": "2024-05-11T16:53:37.818239Z",
     "iopub.status.idle": "2024-05-11T16:53:40.465576Z",
     "shell.execute_reply": "2024-05-11T16:53:40.465153Z",
     "shell.execute_reply.started": "2024-05-11T16:53:37.818615Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from auxiliary.visualization import plot_raster\n",
    "from auxiliary.evaluation import calculate_conf_matrix, calculate_metrics\n",
    "from model_components.unet import *\n",
    "from model_components.resunet import *\n",
    "from model_components.attunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb5a9c3-c82b-49fb-8cce-dd26809ce1af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-11T16:53:40.472176Z",
     "iopub.status.busy": "2024-05-11T16:53:40.471925Z",
     "iopub.status.idle": "2024-05-11T16:53:40.623396Z",
     "shell.execute_reply": "2024-05-11T16:53:40.623039Z",
     "shell.execute_reply.started": "2024-05-11T16:53:40.472161Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA.\n",
      "Device set to: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, then MPS, otherwise use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA.\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU.\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227e4d6e-8982-412a-adaf-57a6035fc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8f8d99-729f-4680-96a5-b7b6bfdc5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots\n",
    "plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af7673-18d4-4d02-b65b-7b50406faed5",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dda95da-6983-416f-b00f-fbe4bd018f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a Dataset object for DataLoader\n",
    "class BuildingRasterDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        '''Loads and unpacks the data from the compressed .npz format'''\n",
    "        data = np.load(path)\n",
    "        \n",
    "        # Read raster maps\n",
    "        blocks_rasterized = data[\"blocks\"].copy()\n",
    "        # Read generalization operators\n",
    "        targets_eli = data[\"elimination\"].copy()\n",
    "        targets_agg = data[\"aggregation\"].copy()\n",
    "        targets_typ = data[\"typification\"].copy()\n",
    "        targets_dis = data[\"displacement\"].copy()\n",
    "        targets_enl = data[\"enlargement\"].copy()\n",
    "        targets_sim = data[\"simplification\"].copy()\n",
    "        \n",
    "        # Read target uuids\n",
    "        self.uuid = data[\"uuids\"].copy()\n",
    "\n",
    "        # Check whether all parts have the same dimensionality\n",
    "        assert blocks_rasterized.shape[0] == self.uuid.shape[0] == targets_eli.shape[0] == targets_agg.shape[0] == targets_typ.shape[0] \\\n",
    "        == targets_dis.shape[0] == targets_enl.shape[0] == targets_sim.shape[0]\n",
    "\n",
    "        # Convert numpy array to tensor with shape (n_samples, 3, height, width)\n",
    "        self.block = torch.from_numpy(blocks_rasterized).float()\n",
    "        \n",
    "        # Convert generalization operators to tensor\n",
    "        self.elimination = torch.from_numpy(targets_eli).float()\n",
    "        self.aggregation = torch.from_numpy(targets_agg).float()\n",
    "        self.typification = torch.from_numpy(targets_typ).float()\n",
    "        self.displacement = torch.from_numpy(targets_dis).float()\n",
    "        self.enlargement = torch.from_numpy(targets_enl).float()\n",
    "        self.simplification = torch.from_numpy(targets_sim).float()\n",
    "\n",
    "        # store transformation\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Enables dataset length calculation'''\n",
    "        return self.uuid.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Enables indexing, returns uuid and block raster as features and generalization operators as label'''\n",
    "        uuid = self.uuid[index]\n",
    "        block = self.block[index]\n",
    "        eli = self.elimination[index]\n",
    "        agg = self.aggregation[index]\n",
    "        typ = self.typification[index]\n",
    "        dis = self.displacement[index]\n",
    "        enl = self.enlargement[index]\n",
    "        sim = self.simplification[index]\n",
    "\n",
    "        if self.transform:\n",
    "            block = self.transform(block)\n",
    "\n",
    "        return uuid, block, eli, agg, typ, dis, enl, sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f523-0e33-403f-bf0e-7a25aa95fa6c",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "\n",
    "1) Design model (input, output size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "     * Forward pass: Compute prediction\n",
    "     * Backward pass: Compute gradients\n",
    "     * Update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e688e5-9a9b-45ab-a10c-02a15ad36770",
   "metadata": {},
   "source": [
    "### Model design\n",
    "\n",
    "Stride refers to the number of positions that the convolutional kernel shifts at one step. Input channel size of one layer should always be equal to the output channel size of the previous layer.\n",
    "\n",
    "The application of convolution and pooling layers decreases the size of the image: The output after a convolution can be calculated according to the following formula, where $W$ is the input width, $F$ is the kernel size, $P$ is the padding and $S$ is the stride:\n",
    "\n",
    "$$\\frac{(W-F + 2 P)}{S} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc295f38-bae2-47cd-b2e3-9195931cdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected layers with Global Average Pooling\n",
    "class FCGlobalPooling(nn.Module):\n",
    "    def __init__(self, n_last_out_channels):\n",
    "        super(FCGlobalPooling, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        \n",
    "        # Due to the global average pooling, the number of input features corresponds to the number of output channels of the last\n",
    "        # convolutional layers\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(), # flatten to reshape the tensor from 4D to 2D\n",
    "            nn.Linear(in_features=self.n_last_out_channels, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Fully-connected layers without Global Average Pooling\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, n_last_out_channels, image_size):\n",
    "        super(FC, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # the number of input features of first fully-connected layer are calculated by multiplying number of output channels of last \n",
    "        # convolutional layer by (image size after all pooling operations)^2\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=self.n_last_out_channels*self.image_size*self.image_size, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb00b17-9dc9-44d0-b266-6e21f1da169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 34,882,675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AttUNet(\n",
       "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att5): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att4): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att3): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att2): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc): FCGlobalPooling(\n",
       "    (fc): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=1, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://amaarora.github.io/posts/2020-09-13-unet.html\n",
    "\n",
    "# conventional, simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        #self.fc = FCGlobalPooling(n_last_out_channels=128)\n",
    "        self.fc = FC(n_last_out_channels=128, image_size=32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input dimension = 256\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # input dimension = 128\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # input dimension = 64\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # input dimension = 32\n",
    "        x = self.fc(x) # No sigmoid function necessary, since BCEWithLogitsLoss applies sigmoid internally for loss computation\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for U-net adapted from https://github.com/milesial/Pytorch-UNet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, 1))\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # decoding + concatenation\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        x = self.fc(logits)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for Residual U-net adapted from https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(3, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        #self.sigmoid = nn.Sigmoid() # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(inputs)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(inputs)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        #output = self.sigmoid(output) # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Code for Attention U-net adapted from https://github.com/LeeJunHyun/Image_Segmentation\n",
    "class AttUNet(nn.Module):\n",
    "    def __init__(self,n_channels):\n",
    "        super(AttUNet,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=n_channels,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,1,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification        \n",
    "        output = self.fc(d1)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Creating model and moving to device\n",
    "#model = CNN(n_channels=3)\n",
    "#model = UNet(n_channels=3)\n",
    "#model = ResUNet(n_channels=3)\n",
    "model = AttUNet(n_channels=3)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {total_params:,}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52663f75-0732-4f3f-b55e-3a68eee493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary cross-entropy loss, applies a sigmoid internally and takes logits as input\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9f7ae-8c3a-434d-bb6e-4300eb067628",
   "metadata": {},
   "source": [
    "### Loss and activation function\n",
    "\n",
    "Softmax is a common activation function, (binary) cross-Entropy is a common loss function for multiclass classification problems, sigmoid is commonly used for binary classification problems. When using the Pytorch implementation: no softmax in the last layer, class labels not one-hot encoded and no softmax. BCELoss requires an activation function at the end! Sigmoid are usually the last layers in binary classification probems.\n",
    "\n",
    "If you don't know which activation function to use, just use ReLU, Leaky ReLU tries to adress vanishing gradient problem. Multiplies input with small negative numbers, as normal ReLU may cause many gradients to become zero, which means that the weights will never be updated. Whenever weights are not updated during training, use Leaky ReLU.\n",
    "\n",
    "I am dealing with a multilabel (for each generalization operator), binary (operator present or absent) classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2f78-e07d-4922-b9f3-b81ba80b9385",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ac2819-465a-4faa-a8e7-5e2cde507c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 finished, loss: 0.618\n",
      "epoch 2 finished, loss: 0.573\n",
      "epoch 3 finished, loss: 0.557\n",
      "epoch 4 finished, loss: 0.540\n",
      "epoch 5 finished, loss: 0.517\n",
      "epoch 6 finished, loss: 0.402\n",
      "epoch 7 finished, loss: 0.398\n",
      "epoch 8 finished, loss: 0.441\n",
      "epoch 9 finished, loss: 0.365\n",
      "epoch 10 finished, loss: 0.364\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "data = \"../training_samples.nosync/raster/raster_building_data.npz\"\n",
    "\n",
    "# composing various random transforms that should be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees=(0,360)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)])\n",
    "\n",
    "train_dataset = BuildingRasterDataset(data, transform=transform)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "\n",
    "# saving the losses from every epoch\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # tracking loss per epoch\n",
    "    train_running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for i, (uuid, block, eli, agg, typ, dis, enl, sim) in enumerate(train_dataloader): \n",
    "        n_batches += 1\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        pred_operators = model(block) # compute predictions, calls forward method under the hood\n",
    "        loss = criterion(pred_operators, operators) # calculate loss\n",
    "        train_running_loss += loss.item() # tracking running loss to keep track of the loss for every epoch\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update the parameters\n",
    "\n",
    "        # print information every few batches\n",
    "        if not (i + 1) % 5:\n",
    "            print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}\")\n",
    "\n",
    "    # print information at the end of each epoch\n",
    "    train_loss_epoch = train_running_loss / n_batches\n",
    "    train_losses.append(train_loss_epoch)\n",
    "    print(f\"epoch {epoch+1} finished, loss: {train_loss_epoch:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238cd359-67bd-41d2-8494-4034d198550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, color=\"orange\", label=\"training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe3dd0-951e-48fc-aca2-4b95f40d966f",
   "metadata": {},
   "source": [
    "### Evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d0f803-c2b1-4bc8-a2e7-6ba22ef76dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIMINATION: Accuracy: 1.000, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "AGGREGATION: Accuracy: 0.778, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "TYPIFICATION: Accuracy: 0.889, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "DISPLACEMENT: Accuracy: 0.778, Precision: 0.778, Recall: 1.000, F1-score: 0.875\n",
      "ENLARGEMENT: Accuracy: 0.778, Precision: 0.778, Recall: 1.000, F1-score: 0.875\n",
      "SIMPLIFICATION: Accuracy: 0.778, Precision: 0.667, Recall: 1.000, F1-score: 0.800\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BuildingRasterDataset(data)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# stores the confusion matrices for every operator\n",
    "metrics = {}\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    metrics[operator_name] = {}\n",
    "    metrics[operator_name][\"tp\"] = 0\n",
    "    metrics[operator_name][\"fp\"] = 0\n",
    "    metrics[operator_name][\"tn\"] = 0\n",
    "    metrics[operator_name][\"fn\"] = 0\n",
    "\n",
    "# prediction evaluations should not be part of the computational graph, gradients should not be tracked\n",
    "with torch.no_grad():\n",
    "    for uuid, block, eli, agg, typ, dis, enl, sim in test_dataloader:\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # prediction on the trained model results in logits, sigmoid needs to be applied to obtain probabilities\n",
    "        pred_operators = torch.sigmoid(model(block))\n",
    "        pred_operators_labels = (pred_operators > 0.5).float()  # thresholding\n",
    "\n",
    "        # calculating metrics for the individual operators\n",
    "        for i, operator_name in enumerate(operator_order):\n",
    "            operator = operators[:, i]\n",
    "            pred_operator = pred_operators_labels[:, i]\n",
    "\n",
    "            tp, fp, tn, fn = calculate_conf_matrix(operator, pred_operator)\n",
    "\n",
    "            metrics[operator_name][\"tp\"] += tp\n",
    "            metrics[operator_name][\"fp\"] += fp\n",
    "            metrics[operator_name][\"tn\"] += tn\n",
    "            metrics[operator_name][\"fn\"] += fn\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    accuracy, precision, recall, f1_score = calculate_metrics(metrics[operator_name][\"tp\"],\n",
    "                                                              metrics[operator_name][\"fp\"],\n",
    "                                                              metrics[operator_name][\"tn\"],\n",
    "                                                              metrics[operator_name][\"fn\"])\n",
    "    \n",
    "    print(f\"{operator_name.upper()}: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f963fc6-62a7-4512-99dc-4277f8bf2b01",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "https://debuggercafe.com/multi-label-image-classification-with-pytorch-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35044e0b-5696-4bef-9f99-ffe005fa3de8",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "* Investigate effect of building size on the prediction quality? Other \"confounding\" factors.\n",
    "* See whether including the roads actually increases the prediction performance.\n",
    "* Investigate effects of imbalanced data / operator distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcc3c9-902c-4ef0-ba6d-779b08e7cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genops",
   "language": "python",
   "name": "genops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

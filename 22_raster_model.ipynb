{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f613cb6e-9dde-45a0-b730-a6883df55bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchview import draw_graph\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from auxiliary.visualization import plot_raster\n",
    "from auxiliary.evaluation import calculate_conf_matrix, calculate_metrics\n",
    "from model_components.unet import *\n",
    "from model_components.resunet import *\n",
    "from model_components.attunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efb5a9c3-c82b-49fb-8cce-dd26809ce1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available, then MPS, otherwise use CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Device set to: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "227e4d6e-8982-412a-adaf-57a6035fc166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8f8d99-729f-4680-96a5-b7b6bfdc5408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots\n",
    "plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70af7673-18d4-4d02-b65b-7b50406faed5",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dda95da-6983-416f-b00f-fbe4bd018f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up a Dataset object for DataLoader\n",
    "class BuildingRasterDataset(Dataset):\n",
    "    def __init__(self, path, transform=None):\n",
    "        '''Loads and unpacks the data from the compressed .npz format'''\n",
    "        data = np.load(path)\n",
    "        \n",
    "        # Read raster maps\n",
    "        blocks_rasterized = data[\"blocks\"].copy()\n",
    "        # Read generalization operators\n",
    "        targets_eli = data[\"elimination\"].copy()\n",
    "        targets_agg = data[\"aggregation\"].copy()\n",
    "        targets_typ = data[\"typification\"].copy()\n",
    "        targets_dis = data[\"displacement\"].copy()\n",
    "        targets_enl = data[\"enlargement\"].copy()\n",
    "        targets_sim = data[\"simplification\"].copy()\n",
    "        \n",
    "        # Read target uuids\n",
    "        self.uuid = data[\"uuids\"].copy()\n",
    "\n",
    "        # Check whether all parts have the same dimensionality\n",
    "        assert blocks_rasterized.shape[0] == self.uuid.shape[0] == targets_eli.shape[0] == targets_agg.shape[0] == targets_typ.shape[0] \\\n",
    "        == targets_dis.shape[0] == targets_enl.shape[0] == targets_sim.shape[0]\n",
    "\n",
    "        # Convert numpy array to tensor with shape (n_samples, 3, height, width)\n",
    "        self.block = torch.from_numpy(blocks_rasterized).float()\n",
    "        \n",
    "        # Convert generalization operators to tensor\n",
    "        self.elimination = torch.from_numpy(targets_eli).float()\n",
    "        self.aggregation = torch.from_numpy(targets_agg).float()\n",
    "        self.typification = torch.from_numpy(targets_typ).float()\n",
    "        self.displacement = torch.from_numpy(targets_dis).float()\n",
    "        self.enlargement = torch.from_numpy(targets_enl).float()\n",
    "        self.simplification = torch.from_numpy(targets_sim).float()\n",
    "\n",
    "        # store transformation\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        '''Enables dataset length calculation'''\n",
    "        return self.uuid.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        '''Enables indexing, returns uuid and block raster as features and generalization operators as label'''\n",
    "        uuid = self.uuid[index]\n",
    "        block = self.block[index]\n",
    "        eli = self.elimination[index]\n",
    "        agg = self.aggregation[index]\n",
    "        typ = self.typification[index]\n",
    "        dis = self.displacement[index]\n",
    "        enl = self.enlargement[index]\n",
    "        sim = self.simplification[index]\n",
    "\n",
    "        if self.transform:\n",
    "            block = self.transform(block)\n",
    "\n",
    "        return uuid, block, eli, agg, typ, dis, enl, sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b73f523-0e33-403f-bf0e-7a25aa95fa6c",
   "metadata": {},
   "source": [
    "### Training pipeline\n",
    "\n",
    "1) Design model (input, output size, forward pass)\n",
    "2) Construct loss and optimizer\n",
    "3) Training loop\n",
    "     * Forward pass: Compute prediction\n",
    "     * Backward pass: Compute gradients\n",
    "     * Update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e688e5-9a9b-45ab-a10c-02a15ad36770",
   "metadata": {},
   "source": [
    "### Model design\n",
    "\n",
    "Stride refers to the number of positions that the convolutional kernel shifts at one step. Input channel size of one layer should always be equal to the output channel size of the previous layer.\n",
    "\n",
    "The application of convolution and pooling layers decreases the size of the image: The output after a convolution can be calculated according to the following formula, where $W$ is the input width, $F$ is the kernel size, $P$ is the padding and $S$ is the stride:\n",
    "\n",
    "$$\\frac{(W-F + 2 P)}{S} + 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc295f38-bae2-47cd-b2e3-9195931cdcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected layers with Global Average Pooling\n",
    "class FCGlobalPooling(nn.Module):\n",
    "    def __init__(self, n_last_out_channels):\n",
    "        super(FCGlobalPooling, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        \n",
    "        # Due to the global average pooling, the number of input features corresponds to the number of output channels of the last\n",
    "        # convolutional layers\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
    "            nn.Flatten(), # flatten to reshape the tensor from 4D to 2D\n",
    "            nn.Linear(in_features=self.n_last_out_channels, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Fully-connected layers without Global Average Pooling\n",
    "class FC(nn.Module):\n",
    "    def __init__(self, n_last_out_channels, image_size):\n",
    "        super(FC, self).__init__()\n",
    "        self.n_last_out_channels = n_last_out_channels\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # the number of input features of first fully-connected layer are calculated by multiplying number of output channels of last \n",
    "        # convolutional layer by (image size after all pooling operations)^2\n",
    "        # the last fully-connected layer has six output neurons, one for each generalization operator\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=self.n_last_out_channels*self.image_size*self.image_size, out_features=512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=6)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb00b17-9dc9-44d0-b266-6e21f1da169a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in the model: 34,882,675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AttUNet(\n",
       "  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (Conv1): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up5): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att5): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv5): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up4): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att4): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv4): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up3): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att3): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv3): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Up2): up_conv(\n",
       "    (up): Sequential(\n",
       "      (0): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Att2): Attention_block(\n",
       "    (W_g): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (W_x): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (psi): Sequential(\n",
       "      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Sigmoid()\n",
       "    )\n",
       "    (relu): ReLU(inplace=True)\n",
       "  )\n",
       "  (Up_conv2): conv_block(\n",
       "    (conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (Conv_1x1): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (fc): FCGlobalPooling(\n",
       "    (fc): Sequential(\n",
       "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (1): Flatten(start_dim=1, end_dim=-1)\n",
       "      (2): Linear(in_features=1, out_features=512, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Linear(in_features=512, out_features=6, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://amaarora.github.io/posts/2020-09-13-unet.html\n",
    "\n",
    "# conventional, simple CNN\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=n_channels, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        #self.fc = FCGlobalPooling(n_last_out_channels=128)\n",
    "        self.fc = FC(n_last_out_channels=128, image_size=32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # input dimension = 256\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # input dimension = 128\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # input dimension = 64\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        # input dimension = 32\n",
    "        x = self.fc(x) # No sigmoid function necessary, since BCEWithLogitsLoss applies sigmoid internally for loss computation\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for U-net adapted from https://github.com/milesial/Pytorch-UNet\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = (Down(512, 1024 // factor))\n",
    "        self.up1 = (Up(1024, 512 // factor, bilinear))\n",
    "        self.up2 = (Up(512, 256 // factor, bilinear))\n",
    "        self.up3 = (Up(256, 128 // factor, bilinear))\n",
    "        self.up4 = (Up(128, 64, bilinear))\n",
    "        self.outc = (OutConv(64, 1))\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        # decoding + concatenation\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        x = self.fc(logits)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Code for Residual U-net adapted from https://github.com/nikhilroxtomar/Semantic-Segmentation-Architecture\n",
    "class ResUNet(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        self.c11 = nn.Conv2d(n_channels, 64, kernel_size=3, padding=1)\n",
    "        self.br1 = batchnorm_relu(64)\n",
    "        self.c12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.c13 = nn.Conv2d(3, 64, kernel_size=1, padding=0)\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        self.r2 = residual_block(64, 128, stride=2)\n",
    "        self.r3 = residual_block(128, 256, stride=2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        self.r4 = residual_block(256, 512, stride=2)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        self.d1 = decoder_block(512, 256)\n",
    "        self.d2 = decoder_block(256, 128)\n",
    "        self.d3 = decoder_block(128, 64)\n",
    "\n",
    "        \"\"\" Output \"\"\"\n",
    "        self.output = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "        #self.sigmoid = nn.Sigmoid() # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\" Encoder 1 \"\"\"\n",
    "        x = self.c11(inputs)\n",
    "        x = self.br1(x)\n",
    "        x = self.c12(x)\n",
    "        s = self.c13(inputs)\n",
    "        skip1 = x + s\n",
    "\n",
    "        \"\"\" Encoder 2 and 3 \"\"\"\n",
    "        skip2 = self.r2(skip1)\n",
    "        skip3 = self.r3(skip2)\n",
    "\n",
    "        \"\"\" Bridge \"\"\"\n",
    "        b = self.r4(skip3)\n",
    "\n",
    "        \"\"\" Decoder \"\"\"\n",
    "        d1 = self.d1(b, skip3)\n",
    "        d2 = self.d2(d1, skip2)\n",
    "        d3 = self.d3(d2, skip1)\n",
    "\n",
    "        \"\"\" output \"\"\"\n",
    "        output = self.output(d3)\n",
    "        #output = self.sigmoid(output) # sigmoid not necessary when using BCEWithLogitsLoss\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Code for Attention U-net adapted from https://github.com/LeeJunHyun/Image_Segmentation\n",
    "class AttUNet(nn.Module):\n",
    "    def __init__(self,n_channels):\n",
    "        super(AttUNet,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=n_channels,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Att5 = Attention_block(F_g=512,F_l=512,F_int=256)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Att4 = Attention_block(F_g=256,F_l=256,F_int=128)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Att3 = Attention_block(F_g=128,F_l=128,F_int=64)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Att2 = Attention_block(F_g=64,F_l=64,F_int=32)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,1,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "        # appending fully-connected layers\n",
    "        self.fc = FCGlobalPooling(n_last_out_channels=1)\n",
    "        #self.fc = FC(n_last_out_channels=1, image_size=256)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        x4 = self.Att5(g=d5,x=x4)\n",
    "        d5 = torch.cat((x4,d5),dim=1)        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4,x=x3)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3,x=x2)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2,x=x1)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "\n",
    "        # passing the segmentation output through fully-connected layers for classification        \n",
    "        output = self.fc(d1)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Creating model and moving to device\n",
    "#model = CNN(n_channels=3)\n",
    "#model = UNet(n_channels=3)\n",
    "#model = ResUNet(n_channels=3)\n",
    "model = AttUNet(n_channels=3)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters in the model: {total_params:,}\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52663f75-0732-4f3f-b55e-3a68eee493cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() # Binary cross-entropy loss, applies a sigmoid internally and takes logits as input\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c9f7ae-8c3a-434d-bb6e-4300eb067628",
   "metadata": {},
   "source": [
    "### Loss and activation function\n",
    "\n",
    "Softmax is a common activation function, (binary) cross-Entropy is a common loss function for multiclass classification problems, sigmoid is commonly used for binary classification problems. When using the Pytorch implementation: no softmax in the last layer, class labels not one-hot encoded and no softmax. BCELoss requires an activation function at the end! Sigmoid are usually the last layers in binary classification probems.\n",
    "\n",
    "If you don't know which activation function to use, just use ReLU, Leaky ReLU tries to adress vanishing gradient problem. Multiplies input with small negative numbers, as normal ReLU may cause many gradients to become zero, which means that the weights will never be updated. Whenever weights are not updated during training, use Leaky ReLU.\n",
    "\n",
    "I am dealing with a multilabel (for each generalization operator), binary (operator present or absent) classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad2f78-e07d-4922-b9f3-b81ba80b9385",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67ac2819-465a-4faa-a8e7-5e2cde507c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/10, step 5/25\n",
      "epoch 1/10, step 10/25\n",
      "epoch 1/10, step 15/25\n",
      "epoch 1/10, step 20/25\n",
      "epoch 1/10, step 25/25\n",
      "epoch 1 finished, loss: 0.549\n",
      "epoch 2/10, step 5/25\n",
      "epoch 2/10, step 10/25\n",
      "epoch 2/10, step 15/25\n",
      "epoch 2/10, step 20/25\n",
      "epoch 2/10, step 25/25\n",
      "epoch 2 finished, loss: 0.481\n",
      "epoch 3/10, step 5/25\n",
      "epoch 3/10, step 10/25\n",
      "epoch 3/10, step 15/25\n",
      "epoch 3/10, step 20/25\n",
      "epoch 3/10, step 25/25\n",
      "epoch 3 finished, loss: 0.473\n",
      "epoch 4/10, step 5/25\n",
      "epoch 4/10, step 10/25\n",
      "epoch 4/10, step 15/25\n",
      "epoch 4/10, step 20/25\n",
      "epoch 4/10, step 25/25\n",
      "epoch 4 finished, loss: 0.477\n",
      "epoch 5/10, step 5/25\n",
      "epoch 5/10, step 10/25\n",
      "epoch 5/10, step 15/25\n",
      "epoch 5/10, step 20/25\n",
      "epoch 5/10, step 25/25\n",
      "epoch 5 finished, loss: 0.477\n",
      "epoch 6/10, step 5/25\n",
      "epoch 6/10, step 10/25\n",
      "epoch 6/10, step 15/25\n",
      "epoch 6/10, step 20/25\n",
      "epoch 6/10, step 25/25\n",
      "epoch 6 finished, loss: 0.479\n",
      "epoch 7/10, step 5/25\n",
      "epoch 7/10, step 10/25\n",
      "epoch 7/10, step 15/25\n",
      "epoch 7/10, step 20/25\n",
      "epoch 7/10, step 25/25\n",
      "epoch 7 finished, loss: 0.470\n",
      "epoch 8/10, step 5/25\n",
      "epoch 8/10, step 10/25\n",
      "epoch 8/10, step 15/25\n",
      "epoch 8/10, step 20/25\n",
      "epoch 8/10, step 25/25\n",
      "epoch 8 finished, loss: 0.469\n",
      "epoch 9/10, step 5/25\n",
      "epoch 9/10, step 10/25\n",
      "epoch 9/10, step 15/25\n",
      "epoch 9/10, step 20/25\n",
      "epoch 9/10, step 25/25\n",
      "epoch 9 finished, loss: 0.479\n",
      "epoch 10/10, step 5/25\n",
      "epoch 10/10, step 10/25\n",
      "epoch 10/10, step 15/25\n",
      "epoch 10/10, step 20/25\n",
      "epoch 10/10, step 25/25\n",
      "epoch 10 finished, loss: 0.469\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "\n",
    "data = \"../data.nosync/raster_training_data_small.npz\"\n",
    "\n",
    "# composing various random transforms that should be applied to the data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomRotation(degrees=(0,360)),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.RandomVerticalFlip(p=0.5)])\n",
    "\n",
    "train_dataset = BuildingRasterDataset(data, transform=transform)\n",
    "train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "total_samples = len(train_dataset)\n",
    "n_iterations = math.ceil(total_samples/batch_size)\n",
    "\n",
    "# saving the losses from every epoch\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # tracking loss per epoch\n",
    "    train_running_loss = 0.0\n",
    "    n_batches = 0\n",
    "    for i, (uuid, block, eli, agg, typ, dis, enl, sim) in enumerate(train_dataloader): \n",
    "        n_batches += 1\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass\n",
    "        pred_operators = model(block) # compute predictions, calls forward method under the hood\n",
    "        loss = criterion(pred_operators, operators) # calculate loss\n",
    "        train_running_loss += loss.item() # tracking running loss to keep track of the loss for every epoch\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward() # backpropagation\n",
    "        optimizer.step() # update the parameters\n",
    "\n",
    "        # print information every few batches\n",
    "        if not (i + 1) % 5:\n",
    "            print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iterations}\")\n",
    "\n",
    "    # print information at the end of each epoch\n",
    "    train_loss_epoch = train_running_loss / n_batches\n",
    "    train_losses.append(train_loss_epoch)\n",
    "    print(f\"epoch {epoch+1} finished, loss: {train_loss_epoch:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "238cd359-67bd-41d2-8494-4034d198550f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, color=\"orange\", label=\"training loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefe3dd0-951e-48fc-aca2-4b95f40d966f",
   "metadata": {},
   "source": [
    "### Evaluation and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3d0f803-c2b1-4bc8-a2e7-6ba22ef76dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELIMINATION: Accuracy: 0.660, Precision: 0.660, Recall: 1.000, F1-score: 0.795\n",
      "AGGREGATION: Accuracy: 0.790, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "TYPIFICATION: Accuracy: 0.920, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "DISPLACEMENT: Accuracy: 0.690, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "ENLARGEMENT: Accuracy: 0.680, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n",
      "SIMPLIFICATION: Accuracy: 0.970, Precision: 0.000, Recall: 0.000, F1-score: 0.000\n"
     ]
    }
   ],
   "source": [
    "test_dataset = BuildingRasterDataset(data)\n",
    "test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# stores the confusion matrices for every operator\n",
    "metrics = {}\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    metrics[operator_name] = {}\n",
    "    metrics[operator_name][\"tp\"] = 0\n",
    "    metrics[operator_name][\"fp\"] = 0\n",
    "    metrics[operator_name][\"tn\"] = 0\n",
    "    metrics[operator_name][\"fn\"] = 0\n",
    "\n",
    "# prediction evaluations should not be part of the computational graph, gradients should not be tracked\n",
    "with torch.no_grad():\n",
    "    for uuid, block, eli, agg, typ, dis, enl, sim in test_dataloader:\n",
    "        # moving the features to device\n",
    "        block = block.to(device)\n",
    "        eli = eli.to(device)\n",
    "        agg = agg.to(device)\n",
    "        typ = typ.to(device)\n",
    "        dis = dis.to(device)\n",
    "        enl = enl.to(device)\n",
    "        sim = sim.to(device)\n",
    "\n",
    "        # concatenate the operators: The first output neuron will indicate presence or absence of elimination, the second aggregation...\n",
    "        operators = torch.stack([eli, agg, typ, dis, enl, sim], dim=1).float()\n",
    "\n",
    "        # prediction on the trained model results in logits, sigmoid needs to be applied to obtain probabilities\n",
    "        pred_operators = torch.sigmoid(model(block))\n",
    "        pred_operators_labels = (pred_operators > 0.5).float()  # thresholding\n",
    "\n",
    "        # calculating metrics for the individual operators\n",
    "        for i, operator_name in enumerate(operator_order):\n",
    "            operator = operators[:, i]\n",
    "            pred_operator = pred_operators_labels[:, i]\n",
    "\n",
    "            tp, fp, tn, fn = calculate_conf_matrix(operator, pred_operator)\n",
    "\n",
    "            metrics[operator_name][\"tp\"] += tp\n",
    "            metrics[operator_name][\"fp\"] += fp\n",
    "            metrics[operator_name][\"tn\"] += tn\n",
    "            metrics[operator_name][\"fn\"] += fn\n",
    "\n",
    "for operator_name in operator_order:\n",
    "    accuracy, precision, recall, f1_score = calculate_metrics(metrics[operator_name][\"tp\"],\n",
    "                                                              metrics[operator_name][\"fp\"],\n",
    "                                                              metrics[operator_name][\"tn\"],\n",
    "                                                              metrics[operator_name][\"fn\"])\n",
    "    \n",
    "    print(f\"{operator_name.upper()}: Accuracy: {accuracy:.3f}, Precision: {precision:.3f}, Recall: {recall:.3f}, F1-score: {f1_score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f963fc6-62a7-4512-99dc-4277f8bf2b01",
   "metadata": {},
   "source": [
    "### Saving the model\n",
    "\n",
    "https://debuggercafe.com/multi-label-image-classification-with-pytorch-and-deep-learning/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35044e0b-5696-4bef-9f99-ffe005fa3de8",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "* Investigate effect of building size on the prediction quality? Other \"confounding\" factors.\n",
    "* See whether including the roads actually increases the prediction performance.\n",
    "* Investigate effects of imbalanced data / operator distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dcc3c9-902c-4ef0-ba6d-779b08e7cc0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

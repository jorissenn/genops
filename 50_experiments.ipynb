{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa35f193-bfa7-4d65-b6bb-64471a507760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/raster\")\n",
    "sys.path.append(\"models/vector\")\n",
    "sys.path.append(\"models/multimodal\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sqlalchemy import create_engine\n",
    "import geoalchemy2\n",
    "\n",
    "from auxiliary.database import read_table_from_db_multiple_geoms\n",
    "from auxiliary.config import db_username, db_password\n",
    "\n",
    "from cnn import CNN\n",
    "from vit import ViT\n",
    "from dataset_raster import BuildingRasterDataset, npz_to_tensor\n",
    "from initialize_gnn import initialize_gnn\n",
    "from dataset_vector import BuildingVectorDataset, process_HeteroData\n",
    "\n",
    "from model_multimodal import MultimodalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1aab1b0-3320-4d75-bf49-3228ab35cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql://{db_username}:{db_password}@localhost/genops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851e3e84-8670-40e3-8855-086a62a07523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read buildings from database\n",
    "buildings = read_table_from_db_multiple_geoms(engine, \n",
    "                                              \"buildings_dkm25_to_dkm50_genops\", \n",
    "                                              geom_cols=[\"source_geom\", \"target_geom\"], \n",
    "                                              columns_to_select=[\"source_uuid\",\n",
    "                                                                 \"source_geom\",\n",
    "                                                                 \"target_uuid\",\n",
    "                                                                 \"target_geom\",\n",
    "                                                                 \"elimination\",\n",
    "                                                                 \"aggregation\",\n",
    "                                                                 \"typification\",\n",
    "                                                                 \"displacement\",\n",
    "                                                                 \"displacement_prob\",\n",
    "                                                                 \"enlargement\",\n",
    "                                                                 \"enlargement_prob\",\n",
    "                                                                 \"simplification\",\n",
    "                                                                 \"simplification_prob\",\n",
    "                                                                 \"block_id\"])\n",
    "\n",
    "uuids_experimental = list(pd.read_csv(\"../data.nosync/balanced_data/experimental_uuids.csv\")[\"uuid\"])\n",
    "\n",
    "buildings_experimental = buildings[buildings[\"source_uuid\"].isin(uuids_experimental)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38dfbb9-580c-4e0b-b7ef-b7c1da2e744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")\n",
    "# features are always specified in this order\n",
    "feature_order = (\"area\", \n",
    "                 \"perimeter\", \n",
    "                 \"convexity\", \n",
    "                 \"eri\", \n",
    "                 \"orientation_mbr\", \n",
    "                 \"wall_average\", \n",
    "                 \"voronoi_area\", \n",
    "                 \"impact_area\", \n",
    "                 \"x_coord\", \n",
    "                 \"y_coord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13c5f39-03ab-47b2-b7f3-0f114aabaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots if working locally\n",
    "if not torch.cuda.is_available():\n",
    "    plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6403c-827e-4a95-97a6-33d72810dcbb",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82007c1-e5ba-4eaa-98c0-75397f68f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to test data for both raster and vector\n",
    "path_to_raster_experimental_data = \"../data.nosync/raster/training_data/experimental\"\n",
    "raster_filenames = os.listdir(path_to_raster_experimental_data)\n",
    "path_to_vector_experimental_data = \"../data.nosync/vector/training_data/experimental\"\n",
    "vector_filenames = os.listdir(path_to_vector_experimental_data)\n",
    "\n",
    "# important features\n",
    "features = [\"area\", \n",
    "            \"perimeter\", \n",
    "            \"convexity\", \n",
    "            \"eri\", \n",
    "            \"orientation_mbr\", \n",
    "            \"wall_average\", \n",
    "            \"voronoi_area\", \n",
    "            \"impact_area\", \n",
    "            \"x_coord\", \n",
    "            \"y_coord\"]\n",
    "\n",
    "selection_operators = [\"aggregation\", \"typification\", \"displacement\", \"enlargement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40657d5-2bc6-4649-a31f-710a1d7da6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â creating Dataset objects to initialize GNNs and multimodal model\n",
    "raster_eli_dataset = BuildingRasterDataset(path_to_raster_experimental_data, \n",
    "                                           operators=[\"elimination\"], \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)\n",
    "\n",
    "raster_sel_dataset = BuildingRasterDataset(path_to_raster_experimental_data, \n",
    "                                           operators=selection_operators, \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)\n",
    "\n",
    "vector_eli_dataset = BuildingVectorDataset(path_to_vector_experimental_data, \n",
    "                                           operators=[\"elimination\"],\n",
    "                                           operator_order=operator_order, \n",
    "                                           features=features, \n",
    "                                           feature_order=feature_order, \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)\n",
    "\n",
    "vector_sel_dataset = BuildingVectorDataset(path_to_vector_experimental_data, \n",
    "                                           operators=selection_operators,\n",
    "                                           operator_order=operator_order, \n",
    "                                           features=features, \n",
    "                                           feature_order=feature_order, \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5f30b-be64-4aba-a241-113b01d27058",
   "metadata": {},
   "source": [
    "### Loading the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba4f41bf-7a9f-4990-91a1-696a757d2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of node features: {'focal_building': 10, 'context_building': 10, 'road': 2}, 1 operators\n",
      "Number of node features: {'focal_building': 10, 'context_building': 10, 'road': 2}, 4 operators\n",
      "Models successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the trained raster models\n",
    "raster_model_path = \"../data.nosync/raster/models\"\n",
    "\n",
    "raster_eli_model_name = \"CNN_eli_attachRoadsTrue_4075585p_1000s_10ep_bs16.pth\"\n",
    "raster_eli_model = CNN(n_channels=3, n_classes=1)\n",
    "raster_eli_checkpoint = torch.load(os.path.join(raster_model_path, \"elimination\", raster_eli_model_name))\n",
    "raster_eli_model.load_state_dict(raster_eli_checkpoint[\"model_state_dict\"])\n",
    "raster_eli_model.eval()\n",
    "\n",
    "raster_sel_model_name = \"ViT_sel_attachRoadsTrue_27075076p_1000s_10ep_bs16.pth\"\n",
    "raster_sel_model = ViT(channels=3, num_classes=4)\n",
    "raster_sel_checkpoint = torch.load(os.path.join(raster_model_path, \"selection\", raster_sel_model_name))\n",
    "raster_sel_model.load_state_dict(raster_sel_checkpoint[\"model_state_dict\"])\n",
    "raster_sel_model.eval()\n",
    "    \n",
    "# load the trained vector models\n",
    "vector_model_path = \"../data.nosync/vector/models\"\n",
    "\n",
    "vector_eli_model_name = \"HGT_eli_attachRoadsTrue_645539p_1000s_10ep_bs16.pth\"\n",
    "vector_eli_model = initialize_gnn(model=\"hgt\", \n",
    "                                  sample=vector_eli_dataset.get(0), \n",
    "                                  hidden_channels=128, \n",
    "                                  num_heads=2,\n",
    "                                  num_layers=2, \n",
    "                                  node_to_predict=\"focal_building\")\n",
    "vector_eli_checkpoint = torch.load(os.path.join(vector_model_path, \"elimination\", vector_eli_model_name))\n",
    "vector_eli_model.load_state_dict(vector_eli_checkpoint[\"model_state_dict\"])\n",
    "vector_eli_model.eval()\n",
    "\n",
    "vector_sel_model_name = \"HGT_sel_attachRoadsTrue_695462p_1000s_10ep_bs16.pth\"\n",
    "vector_sel_model = initialize_gnn(model=\"hgt\", \n",
    "                                  sample=vector_sel_dataset.get(0), \n",
    "                                  hidden_channels=128, \n",
    "                                  num_heads=2, \n",
    "                                  num_layers=2, \n",
    "                                  node_to_predict=\"focal_building\")\n",
    "vector_sel_checkpoint = torch.load(os.path.join(vector_model_path, \"selection\", vector_sel_model_name))\n",
    "vector_sel_model.load_state_dict(vector_sel_checkpoint[\"model_state_dict\"])\n",
    "vector_sel_model.eval()\n",
    "\n",
    "# load the trained multimodal models\n",
    "multimodal_model_path = \"../data.nosync/multimodal/models\"\n",
    "\n",
    "multimodal_eli_model_name = \"MultimodalCNNHGT_eli_attachRoadsTrue_4720867p_1000s_10ep_bs16.pth\"\n",
    "multimodal_eli_model = MultimodalModel(raster_model=raster_eli_model, \n",
    "                                       vector_model=vector_eli_model, \n",
    "                                       dummy_raster_sample=raster_eli_dataset[0][0], \n",
    "                                       dummy_vector_sample=vector_eli_dataset.get(0), \n",
    "                                       n_classes=1)\n",
    "multimodal_eli_checkpoint = torch.load(os.path.join(multimodal_model_path, \"elimination\", multimodal_eli_model_name))\n",
    "multimodal_eli_model.load_state_dict(multimodal_eli_checkpoint[\"model_state_dict\"])\n",
    "multimodal_eli_model.eval()\n",
    "\n",
    "#multimodal_sel_model_name = \"\"\n",
    "#multimodal_sel_model = MultimodalModel(raster_model=raster_sel_model, \n",
    "#                                       vector_model=vector_sel_model, \n",
    "#                                       dummy_raster_sample=raster_sel_dataset[0][0], \n",
    "#                                       dummy_vector_sample=vector_sel_dataset.get(0), \n",
    "#                                       n_classes=4)\n",
    "#multimodal_sel_checkpoint = torch.load(os.path.join(multimodal_model_path, \"selection\", multimodal_sel_model_name))\n",
    "#multimodal_sel_model.load_state_dict(multimodal_sel_checkpoint[\"model_state_dict\"])\n",
    "#multimodal_sel_model.eval()\n",
    "\n",
    "print(\"Models successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7547eb2-b4de-41d7-a7a2-8199119603ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_raster(elimination_model, selection_model, uuid, attach_roads=True):\n",
    "    '''Computes a generalization operator prediction for a given UUID using the specified raster-based elimination and selection model.\n",
    "    Returns a dictionary with the operators as keys and values 1 / 0 indicating their respective presence / absence.'''\n",
    "    # get the file associated with the given uuid\n",
    "    raster_filename = [file for file in raster_filenames if uuid in file][0]\n",
    "\n",
    "    # load the raster file\n",
    "    raster_sample_raw = np.load(os.path.join(path_to_raster_experimental_data, raster_filename))\n",
    "\n",
    "    # convert loaded file to tensor\n",
    "    raster_sample = npz_to_tensor(raster_sample_raw, attach_roads=attach_roads)\n",
    "\n",
    "    # compute prediction through the elimination model\n",
    "    pred_elimination_logits = elimination_model(raster_sample.unsqueeze(0))\n",
    "    pred_elimination = torch.sigmoid(pred_elimination_logits)\n",
    "    pred_elimination_label = (pred_elimination > 0.5).float().squeeze(0)\n",
    "    \n",
    "    if int(pred_elimination_label.item()) == 1:\n",
    "        return {\"elimination\": 1, \"aggregation\": 0, \"typification\": 0, \"displacement\": 0, \"enlargement\": 0}\n",
    "\n",
    "    operators_pred = {\"elimination\": 0}\n",
    "    \n",
    "    # for all retained buildings, compute prediction through the selection model\n",
    "    pred_selection_logits = selection_model(raster_sample.unsqueeze(0))\n",
    "    pred_selection = torch.sigmoid(pred_selection_logits)\n",
    "    pred_selection_label = (pred_selection > 0.5).float().squeeze(0)\n",
    "\n",
    "    for i, operator in enumerate(selection_operators):\n",
    "        operators_pred[operator] = int(pred_selection_label[i].item())\n",
    "\n",
    "    return operators_pred\n",
    "\n",
    "def predict_vector(elimination_model, selection_model, uuid, features, feature_order, attach_roads=True):\n",
    "    '''Computes a generalization operator prediction for a given UUID using the specified graph-based elimination and selection model.\n",
    "    Returns a dictionary with the operators as keys and values 1 / 0 indicating their respective presence / absence.'''\n",
    "    # get the file associated with the given uuid\n",
    "    vector_filename = [file for file in vector_filenames if uuid in file][0]\n",
    "\n",
    "    # load the vector file\n",
    "    vector_sample_raw = torch.load(os.path.join(path_to_vector_experimental_data, vector_filename))\n",
    "    \n",
    "    # process the raw HeteroData object according to the specified information\n",
    "    features_idx = sorted([feature_order.index(feature) for feature in features if feature in feature_order])\n",
    "    vector_sample = process_HeteroData(vector_sample_raw,\n",
    "                                       operators=[0,1,2,3,4,5], #Â operators do not matter -> take all\n",
    "                                       features=features_idx,\n",
    "                                       attach_roads=attach_roads)\n",
    "\n",
    "    # compute prediction through the elimination model\n",
    "    pred_elimination_logits = elimination_model(vector_sample.x_dict, vector_sample.edge_index_dict)\n",
    "    pred_elimination = torch.sigmoid(pred_elimination_logits)\n",
    "    pred_elimination_label = (pred_elimination > 0.5).float().squeeze(0)\n",
    "\n",
    "    if int(pred_elimination_label.item()) == 1:\n",
    "        return {\"elimination\": 1, \"aggregation\": 0, \"typification\": 0, \"displacement\": 0, \"enlargement\": 0}\n",
    "\n",
    "    operators_pred = {\"elimination\": 0}\n",
    "    \n",
    "    # for all retained buildings, compute prediction through the selection model\n",
    "    pred_selection_logits = selection_model(vector_sample.x_dict, vector_sample.edge_index_dict)\n",
    "    pred_selection = torch.sigmoid(pred_selection_logits)\n",
    "    pred_selection_label = (pred_selection > 0.5).float().squeeze(0)\n",
    "\n",
    "    for i, operator in enumerate(selection_operators):\n",
    "        operators_pred[operator] = int(pred_selection_label[i].item())\n",
    "\n",
    "    return operators_pred\n",
    "\n",
    "def predict_multimodal(elimination_model, selection_model, uuid, features, feature_order, attach_roads=True):\n",
    "    # get the files associated with the given uuid\n",
    "    raster_filename = [file for file in raster_filenames if uuid in file][0]\n",
    "    vector_filename = [file for file in vector_filenames if uuid in file][0]\n",
    "\n",
    "    # load the raster and vector files\n",
    "    raster_sample_raw = np.load(os.path.join(path_to_raster_experimental_data, raster_filename))\n",
    "    vector_sample_raw = torch.load(os.path.join(path_to_vector_experimental_data, vector_filename))\n",
    "\n",
    "    # convert loaded file to tensor\n",
    "    raster_sample = npz_to_tensor(raster_sample_raw, attach_roads=attach_roads)\n",
    "\n",
    "    # process the raw HeteroData object according to the specified information\n",
    "    features_idx = sorted([feature_order.index(feature) for feature in features if feature in feature_order])\n",
    "    vector_sample = process_HeteroData(vector_sample_raw,\n",
    "                                       operators=[0,1,2,3,4,5], #Â operators do not matter -> take all\n",
    "                                       features=features_idx,\n",
    "                                       attach_roads=attach_roads)\n",
    "\n",
    "    # compute prediction through the elimination model\n",
    "    pred_elimination_logits = elimination_model(raster_sample.unsqueeze(0), vector_sample)\n",
    "    pred_elimination = torch.sigmoid(pred_elimination_logits)\n",
    "    pred_elimination_label = (pred_elimination > 0.5).float().squeeze(0)\n",
    "\n",
    "    if int(pred_elimination_label.item()) == 1:\n",
    "        return {\"elimination\": 1, \"aggregation\": 0, \"typification\": 0, \"displacement\": 0, \"enlargement\": 0}\n",
    "\n",
    "    operators_pred = {\"elimination\": 0}\n",
    "    \n",
    "    # for all retained buildings, compute prediction through the selection model\n",
    "    pred_selection_logits = selection_model(raster_sample.unsqueeze(0), vector_sample)\n",
    "    pred_selection = torch.sigmoid(pred_selection_logits)\n",
    "    pred_selection_label = (pred_selection > 0.5).float().squeeze(0)\n",
    "\n",
    "    for i, operator in enumerate(selection_operators):\n",
    "        operators_pred[operator] = int(pred_selection_label[i].item())\n",
    "\n",
    "    return operators_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf6cf90-38c2-4ba0-9043-cf7fd2f60753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing raster predictions\n",
    "preds_raster = buildings_experimental[\"source_uuid\"].apply(lambda uuid: predict_raster(raster_eli_model, \n",
    "                                                                                       raster_sel_model, \n",
    "                                                                                       uuid))\n",
    "preds_raster_df = preds_raster.apply(pd.Series)\n",
    "preds_raster_df.columns = [\"pred_\" + col + \"_raster\" for col in preds_raster_df.columns]\n",
    "buildings_experimental = buildings_experimental.join(preds_raster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90cb0930-8524-4cbc-8e64-91405f458e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing vector predictions\n",
    "preds_vector = buildings_experimental[\"source_uuid\"].apply(lambda uuid: predict_vector(vector_eli_model, \n",
    "                                                                                       vector_sel_model, \n",
    "                                                                                       uuid, \n",
    "                                                                                       features=features, \n",
    "                                                                                       feature_order=feature_order))\n",
    "preds_vector_df = preds_vector.apply(pd.Series)\n",
    "preds_vector_df.columns = [\"pred_\" + col + \"_vector\" for col in preds_vector_df.columns]\n",
    "buildings_experimental = buildings_experimental.join(preds_vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff443df1-872d-4897-bed2-2da08006c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing multimodal predictions\n",
    "preds_multimodal = buildings_experimental[\"source_uuid\"].apply(lambda uuid: predict_multimodal(multimodal_eli_model, \n",
    "                                                                                               multimodal_sel_model, \n",
    "                                                                                               uuid, \n",
    "                                                                                               features=features, \n",
    "                                                                                               feature_order=feature_order))\n",
    "preds_multimodal_df = preds_multimodal.apply(pd.Series)\n",
    "preds_multimodal_df.columns = [\"pred_\" + col + \"_multimodal\" for col in preds_multimodal_df.columns]\n",
    "buildings_experimental = buildings_experimental.join(preds_multimodal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a74179df-436c-4466-98b6-0b00d9bb7849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_uuid</th>\n",
       "      <th>source_geom</th>\n",
       "      <th>target_uuid</th>\n",
       "      <th>target_geom</th>\n",
       "      <th>elimination</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>typification</th>\n",
       "      <th>displacement</th>\n",
       "      <th>displacement_prob</th>\n",
       "      <th>enlargement</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_elimination_raster</th>\n",
       "      <th>pred_aggregation_raster</th>\n",
       "      <th>pred_typification_raster</th>\n",
       "      <th>pred_displacement_raster</th>\n",
       "      <th>pred_enlargement_raster</th>\n",
       "      <th>pred_elimination_vector</th>\n",
       "      <th>pred_aggregation_vector</th>\n",
       "      <th>pred_typification_vector</th>\n",
       "      <th>pred_displacement_vector</th>\n",
       "      <th>pred_enlargement_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{0A12E050-7866-4C38-9BD8-90A0C875E449}</td>\n",
       "      <td>POLYGON ((2612545.634 1215627.152, 2612544.010...</td>\n",
       "      <td>None</td>\n",
       "      <td>GEOMETRYCOLLECTION EMPTY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{0A4279BD-63FB-4A53-B273-D635E2C604D9}</td>\n",
       "      <td>POLYGON ((2662321.044 1220319.605, 2662317.509...</td>\n",
       "      <td>{E82F25A5-C7DA-46AD-8340-C5DDE24D90C0}</td>\n",
       "      <td>POLYGON ((2662309.61375 1220343.731249999, 266...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754299</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{0A485357-00DA-41D1-9DFA-E439B1096538}</td>\n",
       "      <td>POLYGON ((2600117.655 1144603.644, 2600104.371...</td>\n",
       "      <td>{BDFC99FF-622A-4C82-BEF5-0CBD3325E25A}</td>\n",
       "      <td>POLYGON ((2600128.6875 1144598.813749999, 2600...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754299</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{0A2477C4-4EB8-4F0D-B7E4-62FE808B9C1E}</td>\n",
       "      <td>POLYGON ((2703592.358 1112522.976, 2703592.331...</td>\n",
       "      <td>{F8380459-A751-414B-89C7-D45B7C916961}</td>\n",
       "      <td>POLYGON ((2703589.401250001 1112519.208749998,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754299</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{0AE31286-44ED-4141-B5ED-4E5C18883C36}</td>\n",
       "      <td>POLYGON ((2609781.329 1225354.030, 2609764.848...</td>\n",
       "      <td>{19446390-61D6-4A00-9732-6080D0909D65}</td>\n",
       "      <td>POLYGON ((2609781.548749998 1225353.067499999,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              source_uuid  \\\n",
       "0  {0A12E050-7866-4C38-9BD8-90A0C875E449}   \n",
       "1  {0A4279BD-63FB-4A53-B273-D635E2C604D9}   \n",
       "2  {0A485357-00DA-41D1-9DFA-E439B1096538}   \n",
       "3  {0A2477C4-4EB8-4F0D-B7E4-62FE808B9C1E}   \n",
       "4  {0AE31286-44ED-4141-B5ED-4E5C18883C36}   \n",
       "\n",
       "                                         source_geom  \\\n",
       "0  POLYGON ((2612545.634 1215627.152, 2612544.010...   \n",
       "1  POLYGON ((2662321.044 1220319.605, 2662317.509...   \n",
       "2  POLYGON ((2600117.655 1144603.644, 2600104.371...   \n",
       "3  POLYGON ((2703592.358 1112522.976, 2703592.331...   \n",
       "4  POLYGON ((2609781.329 1225354.030, 2609764.848...   \n",
       "\n",
       "                              target_uuid  \\\n",
       "0                                    None   \n",
       "1  {E82F25A5-C7DA-46AD-8340-C5DDE24D90C0}   \n",
       "2  {BDFC99FF-622A-4C82-BEF5-0CBD3325E25A}   \n",
       "3  {F8380459-A751-414B-89C7-D45B7C916961}   \n",
       "4  {19446390-61D6-4A00-9732-6080D0909D65}   \n",
       "\n",
       "                                         target_geom  elimination  \\\n",
       "0                           GEOMETRYCOLLECTION EMPTY            1   \n",
       "1  POLYGON ((2662309.61375 1220343.731249999, 266...            0   \n",
       "2  POLYGON ((2600128.6875 1144598.813749999, 2600...            0   \n",
       "3  POLYGON ((2703589.401250001 1112519.208749998,...            0   \n",
       "4  POLYGON ((2609781.548749998 1225353.067499999,...            0   \n",
       "\n",
       "   aggregation  typification  displacement  displacement_prob  enlargement  \\\n",
       "0            0             0             0           1.000000            0   \n",
       "1            0             0             1           0.754299            1   \n",
       "2            1             1             1           0.754299            1   \n",
       "3            1             1             1           0.754299            1   \n",
       "4            0             0             1           0.500000            1   \n",
       "\n",
       "   ...  pred_elimination_raster  pred_aggregation_raster  \\\n",
       "0  ...                        1                        0   \n",
       "1  ...                        1                        0   \n",
       "2  ...                        1                        0   \n",
       "3  ...                        1                        0   \n",
       "4  ...                        1                        0   \n",
       "\n",
       "   pred_typification_raster  pred_displacement_raster  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   pred_enlargement_raster  pred_elimination_vector  pred_aggregation_vector  \\\n",
       "0                        0                        1                        0   \n",
       "1                        0                        1                        0   \n",
       "2                        0                        0                        1   \n",
       "3                        0                        0                        1   \n",
       "4                        0                        0                        1   \n",
       "\n",
       "   pred_typification_vector  pred_displacement_vector  pred_enlargement_vector  \n",
       "0                         0                         0                        0  \n",
       "1                         0                         0                        0  \n",
       "2                         1                         0                        1  \n",
       "3                         1                         1                        0  \n",
       "4                         1                         0                        1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings_experimental.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137658c-c8c4-40fd-ada0-e3fcb2bc2fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

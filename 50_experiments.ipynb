{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa35f193-bfa7-4d65-b6bb-64471a507760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"models/raster\")\n",
    "sys.path.append(\"models/vector\")\n",
    "sys.path.append(\"models/multimodal\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sqlalchemy import create_engine\n",
    "import geoalchemy2\n",
    "\n",
    "from auxiliary.database import read_table_from_db_multiple_geoms\n",
    "from auxiliary.config import db_username, db_password\n",
    "\n",
    "from cnn import CNN\n",
    "from vit import ViT\n",
    "from dataset_raster import BuildingRasterDataset, npz_to_tensor\n",
    "from initialize_gnn import initialize_gnn\n",
    "from dataset_vector import BuildingVectorDataset, process_HeteroData\n",
    "\n",
    "from model_multimodal import MultimodalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1aab1b0-3320-4d75-bf49-3228ab35cb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"postgresql://{db_username}:{db_password}@localhost/genops\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "851e3e84-8670-40e3-8855-086a62a07523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read buildings from database\n",
    "buildings = read_table_from_db_multiple_geoms(engine, \n",
    "                                              \"buildings_dkm25_to_dkm50_genops\", \n",
    "                                              geom_cols=[\"source_geom\", \"target_geom\"], \n",
    "                                              columns_to_select=[\"source_uuid\",\n",
    "                                                                 \"source_geom\",\n",
    "                                                                 \"target_uuid\",\n",
    "                                                                 \"target_geom\",\n",
    "                                                                 \"elimination\",\n",
    "                                                                 \"aggregation\",\n",
    "                                                                 \"typification\",\n",
    "                                                                 \"displacement\",\n",
    "                                                                 \"displacement_prob\",\n",
    "                                                                 \"enlargement\",\n",
    "                                                                 \"enlargement_prob\",\n",
    "                                                                 \"simplification\",\n",
    "                                                                 \"simplification_prob\",\n",
    "                                                                 \"block_id\"])\n",
    "\n",
    "uuids_experimental = list(pd.read_csv(\"../data.nosync/balanced_data/experimental_uuids.csv\")[\"uuid\"])\n",
    "\n",
    "buildings_experimental = buildings[buildings[\"source_uuid\"].isin(uuids_experimental)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38dfbb9-580c-4e0b-b7ef-b7c1da2e744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# operators are always specified in this order\n",
    "operator_order = (\"elimination\", \"aggregation\", \"typification\", \"displacement\", \"enlargement\", \"simplification\")\n",
    "# features are always specified in this order\n",
    "feature_order = (\"area\", \n",
    "                 \"perimeter\", \n",
    "                 \"convexity\", \n",
    "                 \"eri\", \n",
    "                 \"orientation_mbr\", \n",
    "                 \"wall_average\", \n",
    "                 \"voronoi_area\", \n",
    "                 \"impact_area\", \n",
    "                 \"x_coord\", \n",
    "                 \"y_coord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13c5f39-03ab-47b2-b7f3-0f114aabaeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define DIN font for plots if working locally\n",
    "if not torch.cuda.is_available():\n",
    "    plt.rcParams[\"font.family\"] = \"DIN Alternate\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6403c-827e-4a95-97a6-33d72810dcbb",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82007c1-e5ba-4eaa-98c0-75397f68f761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path to test data for both raster and vector\n",
    "path_to_raster_experimental_data = \"../data.nosync/raster/training_data/experimental\"\n",
    "raster_filenames = os.listdir(path_to_raster_experimental_data)\n",
    "path_to_vector_experimental_data = \"../data.nosync/vector/training_data/experimental\"\n",
    "vector_filenames = os.listdir(path_to_vector_experimental_data)\n",
    "\n",
    "# important features\n",
    "features = [\"area\", \n",
    "            \"perimeter\", \n",
    "            \"convexity\", \n",
    "            \"eri\", \n",
    "            \"orientation_mbr\", \n",
    "            \"wall_average\", \n",
    "            \"voronoi_area\", \n",
    "            \"impact_area\", \n",
    "            \"x_coord\", \n",
    "            \"y_coord\"]\n",
    "\n",
    "selection_operators = [\"aggregation\", \"typification\", \"displacement\", \"enlargement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b40657d5-2bc6-4649-a31f-710a1d7da6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â creating Dataset objects to initialize GNNs and multimodal model\n",
    "raster_eli_dataset = BuildingRasterDataset(path_to_raster_experimental_data, \n",
    "                                           operators=[\"elimination\"], \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)\n",
    "\n",
    "raster_sel_dataset = BuildingRasterDataset(path_to_raster_experimental_data, \n",
    "                                           operators=selection_operators, \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)\n",
    "\n",
    "vector_eli_dataset = BuildingVectorDataset(path_to_vector_experimental_data, \n",
    "                                           operators=[\"elimination\"],\n",
    "                                           operator_order=operator_order, \n",
    "                                           features=features, \n",
    "                                           feature_order=feature_order, \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)\n",
    "\n",
    "vector_sel_dataset = BuildingVectorDataset(path_to_vector_experimental_data, \n",
    "                                           operators=selection_operators,\n",
    "                                           operator_order=operator_order, \n",
    "                                           features=features, \n",
    "                                           feature_order=feature_order, \n",
    "                                           attach_roads=True, \n",
    "                                           transform=None, \n",
    "                                           subset=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5f30b-be64-4aba-a241-113b01d27058",
   "metadata": {},
   "source": [
    "### Loading the trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba4f41bf-7a9f-4990-91a1-696a757d2e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of node features: {'focal_building': 10, 'context_building': 10, 'road': 2}, 1 operators\n",
      "Number of node features: {'focal_building': 10, 'context_building': 10, 'road': 2}, 4 operators\n",
      "Models successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "# load the trained raster models\n",
    "raster_model_path = \"../data.nosync/raster/models\"\n",
    "\n",
    "raster_eli_model_name = \"CNN_eli_attachRoadsTrue_4075585p_1000s_10ep_bs16.pth\"\n",
    "raster_eli_model = CNN(n_channels=3, n_classes=1)\n",
    "raster_eli_checkpoint = torch.load(os.path.join(raster_model_path, \"elimination\", raster_eli_model_name))\n",
    "raster_eli_model.load_state_dict(raster_eli_checkpoint[\"model_state_dict\"])\n",
    "raster_eli_model.eval()\n",
    "\n",
    "raster_sel_model_name = \"CNN_sel_attachRoadsTrue_8893252p_1000s_10ep_bs16.pth\"\n",
    "raster_sel_model = CNN(n_channels=3, n_classes=4)\n",
    "raster_sel_checkpoint = torch.load(os.path.join(raster_model_path, \"selection\", raster_sel_model_name))\n",
    "raster_sel_model.load_state_dict(raster_sel_checkpoint[\"model_state_dict\"])\n",
    "raster_sel_model.eval()\n",
    "    \n",
    "# load the trained vector models\n",
    "vector_model_path = \"../data.nosync/vector/models\"\n",
    "\n",
    "vector_eli_model_name = \"HGT_eli_attachRoadsTrue_645539p_1000s_10ep_bs16.pth\"\n",
    "vector_eli_model = initialize_gnn(model=\"hgt\", \n",
    "                                  sample=vector_eli_dataset.get(2), \n",
    "                                  hidden_channels=128, \n",
    "                                  num_heads=2,\n",
    "                                  num_layers=2, \n",
    "                                  node_to_predict=\"focal_building\")\n",
    "vector_eli_checkpoint = torch.load(os.path.join(vector_model_path, \"elimination\", vector_eli_model_name))\n",
    "vector_eli_model.load_state_dict(vector_eli_checkpoint[\"model_state_dict\"])\n",
    "vector_eli_model.eval()\n",
    "\n",
    "vector_sel_model_name = \"HGT_sel_attachRoadsTrue_695462p_1000s_10ep_bs16.pth\"\n",
    "vector_sel_model = initialize_gnn(model=\"hgt\", \n",
    "                                  sample=vector_sel_dataset.get(2), \n",
    "                                  hidden_channels=128, \n",
    "                                  num_heads=2, \n",
    "                                  num_layers=2, \n",
    "                                  node_to_predict=\"focal_building\")\n",
    "vector_sel_checkpoint = torch.load(os.path.join(vector_model_path, \"selection\", vector_sel_model_name))\n",
    "vector_sel_model.load_state_dict(vector_sel_checkpoint[\"model_state_dict\"])\n",
    "vector_sel_model.eval()\n",
    "\n",
    "# load the trained multimodal models\n",
    "multimodal_model_path = \"../data.nosync/multimodal/models\"\n",
    "\n",
    "multimodal_eli_model_name = \"MultimodalCNNHGT_eli_attachRoadsTrue_4720867p_1000s_10ep_bs16.pth\"\n",
    "multimodal_eli_model = MultimodalModel(raster_model=raster_eli_model, \n",
    "                                       vector_model=vector_eli_model, \n",
    "                                       dummy_raster_sample=raster_eli_dataset[0][0], \n",
    "                                       dummy_vector_sample=vector_eli_dataset.get(1), \n",
    "                                       n_classes=1)\n",
    "multimodal_eli_checkpoint = torch.load(os.path.join(multimodal_model_path, \"elimination\", multimodal_eli_model_name))\n",
    "multimodal_eli_model.load_state_dict(multimodal_eli_checkpoint[\"model_state_dict\"])\n",
    "multimodal_eli_model.eval()\n",
    "\n",
    "multimodal_sel_model_name = \"MultimodalCNNHGT_sel_attachRoadsTrue_9587686p_1000s_10ep_bs16.pth\"\n",
    "multimodal_sel_model = MultimodalModel(raster_model=raster_sel_model, \n",
    "                                       vector_model=vector_sel_model, \n",
    "                                       dummy_raster_sample=raster_sel_dataset[0][0], \n",
    "                                       dummy_vector_sample=vector_sel_dataset.get(1), \n",
    "                                       n_classes=4)\n",
    "multimodal_sel_checkpoint = torch.load(os.path.join(multimodal_model_path, \"selection\", multimodal_sel_model_name))\n",
    "multimodal_sel_model.load_state_dict(multimodal_sel_checkpoint[\"model_state_dict\"])\n",
    "multimodal_sel_model.eval()\n",
    "\n",
    "print(\"Models successfully loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7547eb2-b4de-41d7-a7a2-8199119603ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_raster(elimination_model, selection_model, uuid, attach_roads=True):\n",
    "    '''Computes a generalization operator prediction for a given UUID using the specified raster-based elimination and selection model.\n",
    "    Returns a dictionary with the operators as keys and values 1 / 0 indicating their respective presence / absence.'''\n",
    "    # get the file associated with the given uuid\n",
    "    raster_filename = [file for file in raster_filenames if uuid in file][0]\n",
    "\n",
    "    # load the raster file\n",
    "    raster_sample_raw = np.load(os.path.join(path_to_raster_experimental_data, raster_filename))\n",
    "\n",
    "    # convert loaded file to tensor\n",
    "    raster_sample = npz_to_tensor(raster_sample_raw, attach_roads=attach_roads)\n",
    "\n",
    "    # compute prediction through the elimination model\n",
    "    pred_elimination_logits = elimination_model(raster_sample.unsqueeze(0))\n",
    "    pred_elimination = torch.sigmoid(pred_elimination_logits)\n",
    "    pred_elimination_label = (pred_elimination > 0.5).float().squeeze(0)\n",
    "    \n",
    "    if int(pred_elimination_label.item()) == 1:\n",
    "        return {\"elimination\": 1, \"aggregation\": 0, \"typification\": 0, \"displacement\": 0, \"enlargement\": 0}\n",
    "\n",
    "    operators_pred = {\"elimination\": 0}\n",
    "    \n",
    "    # for all retained buildings, compute prediction through the selection model\n",
    "    pred_selection_logits = selection_model(raster_sample.unsqueeze(0))\n",
    "    pred_selection = torch.sigmoid(pred_selection_logits)\n",
    "    pred_selection_label = (pred_selection > 0.5).float().squeeze(0)\n",
    "\n",
    "    for i, operator in enumerate(selection_operators):\n",
    "        operators_pred[operator] = int(pred_selection_label[i].item())\n",
    "\n",
    "    return operators_pred\n",
    "\n",
    "def predict_vector(elimination_model, selection_model, uuid, features, feature_order, attach_roads=True):\n",
    "    '''Computes a generalization operator prediction for a given UUID using the specified graph-based elimination and selection model.\n",
    "    Returns a dictionary with the operators as keys and values 1 / 0 indicating their respective presence / absence.'''\n",
    "    # get the file associated with the given uuid\n",
    "    vector_filename = [file for file in vector_filenames if uuid in file][0]\n",
    "\n",
    "    # load the vector file\n",
    "    vector_sample_raw = torch.load(os.path.join(path_to_vector_experimental_data, vector_filename))\n",
    "    \n",
    "    # process the raw HeteroData object according to the specified information\n",
    "    features_idx = sorted([feature_order.index(feature) for feature in features if feature in feature_order])\n",
    "    vector_sample = process_HeteroData(vector_sample_raw,\n",
    "                                       operators=[0,1,2,3,4,5], #Â operators do not matter -> take all\n",
    "                                       features=features_idx,\n",
    "                                       attach_roads=attach_roads)\n",
    "\n",
    "    # compute prediction through the elimination model\n",
    "    pred_elimination_logits = elimination_model(vector_sample.x_dict, vector_sample.edge_index_dict)\n",
    "    pred_elimination = torch.sigmoid(pred_elimination_logits)\n",
    "    pred_elimination_label = (pred_elimination > 0.5).float().squeeze(0)\n",
    "\n",
    "    if int(pred_elimination_label.item()) == 1:\n",
    "        return {\"elimination\": 1, \"aggregation\": 0, \"typification\": 0, \"displacement\": 0, \"enlargement\": 0}\n",
    "\n",
    "    operators_pred = {\"elimination\": 0}\n",
    "    \n",
    "    # for all retained buildings, compute prediction through the selection model\n",
    "    pred_selection_logits = selection_model(vector_sample.x_dict, vector_sample.edge_index_dict)\n",
    "    pred_selection = torch.sigmoid(pred_selection_logits)\n",
    "    pred_selection_label = (pred_selection > 0.5).float().squeeze(0)\n",
    "\n",
    "    for i, operator in enumerate(selection_operators):\n",
    "        operators_pred[operator] = int(pred_selection_label[i].item())\n",
    "\n",
    "    return operators_pred\n",
    "\n",
    "def predict_multimodal(elimination_model, selection_model, uuid, features, feature_order, attach_roads=True):\n",
    "    # get the files associated with the given uuid\n",
    "    raster_filename = [file for file in raster_filenames if uuid in file][0]\n",
    "    vector_filename = [file for file in vector_filenames if uuid in file][0]\n",
    "\n",
    "    # load the raster and vector files\n",
    "    raster_sample_raw = np.load(os.path.join(path_to_raster_experimental_data, raster_filename))\n",
    "    vector_sample_raw = torch.load(os.path.join(path_to_vector_experimental_data, vector_filename))\n",
    "\n",
    "    # convert loaded file to tensor\n",
    "    raster_sample = npz_to_tensor(raster_sample_raw, attach_roads=attach_roads)\n",
    "\n",
    "    # process the raw HeteroData object according to the specified information\n",
    "    features_idx = sorted([feature_order.index(feature) for feature in features if feature in feature_order])\n",
    "    vector_sample = process_HeteroData(vector_sample_raw,\n",
    "                                       operators=[0,1,2,3,4,5], #Â operators do not matter -> take all\n",
    "                                       features=features_idx,\n",
    "                                       attach_roads=attach_roads)\n",
    "\n",
    "    # compute prediction through the elimination model\n",
    "    pred_elimination_logits = elimination_model(raster_sample.unsqueeze(0), vector_sample)\n",
    "    pred_elimination = torch.sigmoid(pred_elimination_logits)\n",
    "    pred_elimination_label = (pred_elimination > 0.5).float().squeeze(0)\n",
    "\n",
    "    if int(pred_elimination_label.item()) == 1:\n",
    "        return {\"elimination\": 1, \"aggregation\": 0, \"typification\": 0, \"displacement\": 0, \"enlargement\": 0}\n",
    "\n",
    "    operators_pred = {\"elimination\": 0}\n",
    "    \n",
    "    # for all retained buildings, compute prediction through the selection model\n",
    "    pred_selection_logits = selection_model(raster_sample.unsqueeze(0), vector_sample)\n",
    "    pred_selection = torch.sigmoid(pred_selection_logits)\n",
    "    pred_selection_label = (pred_selection > 0.5).float().squeeze(0)\n",
    "\n",
    "    for i, operator in enumerate(selection_operators):\n",
    "        operators_pred[operator] = int(pred_selection_label[i].item())\n",
    "\n",
    "    return operators_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf6cf90-38c2-4ba0-9043-cf7fd2f60753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing raster predictions\n",
    "preds_raster = buildings_experimental[\"source_uuid\"].apply(lambda uuid: predict_raster(raster_eli_model, \n",
    "                                                                                       raster_sel_model, \n",
    "                                                                                       uuid))\n",
    "preds_raster_df = preds_raster.apply(pd.Series)\n",
    "preds_raster_df.columns = [\"pred_\" + col + \"_raster\" for col in preds_raster_df.columns]\n",
    "buildings_experimental = buildings_experimental.join(preds_raster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90cb0930-8524-4cbc-8e64-91405f458e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing vector predictions\n",
    "preds_vector = buildings_experimental[\"source_uuid\"].apply(lambda uuid: predict_vector(vector_eli_model, \n",
    "                                                                                       vector_sel_model, \n",
    "                                                                                       uuid, \n",
    "                                                                                       features=features, \n",
    "                                                                                       feature_order=feature_order))\n",
    "preds_vector_df = preds_vector.apply(pd.Series)\n",
    "preds_vector_df.columns = [\"pred_\" + col + \"_vector\" for col in preds_vector_df.columns]\n",
    "buildings_experimental = buildings_experimental.join(preds_vector_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff443df1-872d-4897-bed2-2da08006c026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing multimodal predictions\n",
    "preds_multimodal = buildings_experimental[\"source_uuid\"].apply(lambda uuid: predict_multimodal(multimodal_eli_model, \n",
    "                                                                                               multimodal_sel_model, \n",
    "                                                                                               uuid, \n",
    "                                                                                               features=features, \n",
    "                                                                                               feature_order=feature_order))\n",
    "preds_multimodal_df = preds_multimodal.apply(pd.Series)\n",
    "preds_multimodal_df.columns = [\"pred_\" + col + \"_multimodal\" for col in preds_multimodal_df.columns]\n",
    "buildings_experimental = buildings_experimental.join(preds_multimodal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a74179df-436c-4466-98b6-0b00d9bb7849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_uuid</th>\n",
       "      <th>source_geom</th>\n",
       "      <th>target_uuid</th>\n",
       "      <th>target_geom</th>\n",
       "      <th>elimination</th>\n",
       "      <th>aggregation</th>\n",
       "      <th>typification</th>\n",
       "      <th>displacement</th>\n",
       "      <th>displacement_prob</th>\n",
       "      <th>enlargement</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_elimination_vector</th>\n",
       "      <th>pred_aggregation_vector</th>\n",
       "      <th>pred_typification_vector</th>\n",
       "      <th>pred_displacement_vector</th>\n",
       "      <th>pred_enlargement_vector</th>\n",
       "      <th>pred_elimination_multimodal</th>\n",
       "      <th>pred_aggregation_multimodal</th>\n",
       "      <th>pred_typification_multimodal</th>\n",
       "      <th>pred_displacement_multimodal</th>\n",
       "      <th>pred_enlargement_multimodal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{85318C34-58F2-4918-94A6-C9F57F1388F5}</td>\n",
       "      <td>POLYGON ((2699374.976 1111182.576, 2699387.823...</td>\n",
       "      <td>{3DD7631E-31D4-4F19-924D-C68C430D0CF2}</td>\n",
       "      <td>POLYGON ((2699353.94125 1111157.725000001, 269...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754299</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{8995993F-DA45-4654-8A66-2DB443384549}</td>\n",
       "      <td>POLYGON ((2678235.300 1289236.329, 2678229.758...</td>\n",
       "      <td>{DA9E1927-2DDC-4871-BFDF-1404164C3363}</td>\n",
       "      <td>POLYGON ((2678239.43375 1289229.973749999, 267...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754299</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{89629C3A-CE33-4FBA-A721-42879058462E}</td>\n",
       "      <td>POLYGON ((2694088.746 1142933.175, 2694078.935...</td>\n",
       "      <td>{AD50AB0B-6ED0-445F-88AA-1F0F1487A330}</td>\n",
       "      <td>POLYGON ((2694104.278749999 1142916.145, 26940...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754299</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{8A31AED2-E820-40D6-90D2-CB37BD0E4CBD}</td>\n",
       "      <td>POLYGON ((2590072.970 1193204.782, 2590070.500...</td>\n",
       "      <td>{3B004F11-D7C6-4453-8C38-406940A5C99F},{E68F90...</td>\n",
       "      <td>MULTIPOLYGON (((2590025.998750001 1193194.2600...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.754299</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{8A0C61FA-B719-4164-9168-826B849404F7}</td>\n",
       "      <td>POLYGON ((2548280.323 1211864.241, 2548269.991...</td>\n",
       "      <td>{CC0807BA-38A0-4B3C-A8D9-378B2DFF3FC1}</td>\n",
       "      <td>POLYGON ((2548283.813749999 1211840.502500001,...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.865735</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              source_uuid  \\\n",
       "0  {85318C34-58F2-4918-94A6-C9F57F1388F5}   \n",
       "1  {8995993F-DA45-4654-8A66-2DB443384549}   \n",
       "2  {89629C3A-CE33-4FBA-A721-42879058462E}   \n",
       "3  {8A31AED2-E820-40D6-90D2-CB37BD0E4CBD}   \n",
       "4  {8A0C61FA-B719-4164-9168-826B849404F7}   \n",
       "\n",
       "                                         source_geom  \\\n",
       "0  POLYGON ((2699374.976 1111182.576, 2699387.823...   \n",
       "1  POLYGON ((2678235.300 1289236.329, 2678229.758...   \n",
       "2  POLYGON ((2694088.746 1142933.175, 2694078.935...   \n",
       "3  POLYGON ((2590072.970 1193204.782, 2590070.500...   \n",
       "4  POLYGON ((2548280.323 1211864.241, 2548269.991...   \n",
       "\n",
       "                                         target_uuid  \\\n",
       "0             {3DD7631E-31D4-4F19-924D-C68C430D0CF2}   \n",
       "1             {DA9E1927-2DDC-4871-BFDF-1404164C3363}   \n",
       "2             {AD50AB0B-6ED0-445F-88AA-1F0F1487A330}   \n",
       "3  {3B004F11-D7C6-4453-8C38-406940A5C99F},{E68F90...   \n",
       "4             {CC0807BA-38A0-4B3C-A8D9-378B2DFF3FC1}   \n",
       "\n",
       "                                         target_geom  elimination  \\\n",
       "0  POLYGON ((2699353.94125 1111157.725000001, 269...            0   \n",
       "1  POLYGON ((2678239.43375 1289229.973749999, 267...            0   \n",
       "2  POLYGON ((2694104.278749999 1142916.145, 26940...            0   \n",
       "3  MULTIPOLYGON (((2590025.998750001 1193194.2600...            0   \n",
       "4  POLYGON ((2548283.813749999 1211840.502500001,...            0   \n",
       "\n",
       "   aggregation  typification  displacement  displacement_prob  enlargement  \\\n",
       "0            1             1             1           0.754299            1   \n",
       "1            1             0             1           0.754299            0   \n",
       "2            1             1             1           0.754299            1   \n",
       "3            1             1             1           0.754299            1   \n",
       "4            1             1             1           0.865735            1   \n",
       "\n",
       "   ...  pred_elimination_vector  pred_aggregation_vector  \\\n",
       "0  ...                        0                        1   \n",
       "1  ...                        0                        1   \n",
       "2  ...                        0                        1   \n",
       "3  ...                        0                        1   \n",
       "4  ...                        1                        0   \n",
       "\n",
       "   pred_typification_vector  pred_displacement_vector  \\\n",
       "0                         0                         1   \n",
       "1                         0                         1   \n",
       "2                         0                         0   \n",
       "3                         0                         1   \n",
       "4                         0                         0   \n",
       "\n",
       "   pred_enlargement_vector  pred_elimination_multimodal  \\\n",
       "0                        1                            0   \n",
       "1                        0                            0   \n",
       "2                        1                            0   \n",
       "3                        0                            0   \n",
       "4                        0                            0   \n",
       "\n",
       "   pred_aggregation_multimodal  pred_typification_multimodal  \\\n",
       "0                            1                             0   \n",
       "1                            1                             0   \n",
       "2                            1                             0   \n",
       "3                            1                             1   \n",
       "4                            0                             0   \n",
       "\n",
       "   pred_displacement_multimodal  pred_enlargement_multimodal  \n",
       "0                             0                            1  \n",
       "1                             1                            0  \n",
       "2                             0                            1  \n",
       "3                             1                            0  \n",
       "4                             1                            1  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildings_experimental.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137658c-c8c4-40fd-ada0-e3fcb2bc2fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
